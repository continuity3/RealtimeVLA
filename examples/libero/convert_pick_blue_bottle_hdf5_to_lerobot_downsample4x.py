"""
è½¬æ¢ pick_blue_bottle æ•°æ®é›†çš„ HDF5 æ ¼å¼æ•°æ®åˆ° LeRobot æ ¼å¼çš„è„šæœ¬ï¼ˆä¸‹é‡‡æ ·4å€ç‰ˆæœ¬ï¼Œä»…ä½¿ç”¨å³è‡‚æ•°æ®ï¼‰ã€‚

è¿™ä¸ªè„šæœ¬ä¸“é—¨ç”¨äºå¤„ç† pick_blue_bottle æ•°æ®é›†çš„ HDF5 æ–‡ä»¶ï¼Œå¹¶å°†æ•°æ®ä¸‹é‡‡æ ·4å€ã€‚
åªä½¿ç”¨å³è‡‚æ•°æ®ï¼ˆå·¦è‡‚æœªä½¿ç”¨ï¼‰ï¼Œå¹¶åŒ…å«å³å¤¹çˆªä¿¡æ¯ã€‚

HDF5 æ–‡ä»¶ç»“æ„:
- time: (T,) æ—¶é—´æˆ³
- topics/_joint_states/:
    - position: (T, 14) å…³èŠ‚ä½ç½®ï¼ˆå‰7ç»´=å·¦è‡‚ï¼Œå7ç»´=å³è‡‚ï¼‰
    - velocity: (T, 14) å…³èŠ‚é€Ÿåº¦ï¼ˆå‰7ç»´=å·¦è‡‚ï¼Œå7ç»´=å³è‡‚ï¼‰
- topics/_info_eef_right/:
    - position: (T, 3) å³è‡‚æœ«ç«¯æ‰§è¡Œå™¨ä½ç½®
    - orientation: (T, 4) å³è‡‚æœ«ç«¯æ‰§è¡Œå™¨æ–¹å‘ï¼ˆå››å…ƒæ•°ï¼‰
- topics/_gripper_feedback_R/:
    - data: (T, 5) å³å¤¹çˆªåé¦ˆæ•°æ®ï¼ˆç¬¬ä¸€åˆ—æ˜¯å¤¹çˆªçŠ¶æ€å€¼ï¼‰
- topics/_camera_camera_color_image_raw/:
    - data: (T, 921600) æˆ– (T, H, W, 3) ä¸»ç›¸æœºå›¾åƒæ•°æ®ï¼ˆæ—§æ ¼å¼æ‰å¹³åŒ–ï¼Œæ–°æ ¼å¼å·²è§£ç ï¼‰
    - data_length: (T,) æ¯ä¸ªå›¾åƒçš„å®é™…é•¿åº¦ï¼ˆä»…æ—§æ ¼å¼ï¼‰
- topics/image_wrist/ (å¯é€‰):
    - data: (T, H, W, 3) æˆ– (T, ...) æ‰‹è…•ç›¸æœºå›¾åƒæ•°æ®ï¼ˆæ–°æ ¼å¼å·²è§£ç ï¼Œæ—§æ ¼å¼å¯èƒ½éœ€è¦è§£ç ï¼‰
    - data_length: (T,) æ¯ä¸ªå›¾åƒçš„å®é™…é•¿åº¦ï¼ˆä»…æ—§æ ¼å¼ï¼Œå¦‚æœå­˜åœ¨ï¼‰

è¾“å‡ºæ•°æ®:
- çŠ¶æ€: [3ç»´EEFä½ç½®, 3ç»´EEFæ–¹å‘(è½´è§’), 1ç»´å¤¹çˆªå€¼, 1ç»´å¤¹çˆªå€¼ç›¸åæ•°] = 8ç»´
- åŠ¨ä½œ: [7ä¸ªå³è‡‚å…³èŠ‚é€Ÿåº¦, 1ä¸ªå³å¤¹çˆªé€Ÿåº¦] = 8ç»´ï¼ˆåŒ…å«gripperï¼‰
  - å…³èŠ‚åŠ¨ä½œ = velocity (rad/s)
  - gripperåŠ¨ä½œ = gripperé€Ÿåº¦ (å˜åŒ–ç‡)
  - æ³¨æ„ï¼šè®­ç»ƒæ—¶éœ€è¦ä½¿ç”¨ q_next = q_curr + velocity * dtï¼Œå…¶ä¸­ dt = 1/fps

Usage:
uv run examples/libero/convert_pick_blue_bottle_hdf5_to_lerobot_downsample4x.py --data_dir /path/to/pick_blue_bottle_extracted
"""

import shutil
from pathlib import Path

import h5py
import numpy as np
from lerobot.common.datasets.lerobot_dataset import HF_LEROBOT_HOME
from lerobot.common.datasets.lerobot_dataset import LeRobotDataset
from PIL import Image
from tqdm import tqdm
import tyro
from scipy.spatial.transform import Rotation as R

REPO_NAME = "your_hf_username/pick_blue_bottle_libero_downsample4x"  # è¾“å‡ºæ•°æ®é›†åç§°ï¼ˆä¸‹é‡‡æ ·4å€ç‰ˆæœ¬ï¼‰


def decode_image(img_data: np.ndarray, img_length: int) -> np.ndarray:
    """
    è§£ç å›¾åƒæ•°æ®ã€‚
    
    å›¾åƒæ•°æ®å¯èƒ½æ˜¯ï¼š
    1. JPEG å‹ç¼©æ ¼å¼ï¼ˆéœ€è¦è§£ç ï¼‰
    2. åŸå§‹ RGB å›¾åƒæ•°æ®ï¼ˆéœ€è¦é‡å¡‘ï¼‰
    
    Args:
        img_data: å›¾åƒæ•°æ®æ•°ç»„ï¼ˆæ‰å¹³åŒ–ï¼‰
        img_length: å›¾åƒæ•°æ®çš„å®é™…é•¿åº¦
    
    Returns:
        è§£ç åçš„å›¾åƒ (H, W, 3) uint8
    """
    img_bytes = bytes(img_data[:img_length])
    
    # ä¼˜å…ˆå°è¯•ä½œä¸º JPEG è§£ç ï¼ˆæœ€å¸¸è§ï¼‰
    try:
        import cv2
        nparr = np.frombuffer(img_bytes, np.uint8)
        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img is not None:
            # OpenCV è¿”å› BGRï¼Œè½¬æ¢ä¸º RGB
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            return img
    except ImportError:
        # å¦‚æœæ²¡æœ‰ OpenCVï¼Œå°è¯•ç”¨ PIL
        try:
            from io import BytesIO
            img = Image.open(BytesIO(img_bytes))
            if img.mode != 'RGB':
                img = img.convert('RGB')
            return np.array(img)
        except:
            pass
    except:
        # OpenCV è§£ç å¤±è´¥ï¼Œå°è¯•å…¶ä»–æ–¹æ³•
        pass
    
    # å¦‚æœä¸æ˜¯ JPEGï¼Œå°è¯•ä½œä¸ºåŸå§‹å›¾åƒæ•°æ®
    # å°è¯•å¸¸è§çš„å°ºå¯¸
    possible_sizes = [
        (720, 1280, 1),  # å•é€šé“
        (480, 640, 3),   # RGB
        (480, 854, 3),   # RGB
        (360, 640, 3),   # RGB
    ]
    
    for h, w, c in possible_sizes:
        if h * w * c == img_length:
            img = np.frombuffer(img_bytes, dtype=np.uint8).reshape(h, w, c)
            if c == 1:
                # å•é€šé“è½¬ RGB
                img = np.repeat(img, 3, axis=2)
            return img
    
    # å¦‚æœéƒ½ä¸åŒ¹é…ï¼Œå°è¯•ç›´æ¥é‡å¡‘ä¸º 640x480x3ï¼ˆæœ€å¸¸è§ï¼‰
    if img_length >= 640 * 480 * 3:
        img = np.frombuffer(img_bytes[:640*480*3], dtype=np.uint8).reshape(480, 640, 3)
        return img
    
    raise ValueError(f"æ— æ³•è§£ç å›¾åƒæ•°æ®ï¼Œé•¿åº¦: {img_length}")


def resize_image(image: np.ndarray, target_size: tuple[int, int] = (256, 256)) -> np.ndarray:
    """è°ƒæ•´å›¾åƒå¤§å°åˆ°ç›®æ ‡å°ºå¯¸"""
    if image.shape[:2] == target_size:
        return image
    img = Image.fromarray(image)
    img = img.resize(target_size, resample=Image.BICUBIC)
    return np.array(img)


def handle_nan_values(data: np.ndarray) -> np.ndarray:
    """
    å¤„ç† NaN å€¼ï¼š
    - ç¬¬ä¸€ä¸ªæ•°æ®å‡ºç° NaN â†’ ä½¿ç”¨ç¬¬äºŒä¸ªæ•°æ®
    - æœ€åä¸€ä¸ªæ•°æ®å‡ºç° NaN â†’ ä½¿ç”¨å€’æ•°ç¬¬äºŒä¸ªæ•°æ®
    - ä¸­é—´å‡ºç° NaN â†’ ä½¿ç”¨ä¸Šä¸€æ—¶åˆ»çš„å€¼
    
    Args:
        data: æ•°æ®æ•°ç»„ï¼Œå¯ä»¥æ˜¯ 1D æˆ– 2D
    
    Returns:
        å¤„ç†åçš„æ•°æ®æ•°ç»„
    """
    data_clean = data.copy()
    
    if len(data_clean.shape) == 1:
        # 1D æ•°ç»„
        for i in range(len(data_clean)):
            if np.isnan(data_clean[i]):
                if i == 0:
                    # ç¬¬ä¸€ä¸ªï¼šä½¿ç”¨ä¸‹ä¸€ä¸ªé NaN å€¼
                    for j in range(1, len(data_clean)):
                        if not np.isnan(data_clean[j]):
                            data_clean[i] = data_clean[j]
                            break
                elif i == len(data_clean) - 1:
                    # æœ€åä¸€ä¸ªï¼šä½¿ç”¨ä¸Šä¸€ä¸ªé NaN å€¼
                    for j in range(len(data_clean) - 2, -1, -1):
                        if not np.isnan(data_clean[j]):
                            data_clean[i] = data_clean[j]
                            break
                else:
                    # ä¸­é—´ï¼šä½¿ç”¨å‰ä¸€ä¸ªé NaN å€¼
                    for j in range(i - 1, -1, -1):
                        if not np.isnan(data_clean[j]):
                            data_clean[i] = data_clean[j]
                            break
    else:
        # 2D æ•°ç»„ï¼Œé€è¡Œå¤„ç†
        for i in range(len(data_clean)):
            if np.isnan(data_clean[i]).any():
                if i == 0:
                    # ç¬¬ä¸€ä¸ªï¼šä½¿ç”¨ä¸‹ä¸€ä¸ªé NaN å€¼
                    for j in range(1, len(data_clean)):
                        if not np.isnan(data_clean[j]).any():
                            data_clean[i] = data_clean[j]
                            break
                elif i == len(data_clean) - 1:
                    # æœ€åä¸€ä¸ªï¼šä½¿ç”¨ä¸Šä¸€ä¸ªé NaN å€¼
                    for j in range(len(data_clean) - 2, -1, -1):
                        if not np.isnan(data_clean[j]).any():
                            data_clean[i] = data_clean[j]
                            break
                else:
                    # ä¸­é—´ï¼šä½¿ç”¨å‰ä¸€ä¸ªé NaN å€¼
                    for j in range(i - 1, -1, -1):
                        if not np.isnan(data_clean[j]).any():
                            data_clean[i] = data_clean[j]
                            break
    
    return data_clean


def axisangle_to_quat(axis_angle):
    """
    axis_angle: (3,)
    return quat: (4,) in xyzw
    """
    return R.from_rotvec(axis_angle).as_quat()


def quat_to_axisangle(quat):
    """
    quat: (4,) xyzw
    return axis-angle: (3,)
    """
    return R.from_quat(quat).as_rotvec()


def relative_axisangle(aa_t, aa_t1):
    """
    Compute relative rotation from t -> t+1 in axis-angle
    """
    q_t = axisangle_to_quat(aa_t)
    q_t1 = axisangle_to_quat(aa_t1)

    # relative rotation: q_rel = q_t1 * inverse(q_t)
    q_rel = R.from_quat(q_t1) * R.from_quat(q_t).inv()
    return q_rel.as_rotvec()


def compute_geom_action(
    ee_pos_t,
    ee_ori_t,
    ee_pos_t1,
    ee_ori_t1,
):
    """
    All inputs are np.ndarray with shape (3,)
    ee_ori_* are axis-angle
    """
    delta_pos = ee_pos_t1 - ee_pos_t
    delta_ori = relative_axisangle(ee_ori_t, ee_ori_t1)

    action_6d = np.concatenate([delta_pos, delta_ori])
    return action_6d


def process_gripper_feedback(gripper_values: np.ndarray) -> np.ndarray:
    """
    å¤„ç†å¤¹çˆªåé¦ˆå€¼ï¼š
    - å°äº 0.4 â†’ 0ï¼ˆæ‰“å¼€ï¼‰
    - å¤§äº 0.6 â†’ 1ï¼ˆé—­åˆï¼‰
    - 0.4-0.6 ä¹‹é—´ â†’ ä¿æŒåŸå€¼æˆ–æ’å€¼
    
    Args:
        gripper_values: å¤¹çˆªåé¦ˆå€¼æ•°ç»„ (T,)
    
    Returns:
        å¤„ç†åçš„å¤¹çˆªçŠ¶æ€æ•°ç»„ (T,)
    """
    gripper_state = gripper_values.copy()
    
    # å¤„ç† NaN
    gripper_state = handle_nan_values(gripper_state)
    
    # åˆ¤æ–­å¤¹çˆªçŠ¶æ€
    gripper_binary = np.zeros_like(gripper_state)
    gripper_binary[gripper_state < 0.4] = 0.0
    gripper_binary[gripper_state > 0.6] = 1.0
    # 0.4-0.6 ä¹‹é—´ï¼šçº¿æ€§æ’å€¼
    mask_middle = (gripper_state >= 0.4) & (gripper_state <= 0.6)
    gripper_binary[mask_middle] = (gripper_state[mask_middle] - 0.4) / 0.2  # å½’ä¸€åŒ–åˆ° [0, 1]
    
    return gripper_binary


def load_pick_blue_bottle_hdf5(hdf5_path: Path, task_description: str = "Pick blue bottle and place it in blue plate", ignore_valid: bool = False, downsample_factor: int = 4) -> list[dict]:
    """
    ä» pick_blue_bottle HDF5 æ–‡ä»¶ä¸­åŠ è½½æ•°æ®ï¼ˆä¸‹é‡‡æ ·ç‰ˆæœ¬ï¼‰ã€‚
    
    ä½¿ç”¨å‡ ä½• action è®¡ç®—æ–¹å¼ï¼š
    - Action: 6ç»´ EEF action (xyzä½ç§» + è½´è§’æ—‹è½¬) + 1ç»´å¤¹çˆªçŠ¶æ€ = 7ç»´
    - State: 3ç»´EEFä½ç½® + 3ç»´EEFæ–¹å‘(è½´è§’) + 1ç»´å¤¹çˆªå€¼ + 1ç»´å¤¹çˆªå€¼ç›¸åæ•° = 8ç»´
    
    Args:
        hdf5_path: HDF5 æ–‡ä»¶è·¯å¾„
        task_description: ä»»åŠ¡æè¿°
        ignore_valid: æ˜¯å¦å¿½ç•¥æœ‰æ•ˆæ€§æ ‡è®°
        downsample_factor: ä¸‹é‡‡æ ·å› å­ï¼ˆæ¯Nå¸§å–1å¸§ï¼‰
    
    Returns:
        æ­¥éª¤åˆ—è¡¨ï¼Œæ¯ä¸ªæ­¥éª¤åŒ…å« image, wrist_image, state, action, task
    """
    with h5py.File(hdf5_path, "r") as f:
        # è¯»å– _info_eef_right æ•°æ®ï¼ˆç”¨äºè®¡ç®—å‡ ä½• actionï¼‰
        if "_info_eef_right" not in f["topics"]:
            raise KeyError("æ‰¾ä¸åˆ° _info_eef_right topic")
        
        eef_right_group = f["topics/_info_eef_right"]
        eef_positions = eef_right_group["position"][:]  # (T, 3)
        eef_orientations = eef_right_group["orientation"][:]  # (T, 4) - å››å…ƒæ•° [x, y, z, w]
        
        print(f"  âœ… è¯»å– _info_eef_right: position {eef_positions.shape}, orientation {eef_orientations.shape}")
        
        # å¤„ç† NaN
        eef_positions = handle_nan_values(eef_positions)
        eef_orientations = handle_nan_values(eef_orientations)
        
        # è½¬æ¢ä¸ºè½´è§’
        axis_angles = np.zeros((len(eef_orientations), 3))
        for i in range(len(eef_orientations)):
            quat = eef_orientations[i]  # [x, y, z, w]
            axis_angles[i] = quat_to_axisangle(quat)
        
        print(f"  âœ… è½¬æ¢ä¸ºè½´è§’: {axis_angles.shape}")
        
        # è¯»å–å…³èŠ‚çŠ¶æ€ï¼ˆç”¨äº stateï¼‰
        if "_joint_states" not in f["topics"]:
            raise KeyError("æ‰¾ä¸åˆ° _joint_states topic")
        
        joint_states = f["topics/_joint_states"]
        joint_positions = joint_states["position"][:]  # (T, 14)
        
        # è¯»å–ä¸»ç›¸æœºå›¾åƒ
        if "_camera_camera_color_image_raw" not in f["topics"]:
            raise KeyError("æ‰¾ä¸åˆ° _camera_camera_color_image_raw topic")
        
        image_topic = f["topics/_camera_camera_color_image_raw"]
        image_data = image_topic["data"][:]  # å¯èƒ½æ˜¯ (T, H, W, 3) æˆ– (T, 921600)
        
        # æ£€æŸ¥æ•°æ®æ ¼å¼ï¼šæ–°æ ¼å¼æ˜¯å·²è§£ç çš„å›¾åƒæ•°ç»„ï¼Œæ—§æ ¼å¼æ˜¯æ‰å¹³åŒ–çš„å­—èŠ‚æ•°æ®
        if len(image_data.shape) == 4:
            # æ–°æ ¼å¼ï¼šå·²ç»æ˜¯è§£ç åçš„å›¾åƒ (T, H, W, 3)
            image_lengths = None
            print("  âœ… æ£€æµ‹åˆ°æ–°æ ¼å¼ï¼šä¸»ç›¸æœºå›¾åƒå·²è§£ç ")
        else:
            # æ—§æ ¼å¼ï¼šæ‰å¹³åŒ–çš„å­—èŠ‚æ•°æ®ï¼Œéœ€è¦è§£ç 
            image_lengths = image_topic["data_length"][:]  # (T,)
            print("  âœ… æ£€æµ‹åˆ°æ—§æ ¼å¼ï¼šä¸»ç›¸æœºå›¾åƒéœ€è¦è§£ç ")
        
        # è¯»å–æ‰‹è…•ç›¸æœºå›¾åƒï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        wrist_image_data = None
        wrist_image_lengths = None
        has_wrist_camera = "image_wrist" in f["topics"]
        if has_wrist_camera:
            wrist_topic = f["topics/image_wrist"]
            wrist_image_data = wrist_topic["data"][:]  # å¯èƒ½æ˜¯ (T, H, W, 3) æˆ– (T, ...)
            if len(wrist_image_data.shape) == 4:
                # æ–°æ ¼å¼ï¼šå·²ç»æ˜¯è§£ç åçš„å›¾åƒ
                wrist_image_lengths = None
                print("  âœ… æ£€æµ‹åˆ°æ‰‹è…•ç›¸æœºæ•°æ®ï¼ˆæ–°æ ¼å¼ï¼‰")
            else:
                # æ—§æ ¼å¼ï¼šå¯èƒ½éœ€è¦è§£ç 
                if "data_length" in wrist_topic:
                    wrist_image_lengths = wrist_topic["data_length"][:]
                print("  âœ… æ£€æµ‹åˆ°æ‰‹è…•ç›¸æœºæ•°æ®ï¼ˆæ—§æ ¼å¼ï¼‰")
        else:
            print("  âš ï¸  æœªæ‰¾åˆ° image_wrist topicï¼Œå°†ä½¿ç”¨ä¸»ç›¸æœºå›¾åƒä½œä¸ºæ‰‹è…•å›¾åƒ")
        
        # è¯»å–æœ‰æ•ˆæ€§æ ‡è®°ï¼ˆå¦‚æœæœ‰ï¼‰
        valid = None
        if not ignore_valid and "valid" in f:
            # ä¼˜å…ˆä½¿ç”¨ joint_states çš„æœ‰æ•ˆæ€§ï¼Œå¦‚æœå›¾åƒä¹Ÿæœ‰æ•ˆåˆ™æ›´å¥½
            if "_joint_states" in f["valid"]:
                valid_joint = f["valid/_joint_states"][:]  # (T,)
            else:
                valid_joint = None
            
            if "_camera_camera_color_image_raw" in f["valid"]:
                valid_image = f["valid/_camera_camera_color_image_raw"][:]  # (T,)
            else:
                valid_image = None
            
            # å¦‚æœå­˜åœ¨æ‰‹è…•ç›¸æœºï¼Œä¹Ÿæ£€æŸ¥å…¶æœ‰æ•ˆæ€§
            valid_wrist = None
            if has_wrist_camera and "image_wrist" in f.get("valid", {}):
                valid_wrist = f["valid/image_wrist"][:]  # (T,)
            
            # ç»„åˆæœ‰æ•ˆæ€§ï¼šjoint_states å¿…é¡»æœ‰æ•ˆï¼Œä¸»ç›¸æœºå’Œæ‰‹è…•ç›¸æœºï¼ˆå¦‚æœå­˜åœ¨ï¼‰ä¹Ÿåº”è¯¥æœ‰æ•ˆ
            valid_list = [v for v in [valid_joint, valid_image, valid_wrist] if v is not None]
            if valid_list:
                valid = valid_list[0]
                for v in valid_list[1:]:
                    valid = valid & v
            elif valid_joint is not None:
                valid = valid_joint
            elif valid_image is not None:
                valid = valid_image
        
        # ç¡®ä¿æ‰€æœ‰æ•°æ®é•¿åº¦ä¸€è‡´
        min_length = min(len(eef_positions), len(joint_positions), len(image_data))
        if wrist_image_data is not None:
            min_length = min(min_length, len(wrist_image_data))
        
        if valid is not None and not ignore_valid:
            # åªä½¿ç”¨æœ‰æ•ˆçš„æ­¥éª¤
            valid_indices = np.where(valid[:min_length])[0]
        else:
            valid_indices = np.arange(min_length)
        
        if len(valid_indices) == 0:
            raise ValueError("æ²¡æœ‰æœ‰æ•ˆçš„æ•°æ®æ­¥éª¤")
        
        # è¯»å–å³å¤¹çˆªåé¦ˆæ•°æ®ï¼ˆä» _gripper_feedback_Rï¼‰
        # ç¬¬ä¸€åˆ—ï¼ˆç´¢å¼•0ï¼‰å°±æ˜¯å¤¹çˆªçŠ¶æ€å€¼
        right_gripper_feedback = None
        if "_gripper_feedback_R" in f["topics"]:
            gripper_feedback_group = f["topics/_gripper_feedback_R"]
            if "data" in gripper_feedback_group:
                gripper_feedback_data = gripper_feedback_group["data"][:]  # (T, 5)
                print(f"  ğŸ“Š åŸå§‹å¤¹çˆªåé¦ˆæ•°æ® shape: {gripper_feedback_data.shape}")
                # å–ç¬¬ä¸€åˆ—ï¼ˆç´¢å¼•0ï¼‰ä½œä¸ºå¤¹çˆªçŠ¶æ€å€¼
                if len(gripper_feedback_data.shape) > 1:
                    gripper_feedback_data = gripper_feedback_data[:, 0]  # å–ç¬¬ä¸€åˆ—
                else:
                    gripper_feedback_data = gripper_feedback_data  # å·²ç»æ˜¯1D
                # å…ˆè¿‡æ»¤æœ‰æ•ˆç´¢å¼•
                gripper_feedback_data = gripper_feedback_data[valid_indices]
                right_gripper_feedback = gripper_feedback_data
                print(f"  âœ… è¯»å–å³å¤¹çˆªåé¦ˆæ•°æ®ï¼ˆç¬¬ä¸€åˆ—ï¼‰: {len(right_gripper_feedback)} ä¸ªå€¼ï¼ˆè¿‡æ»¤åï¼‰")
                print(f"  ğŸ“Š å¤¹çˆªå€¼èŒƒå›´: [{np.nanmin(right_gripper_feedback):.6f}, {np.nanmax(right_gripper_feedback):.6f}]")
            else:
                print("  âš ï¸  å¤¹çˆªåé¦ˆè¯é¢˜ä¸­æ²¡æœ‰ 'data' é”®")
                print(f"  ğŸ“‹ å¯ç”¨é”®: {list(gripper_feedback_group.keys())}")
        else:
            print("  âš ï¸  æœªæ‰¾åˆ° _gripper_feedback_R è¯é¢˜")
            print(f"  ğŸ“‹ å¯ç”¨ topics: {list(f['topics'].keys())[:10]}...")  # åªæ˜¾ç¤ºå‰10ä¸ª
        
        # æå–æœ‰æ•ˆæ•°æ®
        eef_positions = eef_positions[valid_indices]
        eef_orientations = eef_orientations[valid_indices]
        axis_angles = axis_angles[valid_indices]
        joint_positions = joint_positions[valid_indices]
        image_data = image_data[valid_indices]
        if image_lengths is not None:
            image_lengths = image_lengths[valid_indices]
        
        # æå–æ‰‹è…•ç›¸æœºæ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if wrist_image_data is not None:
            wrist_image_data = wrist_image_data[valid_indices]
            if wrist_image_lengths is not None:
                wrist_image_lengths = wrist_image_lengths[valid_indices]
        
        # ä¸‹é‡‡æ ·ï¼šæ¯ downsample_factor å¸§å–1å¸§
        downsampled_indices = np.arange(0, len(eef_positions), downsample_factor)
        eef_positions = eef_positions[downsampled_indices]
        eef_orientations = eef_orientations[downsampled_indices]
        axis_angles = axis_angles[downsampled_indices]
        joint_positions = joint_positions[downsampled_indices]
        image_data = image_data[downsampled_indices]
        if image_lengths is not None:
            image_lengths = image_lengths[downsampled_indices]
        
        # ä¸‹é‡‡æ ·æ‰‹è…•ç›¸æœºæ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if wrist_image_data is not None:
            wrist_image_data = wrist_image_data[downsampled_indices]
            if wrist_image_lengths is not None:
                wrist_image_lengths = wrist_image_lengths[downsampled_indices]
        
        # ä¸‹é‡‡æ ·å¤¹çˆªåé¦ˆæ•°æ®ï¼ˆä¸å…³èŠ‚æ•°æ®åŒæ­¥ï¼‰
        if right_gripper_feedback is not None:
            right_gripper_feedback = right_gripper_feedback[downsampled_indices]
            print(f"  âœ… ä¸‹é‡‡æ ·åå³å¤¹çˆªåé¦ˆæ•°æ®: {len(right_gripper_feedback)} ä¸ªå€¼")
        else:
            # å¦‚æœå¤¹çˆªæ•°æ®ä¸å¯ç”¨ï¼Œåˆ›å»ºé›¶æ•°ç»„
            right_gripper_feedback = np.zeros(len(eef_positions))
            print("  âš ï¸  ä½¿ç”¨é›¶å¤¹çˆªå€¼ï¼ˆæœªæ‰¾åˆ°å¤¹çˆªæ•°æ®ï¼‰")
        
        # è§£ç ä¸»ç›¸æœºå›¾åƒ
        print(f"  å¤„ç† {len(downsampled_indices)} å¼ ä¸»ç›¸æœºå›¾åƒï¼ˆä¸‹é‡‡æ · {downsample_factor}xï¼‰...")
        if len(image_data.shape) == 4:
            # æ–°æ ¼å¼ï¼šå·²ç»æ˜¯è§£ç åçš„å›¾åƒæ•°ç»„ (T, H, W, 3)
            # æ³¨æ„ï¼šHDF5ä¸­å­˜å‚¨çš„å¯èƒ½æ˜¯BGRæ ¼å¼ï¼Œéœ€è¦è½¬æ¢ä¸ºRGB
            images = image_data.astype(np.uint8)
            # è½¬æ¢BGRåˆ°RGBï¼ˆäº¤æ¢é€šé“é¡ºåºï¼‰
            images = images[..., ::-1]  # åè½¬æœ€åä¸€ä¸ªç»´åº¦ (BGR -> RGB)
            print(f"  âœ… ä¸»ç›¸æœºå›¾åƒå·²è§£ç å¹¶è½¬æ¢ä¸ºRGBï¼Œå½¢çŠ¶: {images.shape}")
        else:
            # æ—§æ ¼å¼ï¼šéœ€è¦è§£ç æ‰å¹³åŒ–çš„å­—èŠ‚æ•°æ®
            images = []
            for i in tqdm(range(len(downsampled_indices)), desc="  è§£ç ä¸»ç›¸æœºå›¾åƒ", leave=False):
                try:
                    img = decode_image(image_data[i], image_lengths[i])
                    images.append(img)
                except Exception as e:
                    print(f"  âš ï¸  è§£ç ä¸»ç›¸æœºå›¾åƒ {i} å¤±è´¥: {e}ï¼Œä½¿ç”¨é›¶å›¾åƒ")
                    # ä½¿ç”¨é›¶å›¾åƒä½œä¸ºå ä½ç¬¦
                    images.append(np.zeros((480, 640, 3), dtype=np.uint8))
            images = np.array(images)
        
        # è§£ç æ‰‹è…•ç›¸æœºå›¾åƒï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        wrist_images = None
        if wrist_image_data is not None:
            print(f"  å¤„ç† {len(downsampled_indices)} å¼ æ‰‹è…•ç›¸æœºå›¾åƒï¼ˆä¸‹é‡‡æ · {downsample_factor}xï¼‰...")
            if len(wrist_image_data.shape) == 4:
                # æ–°æ ¼å¼ï¼šå·²ç»æ˜¯è§£ç åçš„å›¾åƒæ•°ç»„ (T, H, W, 3)
                # æ³¨æ„ï¼šHDF5ä¸­å­˜å‚¨çš„å¯èƒ½æ˜¯BGRæ ¼å¼ï¼Œéœ€è¦è½¬æ¢ä¸ºRGB
                wrist_images = wrist_image_data.astype(np.uint8)
                # è½¬æ¢BGRåˆ°RGBï¼ˆäº¤æ¢é€šé“é¡ºåºï¼‰
                wrist_images = wrist_images[..., ::-1]  # åè½¬æœ€åä¸€ä¸ªç»´åº¦ (BGR -> RGB)
                print(f"  âœ… æ‰‹è…•ç›¸æœºå›¾åƒå·²è§£ç å¹¶è½¬æ¢ä¸ºRGBï¼Œå½¢çŠ¶: {wrist_images.shape}")
            else:
                # æ—§æ ¼å¼ï¼šéœ€è¦è§£ç æ‰å¹³åŒ–çš„å­—èŠ‚æ•°æ®
                wrist_images = []
                for i in tqdm(range(len(downsampled_indices)), desc="  è§£ç æ‰‹è…•ç›¸æœºå›¾åƒ", leave=False):
                    try:
                        if wrist_image_lengths is not None:
                            img = decode_image(wrist_image_data[i], wrist_image_lengths[i])
                        else:
                            # å¦‚æœæ²¡æœ‰ data_lengthï¼Œå°è¯•ç›´æ¥è§£ç 
                            img = decode_image(wrist_image_data[i], len(wrist_image_data[i]))
                        wrist_images.append(img)
                    except Exception as e:
                        print(f"  âš ï¸  è§£ç æ‰‹è…•ç›¸æœºå›¾åƒ {i} å¤±è´¥: {e}ï¼Œä½¿ç”¨é›¶å›¾åƒ")
                        # ä½¿ç”¨é›¶å›¾åƒä½œä¸ºå ä½ç¬¦
                        wrist_images.append(np.zeros((480, 640, 3), dtype=np.uint8))
                wrist_images = np.array(wrist_images)
        
        # æå–å³è‡‚å…³èŠ‚ï¼ˆåˆ— 7-13ï¼Œå¯¹åº” Joint1_R åˆ° Joint7_Rï¼‰
        # æ³¨æ„ï¼šjoint_states æœ‰14ç»´ï¼šå‰7ç»´æ˜¯å·¦è‡‚ï¼ˆJoint1_L åˆ° Joint7_Lï¼‰ï¼Œå7ç»´æ˜¯å³è‡‚ï¼ˆJoint1_R åˆ° Joint7_Rï¼‰
        right_joint_positions = joint_positions[:, 7:14]  # (T, 7) - å³è‡‚å…³èŠ‚ä½ç½®
        
        # å¤„ç†å…³èŠ‚ä½ç½®çš„ NaN
        right_joint_positions = handle_nan_values(right_joint_positions)
        print(f"  âœ… å¤„ç†åçš„å³è‡‚å…³èŠ‚ä½ç½®: {right_joint_positions.shape}")
        
        # è®¡ç®—å‡ ä½• actionï¼ˆä» EEF ä½ç½®å’Œæ–¹å‘è®¡ç®—ï¼‰
        print("  ğŸ”„ è®¡ç®—å‡ ä½• action...")
        eef_actions = np.zeros((len(eef_positions) - 1, 6))  # (T-1, 6)
        
        for i in range(len(eef_positions) - 1):
            ee_pos_t = eef_positions[i]
            ee_ori_t = axis_angles[i]
            ee_pos_t1 = eef_positions[i + 1]
            ee_ori_t1 = axis_angles[i + 1]
            
            action_6d = compute_geom_action(ee_pos_t, ee_ori_t, ee_pos_t1, ee_ori_t1)
            eef_actions[i] = action_6d
        
        # æœ€åä¸€ä¸ª action åº”è¯¥æ˜¯å…¨ 0ï¼ˆä¸åŠ¨ï¼‰
        last_action = np.zeros((1, 6))
        eef_actions = np.concatenate([eef_actions, last_action], axis=0)  # (T, 6)
        
        print(f"  âœ… EEF action ç»´åº¦: {eef_actions.shape} (6ç»´: xyzä½ç§» + è½´è§’æ—‹è½¬)")
        
        # å¤„ç†å¤¹çˆªåé¦ˆæ•°æ®
        # State çš„å¤¹çˆªéƒ¨åˆ†ï¼šç›´æ¥ä½¿ç”¨åŸå§‹çš„ç¬¬ä¸€ç»´æ•°å€¼ï¼ˆåªå¤„ç† NaNï¼‰
        gripper_states_for_state = right_gripper_feedback.copy()
        # å¤„ç† NaN å€¼
        gripper_states_for_state = handle_nan_values(gripper_states_for_state)
        print(f"  âœ… å¤¹çˆªçŠ¶æ€ï¼ˆåŸå§‹å€¼ï¼Œç”¨äº stateï¼‰: {gripper_states_for_state.shape}, èŒƒå›´ [{np.nanmin(gripper_states_for_state):.6f}, {np.nanmax(gripper_states_for_state):.6f}]")
        
        # Action çš„å¤¹çˆªéƒ¨åˆ†ï¼šè¯»å–åä¸€ä¸ªæ—¶åˆ»çš„ gripper å€¼
        # å°äºç­‰äº 0.4 å°±æ˜¯ 0ï¼Œå¤§äº 0.4 å°±æ˜¯ 1
        gripper_actions = np.zeros(len(gripper_states_for_state), dtype=np.float32)
        for i in range(len(gripper_states_for_state) - 1):
            # è¯»å–åä¸€ä¸ªæ—¶åˆ»çš„ gripper å€¼
            next_gripper = gripper_states_for_state[i + 1]
            if next_gripper <= 0.4:
                gripper_actions[i] = 0.0
            else:
                gripper_actions[i] = 1.0
        # æœ€åä¸€ä¸ªæ—¶é—´æ­¥æ²¡æœ‰åä¸€ä¸ªæ—¶åˆ»ï¼Œaction ä¸º 0ï¼ˆä¸åŠ¨ï¼‰
        gripper_actions[-1] = 0.0
        print(f"  âœ… å¤¹çˆª action: {gripper_actions.shape}, èŒƒå›´ [{np.min(gripper_actions):.2f}, {np.max(gripper_actions):.2f}]")
        print(f"  ğŸ“Š å¤¹çˆª action ç»Ÿè®¡: 0 çš„æ•°é‡={np.sum(gripper_actions == 0)}, 1 çš„æ•°é‡={np.sum(gripper_actions == 1)}")
        
        # ç»„åˆ actionï¼ˆ6ç»´ EEF action + 1ç»´å¤¹çˆª actionï¼‰ = 7ç»´
        actions = np.concatenate([eef_actions, gripper_actions[:, None]], axis=1)  # (T, 7)
        print(f"  âœ… æœ€ç»ˆ action ç»´åº¦: {actions.shape} (6ç»´ EEF + 1ç»´å¤¹çˆª)")
        
        # ç»„åˆ stateï¼ˆ3ç»´EEFä½ç½® + 3ç»´EEFæ–¹å‘(è½´è§’) + 1ç»´å¤¹çˆªå€¼ + 1ç»´å¤¹çˆªå€¼ç›¸åæ•°ï¼‰ = 8ç»´
        # State çš„å¤¹çˆªéƒ¨åˆ†ç›´æ¥ä½¿ç”¨ _gripper_feedback_R çš„ç¬¬ä¸€ç»´åŸå§‹æ•°å€¼åŠå…¶ç›¸åæ•°
        states = np.concatenate([
            eef_positions,  # (T, 3) - EEFä½ç½®
            axis_angles,    # (T, 3) - EEFæ–¹å‘(è½´è§’)
            gripper_states_for_state[:, None],  # (T, 1) - å¤¹çˆªå€¼
            -gripper_states_for_state[:, None],  # (T, 1) - å¤¹çˆªå€¼ç›¸åæ•°
        ], axis=1)  # (T, 8)
        print(f"  âœ… æœ€ç»ˆ state ç»´åº¦: {states.shape} (3ç»´EEFä½ç½® + 3ç»´EEFæ–¹å‘ + 1ç»´å¤¹çˆªå€¼ + 1ç»´å¤¹çˆªå€¼ç›¸åæ•°)")
        
        # ç¡®ä¿æ‰€æœ‰æ•°æ®é•¿åº¦ä¸€è‡´
        assert len(actions) == len(states) == len(images), \
            f"æ•°æ®é•¿åº¦ä¸ä¸€è‡´: actions={len(actions)}, states={len(states)}, images={len(images)}"
        
        # å»æ‰å¼€å§‹å’Œæœ€åçš„2å¸§ï¼ˆæ€»å…±å»æ‰4å¸§ï¼‰
        trim_frames = 2
        if len(states) <= trim_frames * 2:
            print(f"  âš ï¸  è­¦å‘Šï¼šæ•°æ®é•¿åº¦ ({len(states)}) ä¸è¶³ä»¥å»æ‰ {trim_frames * 2} å¸§ï¼Œè·³è¿‡ä¿®å‰ª")
        else:
            print(f"  âœ‚ï¸  å»æ‰å¼€å§‹å’Œæœ€åçš„å„ {trim_frames} å¸§ï¼ˆæ€»å…± {trim_frames * 2} å¸§ï¼‰")
            print(f"     ä¿®å‰ªå‰: {len(states)} å¸§")
            # å»æ‰å‰2å¸§å’Œå2å¸§
            states = states[trim_frames:-trim_frames]
            actions = actions[trim_frames:-trim_frames]
            images = images[trim_frames:-trim_frames]
            if wrist_images is not None:
                wrist_images = wrist_images[trim_frames:-trim_frames]
            print(f"     ä¿®å‰ªå: {len(states)} å¸§")
        
        # è½¬æ¢ä¸ºæ­¥éª¤åˆ—è¡¨
        steps = []
        for i in range(len(states)):
            # è°ƒæ•´ä¸»ç›¸æœºå›¾åƒå¤§å°
            image = resize_image(images[i], (256, 256))
            
            # --- ğŸ›¡ï¸ ç¡®ä¿å›¾åƒæ˜¯ uint8 ä¸”ä¸éœ€è¦é¢å¤–ç¼©æ”¾ ---
            if image.dtype != np.uint8:
                if image.max() <= 1.0:
                    image = (image * 255).astype(np.uint8)
                else:
                    image = image.astype(np.uint8)
            else:
                image = image.astype(np.uint8)
            
            # å¤„ç†æ‰‹è…•ç›¸æœºå›¾åƒ
            if wrist_images is not None:
                # ä½¿ç”¨çœŸå®çš„æ‰‹è…•ç›¸æœºå›¾åƒ
                wrist_image = resize_image(wrist_images[i], (256, 256))
                if wrist_image.dtype != np.uint8:
                    if wrist_image.max() <= 1.0:
                        wrist_image = (wrist_image * 255).astype(np.uint8)
                    else:
                        wrist_image = wrist_image.astype(np.uint8)
                else:
                    wrist_image = wrist_image.astype(np.uint8)
            else:
                # å¦‚æœæ²¡æœ‰æ‰‹è…•ç›¸æœºï¼Œä½¿ç”¨ä¸»ç›¸æœºï¼ˆå‘åå…¼å®¹ï¼‰
                wrist_image = image.copy()
            
            steps.append({
                "image": image,
                "wrist_image": wrist_image,
                "state": states[i].astype(np.float32),
                "action": actions[i].astype(np.float32),
                "task": task_description,
            })
        
        return steps


def main(
    data_dir: str,
    *,
    push_to_hub: bool = False,
    task_description: str = "Pick blue bottle and place it in blue plate",
    ignore_valid: bool = False,
    downsample_factor: int = 4,
    fps: float = 7.5,  # åŸå§‹30fpsä¸‹é‡‡æ ·4å€åä¸º7.5fps
):
    """
    ä¸»å‡½æ•°ï¼šå°† pick_blue_bottle HDF5 æ ¼å¼æ•°æ®è½¬æ¢ä¸º LeRobot æ ¼å¼ï¼ˆä¸‹é‡‡æ ·4å€ç‰ˆæœ¬ï¼‰
    
    Args:
        data_dir: HDF5 æ–‡ä»¶æ‰€åœ¨çš„ç›®å½•
        push_to_hub: æ˜¯å¦æ¨é€åˆ° Hugging Face Hub
        task_description: ä»»åŠ¡æè¿°
        ignore_valid: æ˜¯å¦å¿½ç•¥æœ‰æ•ˆæ€§æ ‡è®°ï¼Œä½¿ç”¨æ‰€æœ‰æ•°æ®
        downsample_factor: ä¸‹é‡‡æ ·å› å­ï¼ˆæ¯Nå¸§å–1å¸§ï¼‰
        fps: è¾“å‡ºæ•°æ®é›†çš„å¸§ç‡ï¼ˆåŸå§‹30fpsä¸‹é‡‡æ ·4å€åä¸º7.5fpsï¼‰
    """
    data_dir = Path(data_dir)
    
    # æ¸…ç†è¾“å‡ºç›®å½•
    output_path = HF_LEROBOT_HOME / REPO_NAME
    if output_path.exists():
        shutil.rmtree(output_path)
    
    # åˆ›å»º LeRobot æ•°æ®é›†
    dataset = LeRobotDataset.create(
        repo_id=REPO_NAME,
        robot_type="panda",
        fps=fps,  # ä¸‹é‡‡æ ·åçš„å¸§ç‡
        features={
            "image": {
                "dtype": "image",
                "shape": (256, 256, 3),
                "names": ["height", "width", "channel"],
            },
            "wrist_image": {
                "dtype": "image",
                "shape": (256, 256, 3),
                "names": ["height", "width", "channel"],
            },
            "state": {
                "dtype": "float32",
                "shape": (8,),
                "names": ["state"],
            },
            "actions": {
                "dtype": "float32",
                "shape": (7,),  # 7 ç»´åŠ¨ä½œï¼ˆ6ç»´ EEF action + 1ç»´å¤¹çˆª actionï¼‰
                "names": ["actions"],
            },
        },
        image_writer_threads=10,
        image_writer_processes=5,
    )
    
    # æŸ¥æ‰¾æ‰€æœ‰ HDF5 æ–‡ä»¶ï¼ˆé€’å½’æœç´¢å­ç›®å½•ï¼‰
    hdf5_files = sorted(
        list(data_dir.glob("**/*.h5")) + list(data_dir.glob("**/*.hdf5"))
    )
    if not hdf5_files:
        raise FileNotFoundError(f"åœ¨ç›®å½• '{data_dir}' åŠå…¶å­ç›®å½•ä¸­æ‰¾ä¸åˆ°ä»»ä½• .h5 æˆ– .hdf5 æ–‡ä»¶")
    
    print(f"æ‰¾åˆ° {len(hdf5_files)} ä¸ª HDF5 æ–‡ä»¶")
    print(f"ä¸‹é‡‡æ ·å› å­: {downsample_factor}x")
    print(f"è¾“å‡ºå¸§ç‡: {fps} fps")
    
    # éå†æ‰€æœ‰ HDF5 æ–‡ä»¶
    total_steps = 0
    for hdf5_path in tqdm(hdf5_files, desc="å¤„ç† HDF5 æ–‡ä»¶"):
        try:
            steps = load_pick_blue_bottle_hdf5(hdf5_path, task_description, ignore_valid, downsample_factor)
            
            # å†™å…¥ LeRobot æ•°æ®é›†
            # ç›´æ¥ä½¿ç”¨ step ä¸­çš„æ•°æ®ï¼Œå› ä¸º load å‡½æ•°é‡Œå·²ç»å¤„ç†å¥½äº†
            for step in steps:
                dataset.add_frame({
                    "image": step["image"],           # å·²ç»æ˜¯å¤„ç†å¥½çš„ uint8
                    "wrist_image": step["wrist_image"], # å·²ç»æ˜¯å¤„ç†å¥½çš„ uint8
                    "state": step["state"].astype(np.float32),
                    "actions": step["action"].astype(np.float32),
                    "task": step["task"],
                })
            
            dataset.save_episode()
            total_steps += len(steps)
            print(f"âœ… æˆåŠŸè½¬æ¢ {hdf5_path.name} ({len(steps)} æ­¥ï¼Œä¸‹é‡‡æ · {downsample_factor}x)")
            
        except Exception as e:
            print(f"âŒ å¤„ç† {hdf5_path} æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    print(f"\nâœ… è½¬æ¢å®Œæˆï¼æ€»å…± {total_steps} æ­¥ï¼ˆä¸‹é‡‡æ · {downsample_factor}xï¼‰")
    print(f"æ•°æ®é›†ä¿å­˜åœ¨: {output_path}")
    
    # å¯é€‰ï¼šæ¨é€åˆ° Hugging Face Hub
    if push_to_hub:
        print("\næ¨é€åˆ° Hugging Face Hub...")
        dataset.push_to_hub(
            tags=["libero", "panda", "downsampled"],
            private=False,
            push_videos=True,
            license="apache-2.0",
        )
        print(f"âœ… å·²æ¨é€åˆ° Hub: {REPO_NAME}")


if __name__ == "__main__":
    tyro.cli(main)

