"""
è½¬æ¢ pick_blue_bottle æ•°æ®é›†çš„ HDF5 æ ¼å¼æ•°æ®åˆ° LeRobot æ ¼å¼ï¼ˆä¸‹é‡‡æ ·4å€ç‰ˆæœ¬ï¼Œå»æ‰NaNå€¼ï¼‰ã€‚

è¿™ä¸ªè„šæœ¬ä¸“é—¨ç”¨äºå¤„ç† pick_blue_bottle æ•°æ®é›†çš„ HDF5 æ–‡ä»¶ï¼Œå¹¶å°†æ•°æ®ä¸‹é‡‡æ ·4å€ã€‚
åªä½¿ç”¨å³è‡‚æ•°æ®ï¼ˆå·¦è‡‚æœªä½¿ç”¨ï¼‰ï¼Œå¹¶åŒ…å«å³å¤¹çˆªä¿¡æ¯ã€‚
**å…³é”®åŒºåˆ«ï¼šé‡åˆ°NaNå€¼ç›´æ¥åˆ é™¤ï¼Œè€Œä¸æ˜¯å¡«å……0**

HDF5 æ–‡ä»¶ç»“æ„:
- time: (T,) æ—¶é—´æˆ³
- topics/_joint_states/:
    - position: (T, 14) å…³èŠ‚ä½ç½®ï¼ˆå‰7ç»´=å·¦è‡‚ï¼Œå7ç»´=å³è‡‚ï¼‰
    - velocity: (T, 14) å…³èŠ‚é€Ÿåº¦ï¼ˆå‰7ç»´=å·¦è‡‚ï¼Œå7ç»´=å³è‡‚ï¼‰
- topics/_control_gripperValueR/:
    - data: (T,) å³å¤¹çˆªå€¼ï¼ˆ0=å…¨å¼€ï¼Œ1=å…¨é—­ï¼‰
- topics/_camera_camera_color_image_raw/:
    - data: (T, 921600) å›¾åƒæ•°æ®ï¼ˆæ‰å¹³åŒ–ï¼‰
    - data_length: (T,) æ¯ä¸ªå›¾åƒçš„å®é™…é•¿åº¦

è¾“å‡ºæ•°æ®:
- çŠ¶æ€: [7ä¸ªå³è‡‚å…³èŠ‚ä½ç½®, 1ä¸ªå³å¤¹çˆªå€¼] = 8ç»´
- åŠ¨ä½œ: [7ä¸ªå³è‡‚å…³èŠ‚é€Ÿåº¦, 1ä¸ªå³å¤¹çˆªé€Ÿåº¦] = 8ç»´ï¼ˆåŒ…å«gripperï¼‰
  - å…³èŠ‚åŠ¨ä½œ = velocity (rad/s)
  - gripperåŠ¨ä½œ = gripperé€Ÿåº¦ (å˜åŒ–ç‡)
  - æ³¨æ„ï¼šè®­ç»ƒæ—¶éœ€è¦ä½¿ç”¨ q_next = q_curr + velocity * dtï¼Œå…¶ä¸­ dt = 1/fps
- **NaNå€¼å¤„ç†ï¼šç›´æ¥åˆ é™¤åŒ…å«NaNçš„æ—¶é—´æ­¥**

Usage:
uv run examples/libero/convert_pick_blue_bottle_hdf5_to_lerobot_downsample4x_no_nan.py --data_dir /path/to/pick_blue_bottle_extracted
"""

import shutil
from pathlib import Path

import h5py
import numpy as np
from lerobot.common.datasets.lerobot_dataset import HF_LEROBOT_HOME
from lerobot.common.datasets.lerobot_dataset import LeRobotDataset
from PIL import Image
from tqdm import tqdm
import tyro

REPO_NAME = "your_hf_username/pick_blue_bottle_libero_downsample4x_no_nan"  # è¾“å‡ºæ•°æ®é›†åç§°ï¼ˆå»æ‰NaNç‰ˆæœ¬ï¼‰


def decode_image(img_data: np.ndarray, img_length: int) -> np.ndarray:
    """
    è§£ç å›¾åƒæ•°æ®ã€‚
    
    å›¾åƒæ•°æ®å¯èƒ½æ˜¯ï¼š
    1. JPEG å‹ç¼©æ ¼å¼ï¼ˆéœ€è¦è§£ç ï¼‰
    2. åŸå§‹ RGB å›¾åƒæ•°æ®ï¼ˆéœ€è¦é‡å¡‘ï¼‰
    
    Args:
        img_data: å›¾åƒæ•°æ®æ•°ç»„ï¼ˆæ‰å¹³åŒ–ï¼‰
        img_length: å›¾åƒæ•°æ®çš„å®é™…é•¿åº¦
    
    Returns:
        è§£ç åçš„å›¾åƒ (H, W, 3) uint8
    """
    img_bytes = bytes(img_data[:img_length])
    
    # ä¼˜å…ˆå°è¯•ä½œä¸º JPEG è§£ç ï¼ˆæœ€å¸¸è§ï¼‰
    try:
        import cv2
        nparr = np.frombuffer(img_bytes, np.uint8)
        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img is not None:
            # OpenCV è¿”å› BGRï¼Œè½¬æ¢ä¸º RGB
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            return img
    except ImportError:
        # å¦‚æœæ²¡æœ‰ OpenCVï¼Œå°è¯•ç”¨ PIL
        try:
            from io import BytesIO
            img = Image.open(BytesIO(img_bytes))
            if img.mode != 'RGB':
                img = img.convert('RGB')
            return np.array(img)
        except:
            pass
    except:
        # OpenCV è§£ç å¤±è´¥ï¼Œå°è¯•å…¶ä»–æ–¹æ³•
        pass
    
    # å¦‚æœä¸æ˜¯ JPEGï¼Œå°è¯•ä½œä¸ºåŸå§‹å›¾åƒæ•°æ®
    # å°è¯•å¸¸è§çš„å°ºå¯¸
    possible_sizes = [
        (720, 1280, 1),  # å•é€šé“
        (480, 640, 3),   # RGB
        (480, 854, 3),   # RGB
        (360, 640, 3),   # RGB
    ]
    
    for h, w, c in possible_sizes:
        if h * w * c == img_length:
            img = np.frombuffer(img_bytes, dtype=np.uint8).reshape(h, w, c)
            if c == 1:
                # å•é€šé“è½¬ RGB
                img = np.repeat(img, 3, axis=2)
            return img
    
    # å¦‚æœéƒ½ä¸åŒ¹é…ï¼Œå°è¯•ç›´æ¥é‡å¡‘ä¸º 640x480x3ï¼ˆæœ€å¸¸è§ï¼‰
    if img_length >= 640 * 480 * 3:
        img = np.frombuffer(img_bytes[:640*480*3], dtype=np.uint8).reshape(480, 640, 3)
        return img
    
    raise ValueError(f"æ— æ³•è§£ç å›¾åƒæ•°æ®ï¼Œé•¿åº¦: {img_length}")


def resize_image(image: np.ndarray, target_size: tuple[int, int] = (256, 256)) -> np.ndarray:
    """è°ƒæ•´å›¾åƒå¤§å°åˆ°ç›®æ ‡å°ºå¯¸"""
    if image.shape[:2] == target_size:
        return image
    img = Image.fromarray(image)
    img = img.resize(target_size, resample=Image.BICUBIC)
    return np.array(img)


def compute_actions_from_states(positions: np.ndarray, velocities: np.ndarray | None) -> np.ndarray:
    """
    ä»å…³èŠ‚ä½ç½®å’Œé€Ÿåº¦è®¡ç®—åŠ¨ä½œã€‚
    
    å¯¹äº LIBEROï¼Œé€šå¸¸ä½¿ç”¨ä½ç½®å¢é‡ï¼ˆdeltaï¼‰æˆ–é€Ÿåº¦ä½œä¸ºåŠ¨ä½œã€‚
    è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨é€Ÿåº¦ä½œä¸ºåŠ¨ä½œï¼ˆå¦‚æœå¯ç”¨ä¸”æœ‰æ•ˆï¼‰ï¼Œå¦åˆ™ä½¿ç”¨ä½ç½®å·®åˆ†ã€‚
    
    Args:
        positions: å…³èŠ‚ä½ç½®æ•°ç»„ (T, 7)
        velocities: å…³èŠ‚é€Ÿåº¦æ•°ç»„ (T, 7) æˆ– None
    
    Returns:
        åŠ¨ä½œæ•°ç»„ (T, 7)
    """
    # æ£€æŸ¥é€Ÿåº¦æ˜¯å¦æœ‰æ•ˆï¼ˆé Noneã€éç©ºã€éå…¨ NaNã€éå…¨é›¶ï¼‰
    if velocities is not None and len(velocities) > 0:
        if not np.isnan(velocities).any() and np.any(np.abs(velocities) > 1e-6):
            # é€Ÿåº¦æœ‰æ•ˆï¼Œä½¿ç”¨é€Ÿåº¦ä½œä¸ºåŠ¨ä½œ
            return velocities
    
    # é€Ÿåº¦æ— æ•ˆæˆ–ä¸å¯ç”¨ï¼Œä½¿ç”¨ä½ç½®å·®åˆ†ä½œä¸ºåŠ¨ä½œ
    # np.diff è®¡ç®—ç›¸é‚»å¸§ä¹‹é—´çš„ä½ç½®å·®
    # prepend ç¡®ä¿ç¬¬ä¸€å¸§çš„åŠ¨ä½œä¸º 0ï¼ˆæˆ–ä½¿ç”¨ç¬¬ä¸€å¸§çš„ä½ç½®ä½œä¸ºåˆå§‹å€¼ï¼‰
    actions = np.diff(positions, axis=0, prepend=positions[0:1])
    return actions


def load_pick_blue_bottle_hdf5(hdf5_path: Path, task_description: str = "Pick blue bottle and place it in blue plate", ignore_valid: bool = False, downsample_factor: int = 4) -> list[dict]:
    """
    ä» pick_blue_bottle HDF5 æ–‡ä»¶ä¸­åŠ è½½æ•°æ®ï¼ˆä¸‹é‡‡æ ·ç‰ˆæœ¬ï¼Œå»æ‰NaNå€¼ï¼‰ã€‚
    
    Args:
        hdf5_path: HDF5 æ–‡ä»¶è·¯å¾„
        task_description: ä»»åŠ¡æè¿°
        ignore_valid: æ˜¯å¦å¿½ç•¥æœ‰æ•ˆæ€§æ ‡è®°
        downsample_factor: ä¸‹é‡‡æ ·å› å­ï¼ˆæ¯Nå¸§å–1å¸§ï¼‰
    
    Returns:
        æ­¥éª¤åˆ—è¡¨ï¼Œæ¯ä¸ªæ­¥éª¤åŒ…å« image, wrist_image, state, action, task
    """
    with h5py.File(hdf5_path, "r") as f:
        # è¯»å–å…³èŠ‚çŠ¶æ€
        if "_joint_states" not in f["topics"]:
            raise KeyError("æ‰¾ä¸åˆ° _joint_states topic")
        
        joint_states = f["topics/_joint_states"]
        positions = joint_states["position"][:]  # (T, 14)
        velocities = joint_states["velocity"][:]  # (T, 14)
        
        # è¯»å–ä¸»ç›¸æœºå›¾åƒ
        if "_camera_camera_color_image_raw" not in f["topics"]:
            raise KeyError("æ‰¾ä¸åˆ° _camera_camera_color_image_raw topic")
        
        image_topic = f["topics/_camera_camera_color_image_raw"]
        image_data = image_topic["data"][:]  # å¯èƒ½æ˜¯ (T, H, W, 3) æˆ– (T, 921600)
        
        # æ£€æŸ¥æ•°æ®æ ¼å¼ï¼šæ–°æ ¼å¼æ˜¯å·²è§£ç çš„å›¾åƒæ•°ç»„ï¼Œæ—§æ ¼å¼æ˜¯æ‰å¹³åŒ–çš„å­—èŠ‚æ•°æ®
        if len(image_data.shape) == 4:
            # æ–°æ ¼å¼ï¼šå·²ç»æ˜¯è§£ç åçš„å›¾åƒ (T, H, W, 3)
            image_lengths = None
            print("  âœ… æ£€æµ‹åˆ°æ–°æ ¼å¼ï¼šä¸»ç›¸æœºå›¾åƒå·²è§£ç ")
        else:
            # æ—§æ ¼å¼ï¼šæ‰å¹³åŒ–çš„å­—èŠ‚æ•°æ®ï¼Œéœ€è¦è§£ç 
            image_lengths = image_topic["data_length"][:]  # (T,)
            print("  âœ… æ£€æµ‹åˆ°æ—§æ ¼å¼ï¼šä¸»ç›¸æœºå›¾åƒéœ€è¦è§£ç ")
        
        # è¯»å–æ‰‹è…•ç›¸æœºå›¾åƒï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        wrist_image_data = None
        wrist_image_lengths = None
        has_wrist_camera = "image_wrist" in f["topics"]
        if has_wrist_camera:
            wrist_topic = f["topics/image_wrist"]
            wrist_image_data = wrist_topic["data"][:]  # å¯èƒ½æ˜¯ (T, H, W, 3) æˆ– (T, ...)
            if len(wrist_image_data.shape) == 4:
                # æ–°æ ¼å¼ï¼šå·²ç»æ˜¯è§£ç åçš„å›¾åƒ
                wrist_image_lengths = None
                print("  âœ… æ£€æµ‹åˆ°æ‰‹è…•ç›¸æœºæ•°æ®ï¼ˆæ–°æ ¼å¼ï¼‰")
            else:
                # æ—§æ ¼å¼ï¼šå¯èƒ½éœ€è¦è§£ç 
                if "data_length" in wrist_topic:
                    wrist_image_lengths = wrist_topic["data_length"][:]
                print("  âœ… æ£€æµ‹åˆ°æ‰‹è…•ç›¸æœºæ•°æ®ï¼ˆæ—§æ ¼å¼ï¼‰")
        else:
            print("  âš ï¸  æœªæ‰¾åˆ° image_wrist topicï¼Œå°†ä½¿ç”¨ä¸»ç›¸æœºå›¾åƒä½œä¸ºæ‰‹è…•å›¾åƒ")
        
        # è¯»å–æœ‰æ•ˆæ€§æ ‡è®°ï¼ˆå¦‚æœæœ‰ï¼‰
        valid = None
        if not ignore_valid and "valid" in f:
            # ä¼˜å…ˆä½¿ç”¨ joint_states çš„æœ‰æ•ˆæ€§ï¼Œå¦‚æœå›¾åƒä¹Ÿæœ‰æ•ˆåˆ™æ›´å¥½
            if "_joint_states" in f["valid"]:
                valid_joint = f["valid/_joint_states"][:]  # (T,)
            else:
                valid_joint = None
            
            if "_camera_camera_color_image_raw" in f["valid"]:
                valid_image = f["valid/_camera_camera_color_image_raw"][:]  # (T,)
            else:
                valid_image = None
            
            # å¦‚æœå­˜åœ¨æ‰‹è…•ç›¸æœºï¼Œä¹Ÿæ£€æŸ¥å…¶æœ‰æ•ˆæ€§
            valid_wrist = None
            if has_wrist_camera and "image_wrist" in f.get("valid", {}):
                valid_wrist = f["valid/image_wrist"][:]  # (T,)
            
            # ç»„åˆæœ‰æ•ˆæ€§ï¼šjoint_states å¿…é¡»æœ‰æ•ˆï¼Œä¸»ç›¸æœºå’Œæ‰‹è…•ç›¸æœºï¼ˆå¦‚æœå­˜åœ¨ï¼‰ä¹Ÿåº”è¯¥æœ‰æ•ˆ
            valid_list = [v for v in [valid_joint, valid_image, valid_wrist] if v is not None]
            if valid_list:
                valid = valid_list[0]
                for v in valid_list[1:]:
                    valid = valid & v
            elif valid_joint is not None:
                valid = valid_joint
            elif valid_image is not None:
                valid = valid_image
        
        # ç¡®ä¿æ‰€æœ‰æ•°æ®é•¿åº¦ä¸€è‡´
        min_length = len(positions)
        min_length = min(min_length, len(image_data))
        if wrist_image_data is not None:
            min_length = min(min_length, len(wrist_image_data))
        
        if valid is not None and not ignore_valid:
            # åªä½¿ç”¨æœ‰æ•ˆçš„æ­¥éª¤
            valid_indices = np.where(valid[:min_length])[0]
        else:
            valid_indices = np.arange(min_length)
        
        if len(valid_indices) == 0:
            raise ValueError("æ²¡æœ‰æœ‰æ•ˆçš„æ•°æ®æ­¥éª¤")
        
        # è¯»å–å³å¤¹çˆªæ•°æ®ï¼ˆåœ¨è¿‡æ»¤å’Œä¸‹é‡‡æ ·ä¹‹å‰ï¼‰
        right_gripper_values = None
        if "_control_gripperValueR" in f["topics"]:
            gripper_topic = f["topics/_control_gripperValueR"]
            if "data" in gripper_topic:
                gripper_data = gripper_topic["data"][:]  # (T,)
                # å…ˆè¿‡æ»¤æœ‰æ•ˆç´¢å¼•
                gripper_data = gripper_data[valid_indices]
                right_gripper_values = gripper_data
                print(f"  âœ… è¯»å–å³å¤¹çˆªæ•°æ®: {len(right_gripper_values)} ä¸ªå€¼ï¼ˆè¿‡æ»¤åï¼‰")
            else:
                print("  âš ï¸  å¤¹çˆªè¯é¢˜ä¸­æ²¡æœ‰ 'data' é”®")
        else:
            print("  âš ï¸  æœªæ‰¾åˆ° _control_gripperValueR è¯é¢˜")
        
        # æå–æœ‰æ•ˆæ•°æ®
        positions = positions[valid_indices]
        velocities = velocities[valid_indices]
        image_data = image_data[valid_indices]
        if image_lengths is not None:
            image_lengths = image_lengths[valid_indices]
        
        # æå–æ‰‹è…•ç›¸æœºæ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if wrist_image_data is not None:
            wrist_image_data = wrist_image_data[valid_indices]
            if wrist_image_lengths is not None:
                wrist_image_lengths = wrist_image_lengths[valid_indices]
        
        # ä¸‹é‡‡æ ·ï¼šæ¯ downsample_factor å¸§å–1å¸§
        downsampled_indices = np.arange(0, len(positions), downsample_factor)
        positions = positions[downsampled_indices]
        velocities = velocities[downsampled_indices]
        image_data = image_data[downsampled_indices]
        if image_lengths is not None:
            image_lengths = image_lengths[downsampled_indices]
        
        # ä¸‹é‡‡æ ·æ‰‹è…•ç›¸æœºæ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if wrist_image_data is not None:
            wrist_image_data = wrist_image_data[downsampled_indices]
            if wrist_image_lengths is not None:
                wrist_image_lengths = wrist_image_lengths[downsampled_indices]
        
        # ä¸‹é‡‡æ ·å¤¹çˆªæ•°æ®ï¼ˆä¸å…³èŠ‚æ•°æ®åŒæ­¥ï¼‰
        if right_gripper_values is not None:
            right_gripper_values = right_gripper_values[downsampled_indices]
            print(f"  âœ… ä¸‹é‡‡æ ·åå³å¤¹çˆªæ•°æ®: {len(right_gripper_values)} ä¸ªå€¼ï¼ŒèŒƒå›´ [{np.min(right_gripper_values[~np.isnan(right_gripper_values)]):.4f}, {np.max(right_gripper_values[~np.isnan(right_gripper_values)]):.4f}]")
        else:
            # å¦‚æœå¤¹çˆªæ•°æ®ä¸å¯ç”¨ï¼Œåˆ›å»ºé›¶æ•°ç»„
            right_gripper_values = np.zeros(len(positions))
            print("  âš ï¸  ä½¿ç”¨é›¶å¤¹çˆªå€¼ï¼ˆæœªæ‰¾åˆ°å¤¹çˆªæ•°æ®ï¼‰")
        
        # æå–å³è‡‚å…³èŠ‚ï¼ˆåˆ— 7-13ï¼Œå¯¹åº” Joint1_R åˆ° Joint7_Rï¼‰
        # æ³¨æ„ï¼šjoint_states æœ‰14ç»´ï¼šå‰7ç»´æ˜¯å·¦è‡‚ï¼ˆJoint1_L åˆ° Joint7_Lï¼‰ï¼Œå7ç»´æ˜¯å³è‡‚ï¼ˆJoint1_R åˆ° Joint7_Rï¼‰
        right_positions = positions[:, 7:14]  # (T, 7) - å³è‡‚å…³èŠ‚ä½ç½®
        right_velocities = velocities[:, 7:14]  # (T, 7) - å³è‡‚å…³èŠ‚é€Ÿåº¦
        
        # ğŸ”‘ å…³é”®ä¿®æ”¹ï¼šæ‰¾åˆ°æ‰€æœ‰æœ‰æ•ˆçš„æ—¶é—´æ­¥ï¼ˆjointä½ç½®å’Œgripperå€¼éƒ½ä¸æ˜¯NaNï¼‰
        # å¯¹äºjointä½ç½®ï¼Œæ£€æŸ¥æ‰€æœ‰7ä¸ªå…³èŠ‚æ˜¯å¦éƒ½æ˜¯æœ‰æ•ˆå€¼
        joint_valid = ~np.isnan(right_positions).any(axis=1)  # (T,)
        gripper_valid = ~np.isnan(right_gripper_values)  # (T,)
        
        # ä¸¤è€…éƒ½æœ‰æ•ˆçš„æ—¶é—´æ­¥
        no_nan_mask = joint_valid & gripper_valid
        
        no_nan_indices = np.where(no_nan_mask)[0]
        
        print(f"  ğŸ“Š NaNå€¼è¿‡æ»¤ç»Ÿè®¡:")
        print(f"     åŸå§‹æ•°æ®: {len(right_positions)} ä¸ªæ—¶é—´æ­¥")
        print(f"     Jointæœ‰æ•ˆ: {np.sum(joint_valid)}/{len(joint_valid)} ({np.sum(joint_valid)/len(joint_valid)*100:.2f}%)")
        print(f"     Gripperæœ‰æ•ˆ: {np.sum(gripper_valid)}/{len(gripper_valid)} ({np.sum(gripper_valid)/len(gripper_valid)*100:.2f}%)")
        print(f"     ä¸¤è€…éƒ½æœ‰æ•ˆï¼ˆå»æ‰NaNåï¼‰: {len(no_nan_indices)}/{len(right_positions)} ({len(no_nan_indices)/len(right_positions)*100:.2f}%)")
        
        if len(no_nan_indices) == 0:
            raise ValueError("é”™è¯¯ï¼šå»æ‰NaNåæ²¡æœ‰æœ‰æ•ˆçš„æ•°æ®æ­¥éª¤ï¼")
        
        # ğŸ”‘ å…³é”®ä¿®æ”¹ï¼šåªä¿ç•™æ²¡æœ‰NaNçš„æ—¶é—´æ­¥
        right_positions = right_positions[no_nan_indices]  # (N, 7)
        right_velocities = right_velocities[no_nan_indices]  # (N, 7)
        right_gripper_values = right_gripper_values[no_nan_indices]  # (N,)
        image_data = image_data[no_nan_indices]
        if image_lengths is not None:
            image_lengths = image_lengths[no_nan_indices]
        
        # åŒæ­¥è¿‡æ»¤æ‰‹è…•ç›¸æœºæ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if wrist_image_data is not None:
            wrist_image_data = wrist_image_data[no_nan_indices]
            if wrist_image_lengths is not None:
                wrist_image_lengths = wrist_image_lengths[no_nan_indices]
        
        print(f"  âœ… å»æ‰NaNåä¿ç•™: {len(no_nan_indices)} ä¸ªæ—¶é—´æ­¥")
        
        # --- ğŸ›¡ï¸ å¥å£®çš„åŠ¨ä½œè®¡ç®— ---
        # æ£€æŸ¥é€Ÿåº¦æ˜¯å¦æœ‰æ•ˆï¼ˆä¸æ˜¯ NaN ä¸”ä¸å…¨ä¸º 0ï¼‰
        velocity_is_valid = not np.isnan(right_velocities).any() and np.any(np.abs(right_velocities) > 1e-6)
        
        # âš ï¸ CRITICAL: Actions are velocities (rad/s), NOT delta positions
        # The training script will multiply by dt when using: q_next = q_curr + velocity * dt
        if velocity_is_valid:
            print("  âœ… ä½¿ç”¨åŸå§‹å…³èŠ‚é€Ÿåº¦ä½œä¸ºåŠ¨ä½œ (rad/s)")
            actions = right_velocities
        else:
            print("  âš ï¸  åŸå§‹é€Ÿåº¦æ— æ•ˆæˆ–ä¸º NaNï¼Œä½¿ç”¨ä½ç½®å·®åˆ†è®¡ç®—é€Ÿåº¦")
            # ä½¿ç”¨ä½ç½®å·®åˆ†è®¡ç®—é€Ÿåº¦ï¼ˆéœ€è¦é™¤ä»¥ dtï¼‰
            # æ•°æ®é›†ä¸‹é‡‡æ ·4å€ï¼š30fps -> 7.5fpsï¼Œæ‰€ä»¥ dt = 1/7.5
            dt = 1.0 / 7.5
            position_deltas = compute_actions_from_states(right_positions, right_velocities)
            # å°†ä½ç½®å·®åˆ†è½¬æ¢ä¸ºé€Ÿåº¦: velocity = delta_position / dt
            actions = position_deltas / dt
        
        # ç¡®ä¿åŠ¨ä½œæ²¡æœ‰ NaNï¼ˆç†è®ºä¸Šä¸åº”è¯¥æœ‰ï¼Œå› ä¸ºå·²ç»è¿‡æ»¤äº†ï¼‰
        if np.isnan(actions).any():
            print("  âš ï¸  è­¦å‘Šï¼šæ£€æµ‹åˆ°åŠ¨ä½œåŒ…å« NaNï¼ˆä¸åº”è¯¥å‘ç”Ÿï¼Œå› ä¸ºå·²ç»è¿‡æ»¤äº†NaNï¼‰")
            # å¦‚æœè¿˜æœ‰NaNï¼Œåˆ é™¤è¿™äº›æ—¶é—´æ­¥
            action_valid = ~np.isnan(actions).any(axis=1)
            actions = actions[action_valid]
            right_positions = right_positions[action_valid]
            right_gripper_values = right_gripper_values[action_valid]
            image_data = image_data[action_valid]
            if image_lengths is not None:
                image_lengths = image_lengths[action_valid]
            
            # åŒæ­¥è¿‡æ»¤æ‰‹è…•ç›¸æœºæ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if wrist_image_data is not None:
                wrist_image_data = wrist_image_data[action_valid]
                if wrist_image_lengths is not None:
                    wrist_image_lengths = wrist_image_lengths[action_valid]
            
            print(f"  âœ… è¿›ä¸€æ­¥è¿‡æ»¤åä¿ç•™: {len(actions)} ä¸ªæ—¶é—´æ­¥")
        
        # è®¡ç®—gripperåŠ¨ä½œï¼ˆgripperçš„é€Ÿåº¦ï¼Œå³å˜åŒ–ç‡ï¼‰
        # å¯¹äºgripperï¼Œæˆ‘ä»¬ä½¿ç”¨å·®åˆ†æ¥è®¡ç®—é€Ÿåº¦ï¼ˆéœ€è¦é™¤ä»¥ dtï¼‰
        dt = 1.0 / 7.5  # ä¸‹é‡‡æ ·4å€: 30fps -> 7.5fps
        gripper_position_deltas = np.diff(right_gripper_values, axis=0, prepend=right_gripper_values[0:1])
        gripper_actions = gripper_position_deltas / dt  # è½¬æ¢ä¸ºé€Ÿåº¦
        
        # ç¡®ä¿gripperåŠ¨ä½œæ²¡æœ‰NaNï¼ˆç†è®ºä¸Šä¸åº”è¯¥æœ‰ï¼‰
        if np.isnan(gripper_actions).any():
            print("  âš ï¸  è­¦å‘Šï¼šæ£€æµ‹åˆ°gripperåŠ¨ä½œåŒ…å« NaNï¼ˆä¸åº”è¯¥å‘ç”Ÿï¼‰")
            gripper_actions = np.nan_to_num(gripper_actions, nan=0.0)
        
        # ç»„åˆåŠ¨ä½œï¼ˆ7ä¸ªå…³èŠ‚é€Ÿåº¦ + 1ä¸ªgripperé€Ÿåº¦ï¼‰ = 8ç»´
        actions = np.concatenate([actions, gripper_actions[:, None]], axis=1)  # (N, 8)
        print(f"  âœ… åŠ¨ä½œç»´åº¦: {actions.shape} (7ä¸ªå…³èŠ‚é€Ÿåº¦ rad/s + 1ä¸ªgripperé€Ÿåº¦)")
        
        # ç»„åˆçŠ¶æ€ï¼ˆå³è‡‚å…³èŠ‚ä½ç½® + å³å¤¹çˆªï¼ŒLIBERO éœ€è¦8ç»´ï¼‰
        # çŠ¶æ€: [7ä¸ªå³è‡‚å…³èŠ‚ä½ç½®, 1ä¸ªå³å¤¹çˆªå€¼]
        states = np.concatenate([right_positions, right_gripper_values[:, None]], axis=1)  # (N, 8)
        print(f"  âœ… çŠ¶æ€ç»´åº¦: {states.shape} (7ä¸ªå…³èŠ‚ä½ç½® + 1ä¸ªgripperå€¼)")
        
        # è§£ç ä¸»ç›¸æœºå›¾åƒ
        print(f"  å¤„ç† {len(image_data)} å¼ ä¸»ç›¸æœºå›¾åƒï¼ˆå»æ‰NaNåï¼‰...")
        if len(image_data.shape) == 4:
            # æ–°æ ¼å¼ï¼šå·²ç»æ˜¯è§£ç åçš„å›¾åƒæ•°ç»„ (T, H, W, 3)
            images = image_data.astype(np.uint8)
            print(f"  âœ… ä¸»ç›¸æœºå›¾åƒå·²è§£ç ï¼Œå½¢çŠ¶: {images.shape}")
        else:
            # æ—§æ ¼å¼ï¼šéœ€è¦è§£ç æ‰å¹³åŒ–çš„å­—èŠ‚æ•°æ®
            images = []
            for i in tqdm(range(len(image_data)), desc="  è§£ç ä¸»ç›¸æœºå›¾åƒ", leave=False):
                try:
                    img = decode_image(image_data[i], image_lengths[i])
                    images.append(img)
                except Exception as e:
                    print(f"  âš ï¸  è§£ç ä¸»ç›¸æœºå›¾åƒ {i} å¤±è´¥: {e}ï¼Œä½¿ç”¨é›¶å›¾åƒ")
                    # ä½¿ç”¨é›¶å›¾åƒä½œä¸ºå ä½ç¬¦
                    images.append(np.zeros((480, 640, 3), dtype=np.uint8))
            images = np.array(images)
        
        # è§£ç æ‰‹è…•ç›¸æœºå›¾åƒï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        wrist_images = None
        if wrist_image_data is not None:
            print(f"  å¤„ç† {len(wrist_image_data)} å¼ æ‰‹è…•ç›¸æœºå›¾åƒï¼ˆå»æ‰NaNåï¼‰...")
            if len(wrist_image_data.shape) == 4:
                # æ–°æ ¼å¼ï¼šå·²ç»æ˜¯è§£ç åçš„å›¾åƒæ•°ç»„ (T, H, W, 3)
                wrist_images = wrist_image_data.astype(np.uint8)
                print(f"  âœ… æ‰‹è…•ç›¸æœºå›¾åƒå·²è§£ç ï¼Œå½¢çŠ¶: {wrist_images.shape}")
            else:
                # æ—§æ ¼å¼ï¼šéœ€è¦è§£ç æ‰å¹³åŒ–çš„å­—èŠ‚æ•°æ®
                wrist_images = []
                for i in tqdm(range(len(wrist_image_data)), desc="  è§£ç æ‰‹è…•ç›¸æœºå›¾åƒ", leave=False):
                    try:
                        if wrist_image_lengths is not None:
                            img = decode_image(wrist_image_data[i], wrist_image_lengths[i])
                        else:
                            # å¦‚æœæ²¡æœ‰ data_lengthï¼Œå°è¯•ç›´æ¥è§£ç 
                            img = decode_image(wrist_image_data[i], len(wrist_image_data[i]))
                        wrist_images.append(img)
                    except Exception as e:
                        print(f"  âš ï¸  è§£ç æ‰‹è…•ç›¸æœºå›¾åƒ {i} å¤±è´¥: {e}ï¼Œä½¿ç”¨é›¶å›¾åƒ")
                        # ä½¿ç”¨é›¶å›¾åƒä½œä¸ºå ä½ç¬¦
                        wrist_images.append(np.zeros((480, 640, 3), dtype=np.uint8))
                wrist_images = np.array(wrist_images)
        
        # è½¬æ¢ä¸ºæ­¥éª¤åˆ—è¡¨
        steps = []
        for i in range(len(right_positions)):
            # è°ƒæ•´ä¸»ç›¸æœºå›¾åƒå¤§å°
            image = resize_image(images[i], (256, 256))
            
            # --- ğŸ›¡ï¸ ç¡®ä¿å›¾åƒæ˜¯ uint8 ä¸”ä¸éœ€è¦é¢å¤–ç¼©æ”¾ ---
            if image.dtype != np.uint8:
                if image.max() <= 1.0:
                    image = (image * 255).astype(np.uint8)
                else:
                    image = image.astype(np.uint8)
            else:
                image = image.astype(np.uint8)
            
            # å¤„ç†æ‰‹è…•ç›¸æœºå›¾åƒ
            if wrist_images is not None:
                # ä½¿ç”¨çœŸå®çš„æ‰‹è…•ç›¸æœºå›¾åƒ
                wrist_image = resize_image(wrist_images[i], (256, 256))
                if wrist_image.dtype != np.uint8:
                    if wrist_image.max() <= 1.0:
                        wrist_image = (wrist_image * 255).astype(np.uint8)
                    else:
                        wrist_image = wrist_image.astype(np.uint8)
                else:
                    wrist_image = wrist_image.astype(np.uint8)
            else:
                # å¦‚æœæ²¡æœ‰æ‰‹è…•ç›¸æœºï¼Œä½¿ç”¨ä¸»ç›¸æœºï¼ˆå‘åå…¼å®¹ï¼‰
                wrist_image = image.copy()
            
            steps.append({
                "image": image,
                "wrist_image": wrist_image,
                "state": states[i].astype(np.float32),
                "action": actions[i].astype(np.float32),
                "task": task_description,
            })
        
        return steps


def main(
    data_dir: str,
    *,
    push_to_hub: bool = False,
    task_description: str = "Pick blue bottle and place it in blue plate",
    ignore_valid: bool = False,
    downsample_factor: int = 4,
    fps: int = 7.5,  # åŸå§‹30fpsä¸‹é‡‡æ ·4å€åä¸º7.5fps
):
    """
    ä¸»å‡½æ•°ï¼šå°† pick_blue_bottle HDF5 æ ¼å¼æ•°æ®è½¬æ¢ä¸º LeRobot æ ¼å¼ï¼ˆä¸‹é‡‡æ ·4å€ç‰ˆæœ¬ï¼Œå»æ‰NaNå€¼ï¼‰
    
    Args:
        data_dir: HDF5 æ–‡ä»¶æ‰€åœ¨çš„ç›®å½•
        push_to_hub: æ˜¯å¦æ¨é€åˆ° Hugging Face Hub
        task_description: ä»»åŠ¡æè¿°
        ignore_valid: æ˜¯å¦å¿½ç•¥æœ‰æ•ˆæ€§æ ‡è®°ï¼Œä½¿ç”¨æ‰€æœ‰æ•°æ®
        downsample_factor: ä¸‹é‡‡æ ·å› å­ï¼ˆæ¯Nå¸§å–1å¸§ï¼‰
        fps: è¾“å‡ºæ•°æ®é›†çš„å¸§ç‡ï¼ˆåŸå§‹30fpsä¸‹é‡‡æ ·4å€åä¸º7.5fpsï¼‰
    """
    data_dir = Path(data_dir)
    
    # æ¸…ç†è¾“å‡ºç›®å½•
    output_path = HF_LEROBOT_HOME / REPO_NAME
    if output_path.exists():
        shutil.rmtree(output_path)
    
    # åˆ›å»º LeRobot æ•°æ®é›†
    dataset = LeRobotDataset.create(
        repo_id=REPO_NAME,
        robot_type="panda",
        fps=fps,  # ä¸‹é‡‡æ ·åçš„å¸§ç‡
        features={
            "image": {
                "dtype": "image",
                "shape": (256, 256, 3),
                "names": ["height", "width", "channel"],
            },
            "wrist_image": {
                "dtype": "image",
                "shape": (256, 256, 3),
                "names": ["height", "width", "channel"],
            },
            "state": {
                "dtype": "float32",
                "shape": (8,),
                "names": ["state"],
            },
            "actions": {
                "dtype": "float32",
                "shape": (8,),  # 8 ç»´åŠ¨ä½œï¼ˆ7ä¸ªå…³èŠ‚é€Ÿåº¦ + 1ä¸ªgripperé€Ÿåº¦ï¼‰
                "names": ["actions"],
            },
        },
        image_writer_threads=10,
        image_writer_processes=5,
    )
    
    # æŸ¥æ‰¾æ‰€æœ‰ HDF5 æ–‡ä»¶
    hdf5_files = sorted(list(data_dir.glob("*.h5")) + list(data_dir.glob("*.hdf5")))
    if not hdf5_files:
        raise FileNotFoundError(f"åœ¨ç›®å½• '{data_dir}' ä¸­æ‰¾ä¸åˆ°ä»»ä½• .h5 æˆ– .hdf5 æ–‡ä»¶")
    
    print(f"æ‰¾åˆ° {len(hdf5_files)} ä¸ª HDF5 æ–‡ä»¶")
    print(f"ä¸‹é‡‡æ ·å› å­: {downsample_factor}x")
    print(f"è¾“å‡ºå¸§ç‡: {fps} fps")
    print(f"âš ï¸  é‡è¦ï¼šé‡åˆ°NaNå€¼å°†ç›´æ¥åˆ é™¤è¯¥æ—¶é—´æ­¥ï¼ˆä¸å¡«å……0ï¼‰")
    print()
    
    # éå†æ‰€æœ‰ HDF5 æ–‡ä»¶
    total_steps = 0
    total_original_steps = 0
    for hdf5_path in tqdm(hdf5_files, desc="å¤„ç† HDF5 æ–‡ä»¶"):
        try:
            # å…ˆç»Ÿè®¡åŸå§‹æ•°æ®é‡
            with h5py.File(hdf5_path, 'r') as f:
                if "_joint_states" in f["topics"]:
                    original_length = len(f["topics/_joint_states"]["position"])
                    total_original_steps += original_length
            
            steps = load_pick_blue_bottle_hdf5(hdf5_path, task_description, ignore_valid, downsample_factor)
            
            # å†™å…¥ LeRobot æ•°æ®é›†
            # ç›´æ¥ä½¿ç”¨ step ä¸­çš„æ•°æ®ï¼Œå› ä¸º load å‡½æ•°é‡Œå·²ç»å¤„ç†å¥½äº†
            for step in steps:
                dataset.add_frame({
                    "image": step["image"],           # å·²ç»æ˜¯å¤„ç†å¥½çš„ uint8
                    "wrist_image": step["wrist_image"], # å·²ç»æ˜¯å¤„ç†å¥½çš„ uint8
                    "state": step["state"].astype(np.float32),
                    "actions": step["action"].astype(np.float32),
                    "task": step["task"],
                })
            
            dataset.save_episode()
            total_steps += len(steps)
            print(f"âœ… æˆåŠŸè½¬æ¢ {hdf5_path.name} ({len(steps)} æ­¥ï¼Œå»æ‰NaNå)")
            print()
            
        except Exception as e:
            print(f"âŒ å¤„ç† {hdf5_path} æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    print(f"\nâœ… è½¬æ¢å®Œæˆï¼")
    print(f"   åŸå§‹æ•°æ®æ€»æ­¥æ•°: {total_original_steps}")
    print(f"   å»æ‰NaNåæ€»æ­¥æ•°: {total_steps}")
    print(f"   ä¿ç•™ç‡: {total_steps/total_original_steps*100:.2f}%")
    print(f"æ•°æ®é›†ä¿å­˜åœ¨: {output_path}")
    
    # å¯é€‰ï¼šæ¨é€åˆ° Hugging Face Hub
    if push_to_hub:
        print("\næ¨é€åˆ° Hugging Face Hub...")
        dataset.push_to_hub(
            tags=["libero", "panda", "downsampled", "no_nan"],
            private=False,
            push_videos=True,
            license="apache-2.0",
        )
        print(f"âœ… å·²æ¨é€åˆ° Hub: {REPO_NAME}")


if __name__ == "__main__":
    tyro.cli(main)


