"""
é€šç”¨çš„ HDF5 æ ¼å¼æ•°æ®åˆ° LeRobot æ ¼å¼è½¬æ¢è„šæœ¬ï¼ˆä¸é™é‡‡æ ·ç‰ˆæœ¬ï¼Œä»…ä½¿ç”¨å³è‡‚æ•°æ®ï¼‰ã€‚

è¿™ä¸ªè„šæœ¬ç”¨äºå¤„ç† LIBERO æ•°æ®é›†çš„ HDF5 æ–‡ä»¶ï¼Œä¸è¿›è¡Œé™é‡‡æ ·ã€‚
åªä½¿ç”¨å³è‡‚æ•°æ®ï¼ˆå·¦è‡‚æœªä½¿ç”¨ï¼‰ï¼Œå¹¶åŒ…å«å³å¤¹çˆªä¿¡æ¯ã€‚

HDF5 æ–‡ä»¶ç»“æ„:
- time: (T,) æ—¶é—´æˆ³
- topics/_joint_states/:
    - position: (T, 14) å…³èŠ‚ä½ç½®ï¼ˆå‰7ç»´=å·¦è‡‚ï¼Œå7ç»´=å³è‡‚ï¼‰
    - velocity: (T, 14) å…³èŠ‚é€Ÿåº¦ï¼ˆå‰7ç»´=å·¦è‡‚ï¼Œå7ç»´=å³è‡‚ï¼‰
- topics/_control_gripperValueR/:
    - data: (T,) å³å¤¹çˆªå€¼ï¼ˆ0=å…¨å¼€ï¼Œ1=å…¨é—­ï¼‰
- topics/_camera_camera_color_image_raw/:
    - data: (T, 921600) å›¾åƒæ•°æ®ï¼ˆæ‰å¹³åŒ–ï¼‰
    - data_length: (T,) æ¯ä¸ªå›¾åƒçš„å®é™…é•¿åº¦

è¾“å‡ºæ•°æ®:
- çŠ¶æ€: [3ç»´EEFä½ç½®, 3ç»´EEFæ–¹å‘(è½´è§’), 1ç»´å¤¹çˆªå€¼, 1ç»´å¤¹çˆªå€¼ç›¸åæ•°] = 8ç»´
- åŠ¨ä½œ: [6ç»´EEF action (xyzä½ç§» + è½´è§’æ—‹è½¬), 1ç»´å¤¹çˆªçŠ¶æ€] = 7ç»´

Usage:
# è½¬æ¢å•ä¸ªæ–‡ä»¶
uv run examples/libero/convert_hdf5_to_lerobot.py --hdf5_path /path/to/data.h5 --output_repo_name your_hf_username/dataset_name

# è½¬æ¢ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶
uv run examples/libero/convert_hdf5_to_lerobot.py --hdf5_path /path/to/data_dir --output_repo_name your_hf_username/dataset_name
"""

import shutil
from pathlib import Path

import h5py
import numpy as np
from lerobot.common.datasets.lerobot_dataset import HF_LEROBOT_HOME
from lerobot.common.datasets.lerobot_dataset import LeRobotDataset
from PIL import Image
from tqdm import tqdm
import tyro
from scipy.spatial.transform import Rotation as R


def decode_image(img_data: np.ndarray, img_length: int) -> np.ndarray:
    """
    è§£ç å›¾åƒæ•°æ®ã€‚
    
    å›¾åƒæ•°æ®å¯èƒ½æ˜¯ï¼š
    1. JPEG å‹ç¼©æ ¼å¼ï¼ˆéœ€è¦è§£ç ï¼‰
    2. åŸå§‹ RGB å›¾åƒæ•°æ®ï¼ˆéœ€è¦é‡å¡‘ï¼‰
    
    Args:
        img_data: å›¾åƒæ•°æ®æ•°ç»„ï¼ˆæ‰å¹³åŒ–ï¼‰
        img_length: å›¾åƒæ•°æ®çš„å®é™…é•¿åº¦
    
    Returns:
        è§£ç åçš„å›¾åƒ (H, W, 3) uint8
    """
    img_bytes = bytes(img_data[:img_length])
    
    # ä¼˜å…ˆå°è¯•ä½œä¸º JPEG è§£ç ï¼ˆæœ€å¸¸è§ï¼‰
    try:
        import cv2
        nparr = np.frombuffer(img_bytes, np.uint8)
        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img is not None:
            # OpenCV è¿”å› BGRï¼Œè½¬æ¢ä¸º RGB
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            return img
    except ImportError:
        # å¦‚æœæ²¡æœ‰ OpenCVï¼Œå°è¯•ç”¨ PIL
        try:
            from io import BytesIO
            img = Image.open(BytesIO(img_bytes))
            if img.mode != 'RGB':
                img = img.convert('RGB')
            return np.array(img)
        except:
            pass
    except:
        # OpenCV è§£ç å¤±è´¥ï¼Œå°è¯•å…¶ä»–æ–¹æ³•
        pass
    
    # å¦‚æœä¸æ˜¯ JPEGï¼Œå°è¯•ä½œä¸ºåŸå§‹å›¾åƒæ•°æ®
    # å°è¯•å¸¸è§çš„å°ºå¯¸
    possible_sizes = [
        (720, 1280, 1),  # å•é€šé“
        (480, 640, 3),   # RGB
        (480, 854, 3),   # RGB
        (360, 640, 3),   # RGB
    ]
    
    for h, w, c in possible_sizes:
        if h * w * c == img_length:
            img = np.frombuffer(img_bytes, dtype=np.uint8).reshape(h, w, c)
            if c == 1:
                # å•é€šé“è½¬ RGB
                img = np.repeat(img, 3, axis=2)
            return img
    
    # å¦‚æœéƒ½ä¸åŒ¹é…ï¼Œå°è¯•ç›´æ¥é‡å¡‘ä¸º 640x480x3ï¼ˆæœ€å¸¸è§ï¼‰
    if img_length >= 640 * 480 * 3:
        img = np.frombuffer(img_bytes[:640*480*3], dtype=np.uint8).reshape(480, 640, 3)
        return img
    
    raise ValueError(f"æ— æ³•è§£ç å›¾åƒæ•°æ®ï¼Œé•¿åº¦: {img_length}")


def resize_image(image: np.ndarray, target_size: tuple[int, int] = (256, 256)) -> np.ndarray:
    """è°ƒæ•´å›¾åƒå¤§å°åˆ°ç›®æ ‡å°ºå¯¸"""
    if image.shape[:2] == target_size:
        return image
    img = Image.fromarray(image)
    img = img.resize(target_size, resample=Image.BICUBIC)
    return np.array(img)


def handle_nan_values(data: np.ndarray) -> np.ndarray:
    """
    å¤„ç† NaN å€¼ï¼š
    - ç¬¬ä¸€ä¸ªæ•°æ®å‡ºç° NaN â†’ ä½¿ç”¨ç¬¬äºŒä¸ªæ•°æ®
    - æœ€åä¸€ä¸ªæ•°æ®å‡ºç° NaN â†’ ä½¿ç”¨å€’æ•°ç¬¬äºŒä¸ªæ•°æ®
    - ä¸­é—´å‡ºç° NaN â†’ ä½¿ç”¨ä¸Šä¸€æ—¶åˆ»çš„å€¼
    
    Args:
        data: æ•°æ®æ•°ç»„ï¼Œå¯ä»¥æ˜¯ 1D æˆ– 2D
    
    Returns:
        å¤„ç†åçš„æ•°æ®æ•°ç»„
    """
    data_clean = data.copy()
    
    if len(data_clean.shape) == 1:
        # 1D æ•°ç»„
        for i in range(len(data_clean)):
            if np.isnan(data_clean[i]):
                if i == 0:
                    # ç¬¬ä¸€ä¸ªï¼šä½¿ç”¨ä¸‹ä¸€ä¸ªé NaN å€¼
                    for j in range(1, len(data_clean)):
                        if not np.isnan(data_clean[j]):
                            data_clean[i] = data_clean[j]
                            break
                elif i == len(data_clean) - 1:
                    # æœ€åä¸€ä¸ªï¼šä½¿ç”¨ä¸Šä¸€ä¸ªé NaN å€¼
                    for j in range(len(data_clean) - 2, -1, -1):
                        if not np.isnan(data_clean[j]):
                            data_clean[i] = data_clean[j]
                            break
                else:
                    # ä¸­é—´ï¼šä½¿ç”¨å‰ä¸€ä¸ªé NaN å€¼
                    for j in range(i - 1, -1, -1):
                        if not np.isnan(data_clean[j]):
                            data_clean[i] = data_clean[j]
                            break
    else:
        # 2D æ•°ç»„ï¼Œé€è¡Œå¤„ç†
        for i in range(len(data_clean)):
            if np.isnan(data_clean[i]).any():
                if i == 0:
                    # ç¬¬ä¸€ä¸ªï¼šä½¿ç”¨ä¸‹ä¸€ä¸ªé NaN å€¼
                    for j in range(1, len(data_clean)):
                        if not np.isnan(data_clean[j]).any():
                            data_clean[i] = data_clean[j]
                            break
                elif i == len(data_clean) - 1:
                    # æœ€åä¸€ä¸ªï¼šä½¿ç”¨ä¸Šä¸€ä¸ªé NaN å€¼
                    for j in range(len(data_clean) - 2, -1, -1):
                        if not np.isnan(data_clean[j]).any():
                            data_clean[i] = data_clean[j]
                            break
                else:
                    # ä¸­é—´ï¼šä½¿ç”¨å‰ä¸€ä¸ªé NaN å€¼
                    for j in range(i - 1, -1, -1):
                        if not np.isnan(data_clean[j]).any():
                            data_clean[i] = data_clean[j]
                            break
    
    return data_clean


def axisangle_to_quat(axis_angle):
    """
    axis_angle: (3,)
    return quat: (4,) in xyzw
    """
    return R.from_rotvec(axis_angle).as_quat()


def quat_to_axisangle(quat):
    """
    quat: (4,) xyzw
    return axis-angle: (3,)
    """
    return R.from_quat(quat).as_rotvec()


def relative_axisangle(aa_t, aa_t1):
    """
    Compute relative rotation from t -> t+1 in axis-angle
    """
    q_t = axisangle_to_quat(aa_t)
    q_t1 = axisangle_to_quat(aa_t1)

    # relative rotation: q_rel = q_t1 * inverse(q_t)
    q_rel = R.from_quat(q_t1) * R.from_quat(q_t).inv()
    return q_rel.as_rotvec()


def compute_geom_action(
    ee_pos_t,
    ee_ori_t,
    ee_pos_t1,
    ee_ori_t1,
):
    """
    All inputs are np.ndarray with shape (3,)
    ee_ori_* are axis-angle
    """
    delta_pos = ee_pos_t1 - ee_pos_t
    delta_ori = relative_axisangle(ee_ori_t, ee_ori_t1)

    action_6d = np.concatenate([delta_pos, delta_ori])
    return action_6d


def load_hdf5_data(
    hdf5_path: Path,
    task_description: str = "Robot manipulation task",
    ignore_valid: bool = False,
) -> list[dict]:
    """
    ä» HDF5 æ–‡ä»¶ä¸­åŠ è½½æ•°æ®ï¼ˆä¸é™é‡‡æ ·ç‰ˆæœ¬ï¼‰ã€‚
    
    ä½¿ç”¨å‡ ä½• action è®¡ç®—æ–¹å¼ï¼š
    - Action: 6ç»´ EEF action (xyzä½ç§» + è½´è§’æ—‹è½¬) + 1ç»´å¤¹çˆªçŠ¶æ€ = 7ç»´
    - State: 3ç»´EEFä½ç½® + 3ç»´EEFæ–¹å‘(è½´è§’) + 1ç»´å¤¹çˆªå€¼ + 1ç»´å¤¹çˆªå€¼ç›¸åæ•° = 8ç»´
    
    Args:
        hdf5_path: HDF5 æ–‡ä»¶è·¯å¾„
        task_description: ä»»åŠ¡æè¿°
        ignore_valid: æ˜¯å¦å¿½ç•¥æœ‰æ•ˆæ€§æ ‡è®°
    
    Returns:
        æ­¥éª¤åˆ—è¡¨ï¼Œæ¯ä¸ªæ­¥éª¤åŒ…å« image, wrist_image, state, action, task
    """
    with h5py.File(hdf5_path, "r") as f:
        # è¯»å– _info_eef_right æ•°æ®ï¼ˆç”¨äºè®¡ç®—å‡ ä½• actionï¼‰
        if "_info_eef_right" not in f["topics"]:
            raise KeyError("æ‰¾ä¸åˆ° _info_eef_right topic")
        
        eef_right_group = f["topics/_info_eef_right"]
        eef_positions = eef_right_group["position"][:]  # (T, 3)
        eef_orientations = eef_right_group["orientation"][:]  # (T, 4) - å››å…ƒæ•° [x, y, z, w]
        
        print(f"  âœ… è¯»å– _info_eef_right: position {eef_positions.shape}, orientation {eef_orientations.shape}")
        
        # å¤„ç† NaN
        eef_positions = handle_nan_values(eef_positions)
        eef_orientations = handle_nan_values(eef_orientations)
        
        # è½¬æ¢ä¸ºè½´è§’
        axis_angles = np.zeros((len(eef_orientations), 3))
        for i in range(len(eef_orientations)):
            quat = eef_orientations[i]  # [x, y, z, w]
            axis_angles[i] = quat_to_axisangle(quat)
        
        print(f"  âœ… è½¬æ¢ä¸ºè½´è§’: {axis_angles.shape}")
        
        # è¯»å–å…³èŠ‚çŠ¶æ€ï¼ˆç”¨äº stateï¼‰
        if "_joint_states" not in f["topics"]:
            raise KeyError("æ‰¾ä¸åˆ° _joint_states topic")
        
        joint_states = f["topics/_joint_states"]
        joint_positions = joint_states["position"][:]  # (T, 14)
        
        # è¯»å–å›¾åƒï¼ˆæ”¯æŒä¸¤ç§æ ¼å¼ï¼‰
        image_topic = None
        image_data = None
        image_lengths = None
        image_topic_name = None
        
        if "_camera_image" in f["topics"]:
            # æ ¼å¼1: å·²è§£ç çš„å›¾åƒæ•°ç»„
            image_topic = f["topics/_camera_image"]
            image_data = image_topic["data"][:]  # (T, H, W, 3) - å·²è§£ç 
            image_topic_name = "_camera_image"
            print(f"  âœ… ä½¿ç”¨å·²è§£ç å›¾åƒæ ¼å¼: {image_data.shape}")
        elif "_camera_camera_color_image_raw" in f["topics"]:
            # æ ¼å¼2: éœ€è¦è§£ç çš„å›¾åƒæ•°æ®
            image_topic = f["topics/_camera_camera_color_image_raw"]
            image_data = image_topic["data"][:]  # (T, 921600)
            image_lengths = image_topic["data_length"][:]  # (T,)
            image_topic_name = "_camera_camera_color_image_raw"
            print(f"  âœ… ä½¿ç”¨åŸå§‹å›¾åƒæ ¼å¼: {image_data.shape}")
        else:
            raise KeyError("æ‰¾ä¸åˆ°å›¾åƒ topicï¼ˆå°è¯•äº† _camera_image å’Œ _camera_camera_color_image_rawï¼‰")
        
        # è¯»å–æœ‰æ•ˆæ€§æ ‡è®°ï¼ˆå¦‚æœæœ‰ï¼‰
        valid = None
        if not ignore_valid and "valid" in f:
            # ä¼˜å…ˆä½¿ç”¨ joint_states çš„æœ‰æ•ˆæ€§ï¼Œå¦‚æœå›¾åƒä¹Ÿæœ‰æ•ˆåˆ™æ›´å¥½
            if "_joint_states" in f["valid"]:
                valid_joint = f["valid/_joint_states"][:]  # (T,)
            else:
                valid_joint = None
            
            # æ£€æŸ¥ä¸¤ç§å›¾åƒæ ¼å¼çš„æœ‰æ•ˆæ€§
            if image_topic_name == "_camera_image" and "_camera_image" in f["valid"]:
                valid_image = f["valid/_camera_image"][:]  # (T,)
            elif image_topic_name == "_camera_camera_color_image_raw" and "_camera_camera_color_image_raw" in f["valid"]:
                valid_image = f["valid/_camera_camera_color_image_raw"][:]  # (T,)
            else:
                valid_image = None
            
            # å¦‚æœä¸¤è€…éƒ½æœ‰æ•ˆåˆ™ä½¿ç”¨ï¼Œå¦åˆ™ä¼˜å…ˆä¿è¯ joint_states æœ‰æ•ˆ
            if valid_joint is not None and valid_image is not None:
                valid = valid_joint & valid_image
            elif valid_joint is not None:
                valid = valid_joint
            elif valid_image is not None:
                valid = valid_image
        
        # ç¡®ä¿æ‰€æœ‰æ•°æ®é•¿åº¦ä¸€è‡´
        min_length = min(len(eef_positions), len(joint_positions), len(image_data))
        if valid is not None and not ignore_valid:
            # åªä½¿ç”¨æœ‰æ•ˆçš„æ­¥éª¤
            valid_indices = np.where(valid[:min_length])[0]
        else:
            valid_indices = np.arange(min_length)
        
        if len(valid_indices) == 0:
            raise ValueError("æ²¡æœ‰æœ‰æ•ˆçš„æ•°æ®æ­¥éª¤")
        
        # è¯»å–å³å¤¹çˆªåé¦ˆæ•°æ®ï¼ˆä» _gripper_feedback_Rï¼‰
        # ç¬¬ä¸€åˆ—ï¼ˆç´¢å¼•0ï¼‰å°±æ˜¯å¤¹çˆªçŠ¶æ€å€¼
        right_gripper_feedback = None
        if "_gripper_feedback_R" in f["topics"]:
            gripper_feedback_group = f["topics/_gripper_feedback_R"]
            if "data" in gripper_feedback_group:
                gripper_feedback_data = gripper_feedback_group["data"][:]  # (T, 5)
                print(f"  ğŸ“Š åŸå§‹å¤¹çˆªåé¦ˆæ•°æ® shape: {gripper_feedback_data.shape}")
                # å–ç¬¬ä¸€åˆ—ï¼ˆç´¢å¼•0ï¼‰ä½œä¸ºå¤¹çˆªçŠ¶æ€å€¼
                if len(gripper_feedback_data.shape) > 1:
                    gripper_feedback_data = gripper_feedback_data[:, 0]  # å–ç¬¬ä¸€åˆ—
                else:
                    gripper_feedback_data = gripper_feedback_data  # å·²ç»æ˜¯1D
                # å…ˆè¿‡æ»¤æœ‰æ•ˆç´¢å¼•
                gripper_feedback_data = gripper_feedback_data[valid_indices]
                right_gripper_feedback = gripper_feedback_data
                print(f"  âœ… è¯»å–å³å¤¹çˆªåé¦ˆæ•°æ®ï¼ˆç¬¬ä¸€åˆ—ï¼‰: {len(right_gripper_feedback)} ä¸ªå€¼ï¼ˆè¿‡æ»¤åï¼‰")
                print(f"  ğŸ“Š å¤¹çˆªå€¼èŒƒå›´: [{np.nanmin(right_gripper_feedback):.6f}, {np.nanmax(right_gripper_feedback):.6f}]")
            else:
                print("  âš ï¸  å¤¹çˆªåé¦ˆè¯é¢˜ä¸­æ²¡æœ‰ 'data' é”®")
                print(f"  ğŸ“‹ å¯ç”¨é”®: {list(gripper_feedback_group.keys())}")
        else:
            print("  âš ï¸  æœªæ‰¾åˆ° _gripper_feedback_R è¯é¢˜")
            print(f"  ğŸ“‹ å¯ç”¨ topics: {list(f['topics'].keys())[:10]}...")  # åªæ˜¾ç¤ºå‰10ä¸ª
        
        # æå–æœ‰æ•ˆæ•°æ®ï¼ˆä¸é™é‡‡æ ·ï¼‰
        eef_positions = eef_positions[valid_indices]
        eef_orientations = eef_orientations[valid_indices]
        axis_angles = axis_angles[valid_indices]
        joint_positions = joint_positions[valid_indices]
        image_data = image_data[valid_indices]
        if image_lengths is not None:
            image_lengths = image_lengths[valid_indices]
        
        # å¤„ç†å¤¹çˆªåé¦ˆæ•°æ®ï¼ˆä¸å…³èŠ‚æ•°æ®åŒæ­¥ï¼‰
        if right_gripper_feedback is not None:
            print(f"  âœ… å³å¤¹çˆªåé¦ˆæ•°æ®: {len(right_gripper_feedback)} ä¸ªå€¼")
        else:
            # å¦‚æœå¤¹çˆªæ•°æ®ä¸å¯ç”¨ï¼Œåˆ›å»ºé›¶æ•°ç»„
            right_gripper_feedback = np.zeros(len(eef_positions))
            print("  âš ï¸  ä½¿ç”¨é›¶å¤¹çˆªå€¼ï¼ˆæœªæ‰¾åˆ°å¤¹çˆªæ•°æ®ï¼‰")
        
        # å¤„ç†å›¾åƒï¼ˆæ ¹æ®æ ¼å¼å†³å®šæ˜¯å¦éœ€è¦è§£ç ï¼‰
        if image_topic_name == "_camera_image":
            # å·²è§£ç æ ¼å¼ï¼šç›´æ¥ä½¿ç”¨ï¼Œä½†éœ€è¦ç¡®ä¿æ˜¯ uint8 ç±»å‹
            print(f"  å¤„ç† {len(valid_indices)} å¼ å·²è§£ç å›¾åƒï¼ˆä¸é™é‡‡æ ·ï¼‰...")
            images = image_data
            # ç¡®ä¿æ˜¯ uint8 ç±»å‹
            if images.dtype != np.uint8:
                if images.max() <= 1.0:
                    images = (images * 255).astype(np.uint8)
                else:
                    images = images.astype(np.uint8)
        else:
            # éœ€è¦è§£ç çš„æ ¼å¼
            print(f"  è§£ç  {len(valid_indices)} å¼ å›¾åƒï¼ˆä¸é™é‡‡æ ·ï¼‰...")
            images = []
            for i in tqdm(range(len(valid_indices)), desc="  è§£ç å›¾åƒ", leave=False):
                try:
                    img = decode_image(image_data[i], image_lengths[i])
                    images.append(img)
                except Exception as e:
                    print(f"  âš ï¸  è§£ç å›¾åƒ {i} å¤±è´¥: {e}ï¼Œä½¿ç”¨é›¶å›¾åƒ")
                    # ä½¿ç”¨é›¶å›¾åƒä½œä¸ºå ä½ç¬¦
                    images.append(np.zeros((480, 640, 3), dtype=np.uint8))
            
            images = np.array(images)
        
        # æå–å³è‡‚å…³èŠ‚ï¼ˆåˆ— 7-13ï¼Œå¯¹åº” Joint1_R åˆ° Joint7_Rï¼‰
        # æ³¨æ„ï¼šjoint_states æœ‰14ç»´ï¼šå‰7ç»´æ˜¯å·¦è‡‚ï¼ˆJoint1_L åˆ° Joint7_Lï¼‰ï¼Œå7ç»´æ˜¯å³è‡‚ï¼ˆJoint1_R åˆ° Joint7_Rï¼‰
        right_joint_positions = joint_positions[:, 7:14]  # (T, 7) - å³è‡‚å…³èŠ‚ä½ç½®
        
        # å¤„ç†å…³èŠ‚ä½ç½®çš„ NaN
        right_joint_positions = handle_nan_values(right_joint_positions)
        print(f"  âœ… å¤„ç†åçš„å³è‡‚å…³èŠ‚ä½ç½®: {right_joint_positions.shape}")
        
        # è®¡ç®—å‡ ä½• actionï¼ˆä» EEF ä½ç½®å’Œæ–¹å‘è®¡ç®—ï¼‰
        print("  ğŸ”„ è®¡ç®—å‡ ä½• action...")
        eef_actions = np.zeros((len(eef_positions) - 1, 6))  # (T-1, 6)
        
        for i in range(len(eef_positions) - 1):
            ee_pos_t = eef_positions[i]
            ee_ori_t = axis_angles[i]
            ee_pos_t1 = eef_positions[i + 1]
            ee_ori_t1 = axis_angles[i + 1]
            
            action_6d = compute_geom_action(ee_pos_t, ee_ori_t, ee_pos_t1, ee_ori_t1)
            eef_actions[i] = action_6d
        
        # æœ€åä¸€ä¸ª action åº”è¯¥æ˜¯å…¨ 0ï¼ˆä¸åŠ¨ï¼‰
        last_action = np.zeros((1, 6))
        eef_actions = np.concatenate([eef_actions, last_action], axis=0)  # (T, 6)
        
        print(f"  âœ… EEF action ç»´åº¦: {eef_actions.shape} (6ç»´: xyzä½ç§» + è½´è§’æ—‹è½¬)")
        
        # å¤„ç†å¤¹çˆªåé¦ˆæ•°æ®
        # State çš„å¤¹çˆªéƒ¨åˆ†ï¼šç›´æ¥ä½¿ç”¨åŸå§‹çš„ç¬¬ä¸€ç»´æ•°å€¼ï¼ˆåªå¤„ç† NaNï¼‰
        gripper_states_for_state = right_gripper_feedback.copy()
        # å¤„ç† NaN å€¼
        gripper_states_for_state = handle_nan_values(gripper_states_for_state)
        print(f"  âœ… å¤¹çˆªçŠ¶æ€ï¼ˆåŸå§‹å€¼ï¼Œç”¨äº stateï¼‰: {gripper_states_for_state.shape}, èŒƒå›´ [{np.nanmin(gripper_states_for_state):.6f}, {np.nanmax(gripper_states_for_state):.6f}]")
        
        # Action çš„å¤¹çˆªéƒ¨åˆ†ï¼šè¯»å–åä¸€ä¸ªæ—¶åˆ»çš„ gripper å€¼
        # å°äºç­‰äº 0.4 å°±æ˜¯ 0ï¼Œå¤§äº 0.4 å°±æ˜¯ 1
        gripper_actions = np.zeros(len(gripper_states_for_state), dtype=np.float32)
        for i in range(len(gripper_states_for_state) - 1):
            # è¯»å–åä¸€ä¸ªæ—¶åˆ»çš„ gripper å€¼
            next_gripper = gripper_states_for_state[i + 1]
            if next_gripper <= 0.4:
                gripper_actions[i] = 0.0
            else:
                gripper_actions[i] = 1.0
        # æœ€åä¸€ä¸ªæ—¶é—´æ­¥æ²¡æœ‰åä¸€ä¸ªæ—¶åˆ»ï¼Œaction ä¸º 0ï¼ˆä¸åŠ¨ï¼‰
        gripper_actions[-1] = 0.0
        print(f"  âœ… å¤¹çˆª action: {gripper_actions.shape}, èŒƒå›´ [{np.min(gripper_actions):.2f}, {np.max(gripper_actions):.2f}]")
        print(f"  ğŸ“Š å¤¹çˆª action ç»Ÿè®¡: 0 çš„æ•°é‡={np.sum(gripper_actions == 0)}, 1 çš„æ•°é‡={np.sum(gripper_actions == 1)}")
        
        # ç»„åˆ actionï¼ˆ6ç»´ EEF action + 1ç»´å¤¹çˆª actionï¼‰ = 7ç»´
        actions = np.concatenate([eef_actions, gripper_actions[:, None]], axis=1)  # (T, 7)
        print(f"  âœ… æœ€ç»ˆ action ç»´åº¦: {actions.shape} (6ç»´ EEF + 1ç»´å¤¹çˆª)")
        
        # ç»„åˆ stateï¼ˆ3ç»´EEFä½ç½® + 3ç»´EEFæ–¹å‘(è½´è§’) + 1ç»´å¤¹çˆªå€¼ + 1ç»´å¤¹çˆªå€¼ç›¸åæ•°ï¼‰ = 8ç»´
        # State çš„å¤¹çˆªéƒ¨åˆ†ç›´æ¥ä½¿ç”¨ _gripper_feedback_R çš„ç¬¬ä¸€ç»´åŸå§‹æ•°å€¼åŠå…¶ç›¸åæ•°
        states = np.concatenate([
            eef_positions,  # (T, 3) - EEFä½ç½®
            axis_angles,    # (T, 3) - EEFæ–¹å‘(è½´è§’)
            gripper_states_for_state[:, None],  # (T, 1) - å¤¹çˆªå€¼
            -gripper_states_for_state[:, None],  # (T, 1) - å¤¹çˆªå€¼ç›¸åæ•°
        ], axis=1)  # (T, 8)
        print(f"  âœ… æœ€ç»ˆ state ç»´åº¦: {states.shape} (3ç»´EEFä½ç½® + 3ç»´EEFæ–¹å‘ + 1ç»´å¤¹çˆªå€¼ + 1ç»´å¤¹çˆªå€¼ç›¸åæ•°)")
        
        # ç¡®ä¿æ‰€æœ‰æ•°æ®é•¿åº¦ä¸€è‡´
        assert len(actions) == len(states) == len(images), \
            f"æ•°æ®é•¿åº¦ä¸ä¸€è‡´: actions={len(actions)}, states={len(states)}, images={len(images)}"
        
        # è½¬æ¢ä¸ºæ­¥éª¤åˆ—è¡¨
        steps = []
        for i in range(len(states)):
            # è°ƒæ•´å›¾åƒå¤§å°
            image = resize_image(images[i], (256, 256))
            
            # ç¡®ä¿å›¾åƒæ˜¯ uint8 ä¸”ä¸éœ€è¦é¢å¤–ç¼©æ”¾
            # decode_image é€šå¸¸è¿”å› uint8ï¼Œè¿™é‡Œåšä¸€ä¸ªé˜²å¾¡æ€§è½¬æ¢
            if image.dtype != np.uint8:
                if image.max() <= 1.0:
                    image = (image * 255).astype(np.uint8)
                else:
                    image = image.astype(np.uint8)
            else:
                # ç¡®ä¿æ˜¯ uint8 ç±»å‹
                image = image.astype(np.uint8)
            
            # å¦‚æœæ²¡æœ‰æ‰‹è…•ç›¸æœºï¼Œä½¿ç”¨ä¸»ç›¸æœº
            wrist_image = image.copy()
            
            steps.append({
                "image": image,
                "wrist_image": wrist_image,
                "state": states[i].astype(np.float32),
                "action": actions[i].astype(np.float32),
                "task": task_description,
            })
        
        return steps


def main(
    hdf5_path: str,
    output_repo_name: str,
    *,
    push_to_hub: bool = False,
    task_description: str = "Robot manipulation task",
    ignore_valid: bool = False,
    fps: float = 30.0,  # é»˜è®¤30fpsï¼ˆä¸é™é‡‡æ ·ï¼‰
):
    """
    ä¸»å‡½æ•°ï¼šå°† HDF5 æ ¼å¼æ•°æ®è½¬æ¢ä¸º LeRobot æ ¼å¼ï¼ˆä¸é™é‡‡æ ·ç‰ˆæœ¬ï¼‰
    
    Args:
        hdf5_path: HDF5 æ–‡ä»¶è·¯å¾„æˆ–åŒ…å« HDF5 æ–‡ä»¶çš„ç›®å½•è·¯å¾„
        output_repo_name: è¾“å‡ºæ•°æ®é›†åç§°ï¼ˆæ ¼å¼ï¼šyour_hf_username/dataset_nameï¼‰
        push_to_hub: æ˜¯å¦æ¨é€åˆ° Hugging Face Hub
        task_description: ä»»åŠ¡æè¿°
        ignore_valid: æ˜¯å¦å¿½ç•¥æœ‰æ•ˆæ€§æ ‡è®°ï¼Œä½¿ç”¨æ‰€æœ‰æ•°æ®
        fps: è¾“å‡ºæ•°æ®é›†çš„å¸§ç‡ï¼ˆé»˜è®¤30fpsï¼Œä¸é™é‡‡æ ·ï¼‰
    """
    # è§„èŒƒåŒ–è·¯å¾„ï¼ˆå¤„ç†åŒæ–œæ ç­‰é—®é¢˜ï¼‰
    hdf5_path = Path(str(hdf5_path).replace("//", "/")).resolve()
    
    # åˆ¤æ–­æ˜¯æ–‡ä»¶è¿˜æ˜¯ç›®å½•
    if hdf5_path.is_file():
        # å•ä¸ªæ–‡ä»¶
        hdf5_files = [hdf5_path]
    elif hdf5_path.is_dir():
        # ç›®å½•ï¼šæŸ¥æ‰¾æ‰€æœ‰ HDF5 æ–‡ä»¶ï¼ˆé€’å½’æœç´¢å­ç›®å½•ï¼‰
        hdf5_files = sorted(
            list(hdf5_path.glob("**/*.h5")) + list(hdf5_path.glob("**/*.hdf5"))
        )
        if not hdf5_files:
            raise FileNotFoundError(f"åœ¨ç›®å½• '{hdf5_path}' åŠå…¶å­ç›®å½•ä¸­æ‰¾ä¸åˆ°ä»»ä½• .h5 æˆ– .hdf5 æ–‡ä»¶")
    else:
        raise FileNotFoundError(f"è·¯å¾„ä¸å­˜åœ¨: {hdf5_path}")
    
    print(f"æ‰¾åˆ° {len(hdf5_files)} ä¸ª HDF5 æ–‡ä»¶")
    print(f"è¾“å‡ºå¸§ç‡: {fps} fpsï¼ˆä¸é™é‡‡æ ·ï¼‰")
    print(f"è¾“å‡ºæ•°æ®é›†: {output_repo_name}")
    
    # æ¸…ç†è¾“å‡ºç›®å½•
    output_path = HF_LEROBOT_HOME / output_repo_name
    if output_path.exists():
        shutil.rmtree(output_path)
    
    # åˆ›å»º LeRobot æ•°æ®é›†
    dataset = LeRobotDataset.create(
        repo_id=output_repo_name,
        robot_type="panda",
        fps=fps,
        features={
            "image": {
                "dtype": "image",
                "shape": (256, 256, 3),
                "names": ["height", "width", "channel"],
            },
            "wrist_image": {
                "dtype": "image",
                "shape": (256, 256, 3),
                "names": ["height", "width", "channel"],
            },
            "state": {
                "dtype": "float32",
                "shape": (8,),
                "names": ["state"],
            },
            "actions": {
                "dtype": "float32",
                "shape": (7,),  # 7 ç»´åŠ¨ä½œï¼ˆ6ç»´ EEF action + 1ç»´å¤¹çˆª actionï¼‰
                "names": ["actions"],
            },
        },
        image_writer_threads=10,
        image_writer_processes=5,
    )
    
    # éå†æ‰€æœ‰ HDF5 æ–‡ä»¶
    total_steps = 0
    for hdf5_file in tqdm(hdf5_files, desc="å¤„ç† HDF5 æ–‡ä»¶"):
        try:
            steps = load_hdf5_data(hdf5_file, task_description, ignore_valid)
            
            # å†™å…¥ LeRobot æ•°æ®é›†
            for step in steps:
                dataset.add_frame({
                    "image": step["image"],           # å·²ç»æ˜¯å¤„ç†å¥½çš„ uint8
                    "wrist_image": step["wrist_image"], # å·²ç»æ˜¯å¤„ç†å¥½çš„ uint8
                    "state": step["state"].astype(np.float32),
                    "actions": step["action"].astype(np.float32),
                    "task": step["task"],
                })
            
            dataset.save_episode()
            total_steps += len(steps)
            print(f"âœ… æˆåŠŸè½¬æ¢ {hdf5_file.name} ({len(steps)} æ­¥)")
            
        except Exception as e:
            print(f"âŒ å¤„ç† {hdf5_file} æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    print(f"\nâœ… è½¬æ¢å®Œæˆï¼æ€»å…± {total_steps} æ­¥ï¼ˆä¸é™é‡‡æ ·ï¼‰")
    print(f"æ•°æ®é›†ä¿å­˜åœ¨: {output_path}")
    
    # å¯é€‰ï¼šæ¨é€åˆ° Hugging Face Hub
    if push_to_hub:
        print("\næ¨é€åˆ° Hugging Face Hub...")
        dataset.push_to_hub(
            tags=["libero", "panda"],
            private=False,
            push_videos=True,
            license="apache-2.0",
        )
        print(f"âœ… å·²æ¨é€åˆ° Hub: {output_repo_name}")


if __name__ == "__main__":
    tyro.cli(main)

