{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/wyz/miniconda3/envs/pi0/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 导入完成\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import torch\n",
        "from typing import Dict, Any\n",
        "\n",
        "from openpi.training import config as _config\n",
        "from openpi.training import data_loader as _data_loader\n",
        "from openpi.training import checkpoints as _checkpoints\n",
        "from openpi import transforms as _transforms\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "os.environ[\"JAX_PLATFORMS\"] = \"cpu\"\n",
        "os.environ[\"TORCH_DISABLE_DYNAMO\"] = \"1\"\n",
        "os.environ[\"PYTORCH_JIT\"] = \"0\"\n",
        "\n",
        "print(\"✅ 导入完成\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "配置:\n",
            "  Config: pi05_pick_blue_bottle_libero_downsample4x\n",
            "  Data path: /home/wyz/.cache/huggingface/lerobot/your_hf_username/pick_blue_bottle_libero_downsample4x\n",
            "  Output file: pick_blue_bottle_actions_normalization_comparison.txt\n",
            "  Max samples: 10\n"
          ]
        }
      ],
      "source": [
        "# 配置参数\n",
        "config_name = \"pi05_pick_blue_bottle_libero_downsample4x\"\n",
        "local_data_path = \"/home/wyz/.cache/huggingface/lerobot/your_hf_username/pick_blue_bottle_libero_downsample4x\"\n",
        "output_txt_file = \"pick_blue_bottle_actions_normalization_comparison.txt\"\n",
        "\n",
        "# 要查看的样本数量（None 表示查看所有）\n",
        "max_samples = 10  # 可以设置为 None 查看所有样本\n",
        "\n",
        "print(f\"配置:\")\n",
        "print(f\"  Config: {config_name}\")\n",
        "print(f\"  Data path: {local_data_path}\")\n",
        "print(f\"  Output file: {output_txt_file}\")\n",
        "print(f\"  Max samples: {max_samples if max_samples else 'All'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading config and dataset...\n",
            "Found 101 parquet files\n",
            "Dataset length: 8472\n",
            "✅ Loaded norm stats from checkpoint\n"
          ]
        }
      ],
      "source": [
        "# 加载配置和数据\n",
        "print(\"Loading config and dataset...\")\n",
        "config = _config.get_config(config_name)\n",
        "data_config = config.data.create(config.assets_dirs, config.model)\n",
        "\n",
        "# 从本地路径加载数据集\n",
        "from datasets import load_dataset\n",
        "\n",
        "data_dir = pathlib.Path(local_data_path) / \"data\"\n",
        "if not data_dir.exists():\n",
        "    data_dir = pathlib.Path(local_data_path)\n",
        "\n",
        "parquet_files = list(data_dir.rglob(\"*.parquet\"))\n",
        "if parquet_files:\n",
        "    print(f\"Found {len(parquet_files)} parquet files\")\n",
        "    parquet_files = sorted(parquet_files)\n",
        "    hf_dataset = load_dataset(\"parquet\", data_files=[str(f) for f in parquet_files], split=\"train\")\n",
        "else:\n",
        "    try:\n",
        "        hf_dataset = load_dataset(\"parquet\", data_dir=str(data_dir), split=\"train\")\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Could not load from {data_dir}: {e}\")\n",
        "        hf_dataset = load_dataset(data_config.repo_id, split=\"train\")\n",
        "\n",
        "print(f\"Dataset length: {len(hf_dataset)}\")\n",
        "\n",
        "# 加载归一化统计信息\n",
        "ckpt_dir = pathlib.Path(\"/home/wyz/openpi/checkpoints/pi05_pick_blue_bottle_libero_downsample4x/pick_blue_bottle_finetune/20000\")\n",
        "norm_stats = _checkpoints.load_norm_stats(ckpt_dir / \"assets\", data_config.asset_id)\n",
        "print(f\"✅ Loaded norm stats from checkpoint\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing samples...\n",
            "✅ Processed 10 samples\n"
          ]
        }
      ],
      "source": [
        "# 处理样本并收集归一化前后的 actions\n",
        "def to_numpy(x):\n",
        "    if isinstance(x, torch.Tensor):\n",
        "        return x.cpu().numpy()\n",
        "    return np.asarray(x)\n",
        "\n",
        "def process_sample(raw_sample, sample_idx, episode_idx, frame_idx):\n",
        "    \"\"\"处理单个样本，返回归一化前后的 actions\"\"\"\n",
        "    # 获取原始 action（单个 action，不是 sequence）\n",
        "    raw_action = None\n",
        "    if \"actions\" in raw_sample:\n",
        "        raw_action = raw_sample[\"actions\"]\n",
        "        if hasattr(raw_action, 'numpy'):\n",
        "            raw_action = raw_action.numpy()\n",
        "        elif not isinstance(raw_action, np.ndarray):\n",
        "            raw_action = np.array(raw_action)\n",
        "        # 确保是 1D\n",
        "        if len(raw_action.shape) > 1:\n",
        "            raw_action = raw_action[0]\n",
        "    \n",
        "    if raw_action is None:\n",
        "        return None\n",
        "    \n",
        "    # 应用 transforms 获取归一化后的 action\n",
        "    # 首先应用 repack_transforms\n",
        "    sample_dict = {}\n",
        "    for key, value in raw_sample.items():\n",
        "        if isinstance(value, np.ndarray):\n",
        "            sample_dict[key] = value\n",
        "        elif hasattr(value, 'numpy'):\n",
        "            sample_dict[key] = value.numpy()\n",
        "        else:\n",
        "            sample_dict[key] = value\n",
        "    \n",
        "    # 确保 prompt 键存在（RepackTransform 需要）\n",
        "    # LeRobot 数据集中可能使用 \"task\" 而不是 \"prompt\"\n",
        "    if \"prompt\" not in sample_dict:\n",
        "        if \"task\" in sample_dict:\n",
        "            task = sample_dict[\"task\"]\n",
        "            if isinstance(task, bytes):\n",
        "                task = task.decode('utf-8')\n",
        "            sample_dict[\"prompt\"] = str(task)\n",
        "        else:\n",
        "            sample_dict[\"prompt\"] = \"pick blue bottle\"  # 默认 prompt\n",
        "    \n",
        "    # 确保所有数值数据都是 numpy array\n",
        "    for key in [\"actions\", \"state\"]:\n",
        "        if key in sample_dict:\n",
        "            if not isinstance(sample_dict[key], np.ndarray):\n",
        "                sample_dict[key] = np.asarray(sample_dict[key])\n",
        "    \n",
        "    # 应用 repack_transforms\n",
        "    for transform in data_config.repack_transforms.inputs:\n",
        "        sample_dict = transform(sample_dict)\n",
        "    \n",
        "    # 应用 data_transforms.inputs\n",
        "    for transform in data_config.data_transforms.inputs:\n",
        "        sample_dict = transform(sample_dict)\n",
        "    \n",
        "    # 再次确保 actions 是 numpy array（归一化需要）\n",
        "    if \"actions\" in sample_dict:\n",
        "        if not isinstance(sample_dict[\"actions\"], np.ndarray):\n",
        "            sample_dict[\"actions\"] = np.asarray(sample_dict[\"actions\"])\n",
        "    \n",
        "    # 应用归一化\n",
        "    normalize_transform = _transforms.Normalize(norm_stats, use_quantiles=data_config.use_quantile_norm)\n",
        "    sample_dict = normalize_transform(sample_dict)\n",
        "    \n",
        "    # 获取归一化后的 action\n",
        "    normalized_action = None\n",
        "    if \"actions\" in sample_dict:\n",
        "        normalized_action = to_numpy(sample_dict[\"actions\"])\n",
        "        if len(normalized_action.shape) > 1:\n",
        "            normalized_action = normalized_action[0]\n",
        "    \n",
        "    return {\n",
        "        \"sample_idx\": sample_idx,\n",
        "        \"episode_idx\": episode_idx,\n",
        "        \"frame_idx\": frame_idx,\n",
        "        \"raw_action\": raw_action,\n",
        "        \"normalized_action\": normalized_action,\n",
        "    }\n",
        "\n",
        "# 处理所有样本\n",
        "print(\"Processing samples...\")\n",
        "results = []\n",
        "num_samples_to_process = min(max_samples, len(hf_dataset)) if max_samples else len(hf_dataset)\n",
        "\n",
        "for i in range(num_samples_to_process):\n",
        "    raw_sample = hf_dataset[i]\n",
        "    episode_idx = raw_sample.get(\"episode_index\", i)\n",
        "    frame_idx = raw_sample.get(\"frame_index\", i)\n",
        "    \n",
        "    result = process_sample(raw_sample, i, episode_idx, frame_idx)\n",
        "    if result is not None:\n",
        "        results.append(result)\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "        print(f\"  Processed {i + 1}/{num_samples_to_process} samples...\")\n",
        "\n",
        "print(f\"✅ Processed {len(results)} samples\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing results to pick_blue_bottle_actions_normalization_comparison.txt...\n",
            "✅ 结果已保存到: pick_blue_bottle_actions_normalization_comparison.txt\n"
          ]
        }
      ],
      "source": [
        "# 保存归一化前后的 actions 到 txt 文件\n",
        "print(f\"Writing results to {output_txt_file}...\")\n",
        "\n",
        "with open(output_txt_file, 'w', encoding='utf-8') as f:\n",
        "    f.write(\"=\" * 100 + \"\\n\")\n",
        "    f.write(\"Pick Blue Bottle 数据集 - Actions 归一化前后对比\\n\")\n",
        "    f.write(\"=\" * 100 + \"\\n\\n\")\n",
        "    \n",
        "    f.write(f\"数据集: {config_name}\\n\")\n",
        "    f.write(f\"数据路径: {local_data_path}\\n\")\n",
        "    f.write(f\"总样本数: {len(results)}\\n\")\n",
        "    f.write(f\"归一化方法: {'Quantile' if data_config.use_quantile_norm else 'Z-score'}\\n\")\n",
        "    f.write(\"\\n\" + \"=\" * 100 + \"\\n\\n\")\n",
        "    \n",
        "    # 写入归一化统计信息\n",
        "    if \"actions\" in norm_stats:\n",
        "        stats = norm_stats[\"actions\"]\n",
        "        f.write(\"归一化统计信息 (Actions):\\n\")\n",
        "        f.write(\"-\" * 100 + \"\\n\")\n",
        "        if data_config.use_quantile_norm:\n",
        "            if stats.q01 is not None and stats.q99 is not None:\n",
        "                f.write(f\"  Q01: {stats.q01}\\n\")\n",
        "                f.write(f\"  Q99: {stats.q99}\\n\")\n",
        "        else:\n",
        "            f.write(f\"  Mean: {stats.mean}\\n\")\n",
        "            f.write(f\"  Std:  {stats.std}\\n\")\n",
        "        f.write(\"\\n\" + \"=\" * 100 + \"\\n\\n\")\n",
        "    \n",
        "    # 写入每个样本的对比\n",
        "    for idx, result in enumerate(results):\n",
        "        f.write(f\"样本 {idx + 1} / {len(results)}\\n\")\n",
        "        f.write(\"-\" * 100 + \"\\n\")\n",
        "        f.write(f\"  样本索引: {result['sample_idx']}\\n\")\n",
        "        f.write(f\"  Episode索引: {result['episode_idx']}\\n\")\n",
        "        f.write(f\"  Frame索引: {result['frame_idx']}\\n\")\n",
        "        f.write(\"\\n\")\n",
        "        \n",
        "        raw_action = result['raw_action']\n",
        "        normalized_action = result['normalized_action']\n",
        "        \n",
        "        f.write(\"  原始 Action (归一化前):\\n\")\n",
        "        f.write(f\"    Shape: {raw_action.shape}\\n\")\n",
        "        f.write(f\"    Values: {raw_action}\\n\")\n",
        "        f.write(f\"    Min: {raw_action.min():.6f}, Max: {raw_action.max():.6f}, Mean: {raw_action.mean():.6f}\\n\")\n",
        "        f.write(\"\\n\")\n",
        "        \n",
        "        if normalized_action is not None:\n",
        "            f.write(\"  归一化后的 Action:\\n\")\n",
        "            f.write(f\"    Shape: {normalized_action.shape}\\n\")\n",
        "            f.write(f\"    Values: {normalized_action}\\n\")\n",
        "            f.write(f\"    Min: {normalized_action.min():.6f}, Max: {normalized_action.max():.6f}, Mean: {normalized_action.mean():.6f}\\n\")\n",
        "            f.write(\"\\n\")\n",
        "            \n",
        "            # 计算每个维度的变化\n",
        "            f.write(\"  每个维度的变化:\\n\")\n",
        "            for dim in range(min(len(raw_action), len(normalized_action))):\n",
        "                raw_val = raw_action[dim]\n",
        "                norm_val = normalized_action[dim]\n",
        "                change = norm_val - raw_val\n",
        "                change_pct = (change / (abs(raw_val) + 1e-10)) * 100 if abs(raw_val) > 1e-10 else 0\n",
        "                f.write(f\"    Dim {dim:2d}: {raw_val:10.6f} -> {norm_val:10.6f} (变化: {change:10.6f}, {change_pct:6.2f}%)\\n\")\n",
        "        else:\n",
        "            f.write(\"  归一化后的 Action: None (处理失败)\\n\")\n",
        "        \n",
        "        f.write(\"\\n\" + \"=\" * 100 + \"\\n\\n\")\n",
        "    \n",
        "    # 写入汇总统计\n",
        "    f.write(\"\\n\" + \"=\" * 100 + \"\\n\")\n",
        "    f.write(\"汇总统计\\n\")\n",
        "    f.write(\"=\" * 100 + \"\\n\\n\")\n",
        "    \n",
        "    if results:\n",
        "        all_raw_actions = np.array([r['raw_action'] for r in results if r['raw_action'] is not None])\n",
        "        all_normalized_actions = np.array([r['normalized_action'] for r in results if r['normalized_action'] is not None])\n",
        "        \n",
        "        if len(all_raw_actions) > 0:\n",
        "            f.write(\"所有原始 Actions 的统计:\\n\")\n",
        "            f.write(f\"  Shape: {all_raw_actions.shape}\\n\")\n",
        "            f.write(f\"  Min: {all_raw_actions.min():.6f}\\n\")\n",
        "            f.write(f\"  Max: {all_raw_actions.max():.6f}\\n\")\n",
        "            f.write(f\"  Mean: {all_raw_actions.mean():.6f}\\n\")\n",
        "            f.write(f\"  Std:  {all_raw_actions.std():.6f}\\n\")\n",
        "            f.write(\"\\n\")\n",
        "            \n",
        "            f.write(\"每个维度的原始 Actions 统计:\\n\")\n",
        "            for dim in range(all_raw_actions.shape[1]):\n",
        "                dim_values = all_raw_actions[:, dim]\n",
        "                f.write(f\"  Dim {dim:2d}: min={dim_values.min():10.6f}, max={dim_values.max():10.6f}, mean={dim_values.mean():10.6f}, std={dim_values.std():10.6f}\\n\")\n",
        "            f.write(\"\\n\")\n",
        "        \n",
        "        if len(all_normalized_actions) > 0:\n",
        "            f.write(\"所有归一化 Actions 的统计:\\n\")\n",
        "            f.write(f\"  Shape: {all_normalized_actions.shape}\\n\")\n",
        "            f.write(f\"  Min: {all_normalized_actions.min():.6f}\\n\")\n",
        "            f.write(f\"  Max: {all_normalized_actions.max():.6f}\\n\")\n",
        "            f.write(f\"  Mean: {all_normalized_actions.mean():.6f}\\n\")\n",
        "            f.write(f\"  Std:  {all_normalized_actions.std():.6f}\\n\")\n",
        "            f.write(\"\\n\")\n",
        "            \n",
        "            f.write(\"每个维度的归一化 Actions 统计:\\n\")\n",
        "            for dim in range(all_normalized_actions.shape[1]):\n",
        "                dim_values = all_normalized_actions[:, dim]\n",
        "                f.write(f\"  Dim {dim:2d}: min={dim_values.min():10.6f}, max={dim_values.max():10.6f}, mean={dim_values.mean():10.6f}, std={dim_values.std():10.6f}\\n\")\n",
        "\n",
        "print(f\"✅ 结果已保存到: {output_txt_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 显示前几个样本的摘要\n",
        "print(\"\\n\" + \"=\" * 100)\n",
        "print(\"前 5 个样本的摘要\")\n",
        "print(\"=\" * 100)\n",
        "\n",
        "for idx, result in enumerate(results[:5]):\n",
        "    print(f\"\\n样本 {idx + 1}:\")\n",
        "    print(f\"  Episode: {result['episode_idx']}, Frame: {result['frame_idx']}\")\n",
        "    \n",
        "    raw_action = result['raw_action']\n",
        "    normalized_action = result['normalized_action']\n",
        "    \n",
        "    print(f\"  原始 Action (归一化前):\")\n",
        "    print(f\"    Shape: {raw_action.shape}\")\n",
        "    print(f\"    Values: {raw_action}\")\n",
        "    print(f\"    Min: {raw_action.min():.6f}, Max: {raw_action.max():.6f}, Mean: {raw_action.mean():.6f}\")\n",
        "    \n",
        "    if normalized_action is not None:\n",
        "        print(f\"  归一化 Action:\")\n",
        "        print(f\"    Shape: {normalized_action.shape}\")\n",
        "        print(f\"    Values: {normalized_action}\")\n",
        "        print(f\"    Min: {normalized_action.min():.6f}, Max: {normalized_action.max():.6f}, Mean: {normalized_action.mean():.6f}\")\n",
        "        \n",
        "        # 显示每个维度的变化\n",
        "        print(f\"  每个维度的变化:\")\n",
        "        for dim in range(min(len(raw_action), len(normalized_action))):\n",
        "            raw_val = raw_action[dim]\n",
        "            norm_val = normalized_action[dim]\n",
        "            change = norm_val - raw_val\n",
        "            change_pct = (change / (abs(raw_val) + 1e-10)) * 100 if abs(raw_val) > 1e-10 else 0\n",
        "            print(f\"    Dim {dim:2d}: {raw_val:10.6f} -> {norm_val:10.6f} (变化: {change:10.6f}, {change_pct:6.2f}%)\")\n",
        "    else:\n",
        "        print(f\"  归一化 Action: None (处理失败)\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 100)\n",
        "print(f\"✅ 完整结果已保存到: {output_txt_file}\")\n",
        "print(f\"   共处理了 {len(results)} 个样本\")\n",
        "print(\"=\" * 100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pi0",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
