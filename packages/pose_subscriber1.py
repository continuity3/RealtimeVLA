#!/usr/bin/env python3
"""
Minimal TEST version for OpenPI LIBERO policy.

Goal:
- Make OpenPI LIBERO policy inference RUN successfully
- No physical meaning, only pipeline verification
"""

import argparse
import json
import pathlib
import sys
import time
import numpy as np
from datetime import datetime

from openpi_client import websocket_client_policy

# OpenCV ç”¨äºå¯è§†åŒ–
try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    print("âš ï¸  cv2 not available. Install with: pip install opencv-python")

# RealSense ç›¸æœºæ”¯æŒ
try:
    import pyrealsense2 as rs
    REALSENSE_AVAILABLE = True
except ImportError:
    REALSENSE_AVAILABLE = False
    print("âš ï¸  pyrealsense2 not available. Install with: pip install pyrealsense2")

try:
    import rclpy
    from rclpy.node import Node
    from geometry_msgs.msg import PoseStamped
    from std_msgs.msg import Float64MultiArray, Float64
    from sensor_msgs.msg import JointState
    ROS2_AVAILABLE = True
except Exception:
    rclpy = None
    Node = None
    PoseStamped = None
    Float64MultiArray = None
    Float64 = None
    JointState = None
    ROS2_AVAILABLE = False


# =========================
# Configuration
# =========================

IMG_SIZE = 224

# LIBERO expects 8-dim joint state
state = [0.0] * 8

# Default task instruction (can be overridden via --prompt argument)
task_instruction = "Pick up the blue square"

# åå½’ä¸€åŒ–ç›¸å…³å…¨å±€å˜é‡
action_norm_stats = None
use_quantile_norm = False


# =========================
# åå½’ä¸€åŒ–åŠŸèƒ½
# =========================

def load_norm_stats(norm_stats_path: str | pathlib.Path):
    """
    åŠ è½½å½’ä¸€åŒ–ç»Ÿè®¡ä¿¡æ¯ï¼ˆä¸ä¾èµ– openpi åŒ…ï¼‰
    
    Args:
        norm_stats_path: norm_stats.json æ–‡ä»¶çš„è·¯å¾„
    """
    global action_norm_stats, use_quantile_norm
    
    norm_stats_path = pathlib.Path(norm_stats_path)
    if not norm_stats_path.exists():
        print(f"âš ï¸  Norm stats file not found: {norm_stats_path}")
        print("    Actions will not be unnormalized.")
        return False
    
    try:
        with open(norm_stats_path, 'r') as f:
            data = json.load(f)
        
        # è§£æ JSON ç»“æ„ï¼š{"norm_stats": {"actions": {...}, "state": {...}}}
        if "norm_stats" in data:
            norm_stats_dict = data["norm_stats"]
        else:
            norm_stats_dict = data
        
        if "actions" not in norm_stats_dict:
            print(f"âš ï¸  No 'actions' key in norm stats file")
            return False
        
        action_stats = norm_stats_dict["actions"]
        action_norm_stats = {
            "mean": np.array(action_stats.get("mean", [])),
            "std": np.array(action_stats.get("std", [])),
            "q01": np.array(action_stats.get("q01", [])) if action_stats.get("q01") is not None else None,
            "q99": np.array(action_stats.get("q99", [])) if action_stats.get("q99") is not None else None,
        }
        
        # åˆ¤æ–­æ˜¯å¦ä½¿ç”¨åˆ†ä½æ•°å½’ä¸€åŒ–ï¼ˆå¦‚æœæœ‰ q01 å’Œ q99ï¼Œé€šå¸¸ä½¿ç”¨åˆ†ä½æ•°å½’ä¸€åŒ–ï¼‰
        use_quantile_norm = action_norm_stats["q01"] is not None and action_norm_stats["q99"] is not None
        
        print(f"âœ… Loaded norm stats from: {norm_stats_path}")
        print(f"   Action stats shape - mean: {action_norm_stats['mean'].shape}, std: {action_norm_stats['std'].shape}")
        if use_quantile_norm:
            print(f"   Using quantile normalization (Q01, Q99)")
            if action_norm_stats["q01"] is not None:
                print(f"   Actions Q01 shape: {action_norm_stats['q01'].shape}, values: {action_norm_stats['q01']}")
            if action_norm_stats["q99"] is not None:
                print(f"   Actions Q99 shape: {action_norm_stats['q99'].shape}, values: {action_norm_stats['q99']}")
        else:
            print(f"   Using z-score normalization (mean, std)")
            print(f"   Actions Mean shape: {action_norm_stats['mean'].shape}, values: {action_norm_stats['mean']}")
            print(f"   Actions Std shape: {action_norm_stats['std'].shape}, values: {action_norm_stats['std']}")
        
        return True
    except Exception as e:
        print(f"âŒ Failed to load norm stats: {e}")
        import traceback
        traceback.print_exc()
        return False


def unnormalize_action(normalized_action: np.ndarray) -> np.ndarray:
    """
    åå½’ä¸€åŒ– actionï¼ˆä¸ä¾èµ– openpi åŒ…ï¼‰
    
    Args:
        normalized_action: å½’ä¸€åŒ–åçš„ action (å¯ä»¥æ˜¯ 1D æˆ– 2D æ•°ç»„)
    
    Returns:
        åå½’ä¸€åŒ–åçš„ action
    """
    global action_norm_stats, use_quantile_norm
    
    if action_norm_stats is None:
        # å¦‚æœæ²¡æœ‰åŠ è½½ç»Ÿè®¡ä¿¡æ¯ï¼Œç›´æ¥è¿”å›åŸå€¼
        print("âš ï¸  Warning: action_norm_stats is None, returning normalized action as-is")
        return normalized_action
    
    # ç¡®ä¿æ˜¯ numpy æ•°ç»„
    action = np.asarray(normalized_action)
    original_shape = action.shape
    
    # å¦‚æœæ˜¯ 2Dï¼Œå…ˆå¤„ç†ä¸º 1Dï¼ˆå–ç¬¬ä¸€ä¸ªæ—¶é—´æ­¥ï¼‰
    if action.ndim > 1:
        action = action.reshape(-1, action.shape[-1])
        is_2d = True
    else:
        action = action.reshape(1, -1)
        is_2d = False
    
    action_dim = action.shape[-1]
    
    if use_quantile_norm:
        # åˆ†ä½æ•°åå½’ä¸€åŒ–: (x + 1.0) / 2.0 * (q99 - q01 + 1e-6) + q01
        q01 = action_norm_stats["q01"]
        q99 = action_norm_stats["q99"]
        
        # ç¡®ä¿ q01 å’Œ q99 æ˜¯ 1D æ•°ç»„
        if q01.ndim > 1:
            q01 = q01.flatten()
        if q99.ndim > 1:
            q99 = q99.flatten()
        
        # å¤„ç†ç»´åº¦ä¸åŒ¹é…çš„æƒ…å†µ
        if q01.shape[0] < action_dim:
            # å¦‚æœç»Ÿè®¡ä¿¡æ¯ç»´åº¦å°äº action ç»´åº¦ï¼Œåªå¯¹å‰é¢çš„ç»´åº¦è¿›è¡Œåå½’ä¸€åŒ–
            unnormalized = np.zeros_like(action)
            dim = q01.shape[0]
            q01_sel = q01[:dim]
            q99_sel = q99[:dim]
            unnormalized[..., :dim] = (action[..., :dim] + 1.0) / 2.0 * (q99_sel - q01_sel + 1e-6) + q01_sel
            unnormalized[..., dim:] = action[..., dim:]  # åé¢çš„ç»´åº¦ä¿æŒä¸å˜
        else:
            # æˆªå–åˆ°åŒ¹é…çš„ç»´åº¦
            q01_sel = q01[:action_dim]
            q99_sel = q99[:action_dim]
            unnormalized = (action + 1.0) / 2.0 * (q99_sel - q01_sel + 1e-6) + q01_sel
    else:
        # Z-score åå½’ä¸€åŒ–: x * (std + 1e-6) + mean
        mean = action_norm_stats["mean"]
        std = action_norm_stats["std"]
        
        # ç¡®ä¿ mean å’Œ std æ˜¯ 1D æ•°ç»„
        if mean.ndim > 1:
            mean = mean.flatten()
        if std.ndim > 1:
            std = std.flatten()
        
        # å¤„ç†ç»´åº¦ä¸åŒ¹é…çš„æƒ…å†µ
        if mean.shape[0] < action_dim:
            # å¦‚æœç»Ÿè®¡ä¿¡æ¯ç»´åº¦å°äº action ç»´åº¦ï¼Œåªå¯¹å‰é¢çš„ç»´åº¦è¿›è¡Œåå½’ä¸€åŒ–
            unnormalized = np.zeros_like(action)
            dim = mean.shape[0]
            unnormalized[..., :dim] = action[..., :dim] * (std[:dim] + 1e-6) + mean[:dim]
            unnormalized[..., dim:] = action[..., dim:]  # åé¢çš„ç»´åº¦ä¿æŒä¸å˜
        else:
            # æˆªå–åˆ°åŒ¹é…çš„ç»´åº¦
            mean_sel = mean[:action_dim]
            std_sel = std[:action_dim]
            unnormalized = action * (std_sel + 1e-6) + mean_sel
    
    # æ¢å¤åŸå§‹å½¢çŠ¶
    if is_2d:
        return unnormalized.reshape(original_shape)
    else:
        return unnormalized.reshape(original_shape)


# =========================
# RealSense Camera Manager
# =========================

class RealSenseCameraManager:
    """ç®¡ç† RealSense ç›¸æœºï¼ˆLIBERO ç‰ˆæœ¬ï¼‰"""
    
    def __init__(self, camera_serial=None, width=640, height=480, fps=30):
        """
        åˆå§‹åŒ– RealSense ç›¸æœºç®¡ç†å™¨
        
        Args:
            camera_serial: ç›¸æœºåºåˆ—å·ï¼Œå¦‚æœä¸º Noneï¼Œå°†è‡ªåŠ¨æ£€æµ‹ç¬¬ä¸€ä¸ªå¯ç”¨ç›¸æœº
            width: å›¾åƒå®½åº¦
            height: å›¾åƒé«˜åº¦
            fps: å¸§ç‡
        """
        if not REALSENSE_AVAILABLE:
            raise RuntimeError("pyrealsense2 is not available. Please install it.")
        
        self.width = width
        self.height = height
        self.fps = fps
        self.pipeline = None
        
        # æ£€æµ‹å¯ç”¨ç›¸æœº
        ctx = rs.context()
        devices = ctx.query_devices()
        
        print(f"Found {len(devices)} RealSense device(s):")
        available_serials = []
        for dev in devices:
            serial = dev.get_info(rs.camera_info.serial_number)
            name = dev.get_info(rs.camera_info.name)
            print(f"  - {name} (Serial: {serial})")
            available_serials.append(serial)
        
        if len(devices) == 0:
            raise RuntimeError("No RealSense cameras found!")
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šåºåˆ—å·ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨ç›¸æœº
        if camera_serial is None:
            camera_serial = available_serials[0]
        
        # åˆå§‹åŒ–ç›¸æœº
        try:
            pipeline = rs.pipeline()
            config = rs.config()
            config.enable_device(camera_serial)
            config.enable_stream(rs.stream.color, width, height, rs.format.bgr8, fps)
            
            pipeline.start(config)
            self.pipeline = pipeline
            print(f"âœ… Started camera (Serial: {camera_serial})")
        except Exception as e:
            print(f"âš ï¸  Failed to start camera (Serial: {camera_serial}): {e}")
            raise
    
    def get_image(self):
        """
        è·å–å›¾åƒ
        
        Returns:
            numpy array in RGB format (H, W, 3), uint8, æˆ– None å¦‚æœç›¸æœºä¸å¯ç”¨
        """
        if self.pipeline is None:
            return None
        
        try:
            frames = self.pipeline.wait_for_frames(timeout_ms=1000)
            color_frame = frames.get_color_frame()
            
            if color_frame:
                # è½¬æ¢ä¸º numpy æ•°ç»„ (BGR format)
                img = np.asanyarray(color_frame.get_data())
                # BGR -> RGB
                img = img[:, :, ::-1]
                return img
        except Exception as e:
            print(f"âš ï¸  Error reading from camera: {e}")
        
        return None
    
    def stop(self):
        """åœæ­¢ç›¸æœº"""
        if self.pipeline is not None:
            try:
                self.pipeline.stop()
                print("âœ… Stopped camera")
            except Exception as e:
                print(f"âš ï¸  Error stopping camera: {e}")


# =========================
# ROS2 Node
# =========================

if ROS2_AVAILABLE:
    class PoseSubscriber(Node):
        def __init__(self, pose_topic: str, action_topic: str, joint_states_topic: str = "/joint_states", gripper_topic: str = "/gripper/feedback_R"):
            super().__init__('pose_subscriber_libero')
            self.get_logger().info(f'Subscribing to pose topic: {pose_topic}')
            self.get_logger().info(f'Subscribing to joint_states topic: {joint_states_topic}')
            self.get_logger().info(f'Subscribing to gripper topic: {gripper_topic}')
            self.get_logger().info(f'Publishing actions to topic: {action_topic}')
            
            # è®¢é˜…ä½å§¿è¯é¢˜
            self.create_subscription(
                PoseStamped,
                pose_topic,
                self.pose_callback,
                10,
            )
            
            # è®¢é˜…å…³èŠ‚çŠ¶æ€è¯é¢˜
            self.create_subscription(
                JointState,
                joint_states_topic,
                self.joint_states_callback,
                10,
            )
            
            # è®¢é˜…å³å¤¹çˆªè¯é¢˜ï¼ˆç”¨äºè¯»å–çœŸå®çš„å¤¹çˆªå€¼ï¼‰
            self.create_subscription(
                Float64,
                gripper_topic,
                self.gripper_callback,
                10,
            )
            
            # å‘å¸ƒåŠ¨ä½œè¯é¢˜
            self.action_publisher = self.create_publisher(
                Float64MultiArray,
                action_topic,
                10
            )
            
            self.latest_action = None
            self.latest_joint_positions = None  # 7ä¸ªå³è‡‚å…³èŠ‚ä½ç½®
            self.latest_gripper_value = 0.0  # å³å¤¹çˆªå€¼ï¼ˆåˆå§‹ä¸º0ï¼Œç­‰å¾…æ¥æ”¶ï¼‰
            self.latest_state = np.array([0.0] * 8, dtype=np.float32)  # LIBERO éœ€è¦ 8 ç»´

        def pose_callback(self, msg: PoseStamped):
            # Only log, not used for control yet
            p = msg.pose.position
            self.get_logger().info(
                f"Pose: ({p.x:.3f}, {p.y:.3f}, {p.z:.3f})"
            )
        
        def joint_states_callback(self, msg: JointState):
            """å¤„ç†å…³èŠ‚çŠ¶æ€æ¶ˆæ¯"""
            if len(msg.position) >= 14:
                # æå–ç¬¬ 7-13 ç»´ï¼ˆç´¢å¼• 7-12ï¼Œå…± 7 ä¸ªå€¼ï¼‰- å³è‡‚å…³èŠ‚ä½ç½®
                joint_positions = np.array(msg.position[7:14], dtype=np.float32)
                self.latest_joint_positions = joint_positions
                # ä½¿ç”¨æœ€æ–°çš„å¤¹çˆªå€¼ï¼ˆå¦‚æœå·²æ¥æ”¶ï¼‰æˆ–ä½¿ç”¨0
                self._update_state()
            else:
                self.get_logger().warn(f'JointState has {len(msg.position)} positions, expected at least 14')
        
        def gripper_callback(self, msg: Float64):
            """å¤„ç†å³å¤¹çˆªå€¼æ¶ˆæ¯"""
            # å¤¹çˆªå€¼èŒƒå›´é€šå¸¸æ˜¯ [0.0, 1.0] (0=å…¨å¼€, 1=å…¨é—­)
            self.latest_gripper_value = float(msg.data)
            self.get_logger().debug(f'Updated gripper value: {self.latest_gripper_value}')
            # æ›´æ–°çŠ¶æ€
            self._update_state()
        
        def _update_state(self):
            """æ›´æ–°çŠ¶æ€ï¼ˆ7ä¸ªå…³èŠ‚ä½ç½® + 1ä¸ªå¤¹çˆªå€¼ï¼‰"""
            if self.latest_joint_positions is not None:
                # ç»„åˆå³è‡‚å…³èŠ‚ä½ç½®å’Œå³å¤¹çˆªå€¼
                self.latest_state = np.concatenate([
                    self.latest_joint_positions,
                    np.array([self.latest_gripper_value], dtype=np.float32)
                ])
                self.get_logger().debug(f'Updated state: {self.latest_state}')
        
        def publish_action(self, action: np.ndarray):
            """å‘å¸ƒåŠ¨ä½œä¸º Float64MultiArray æ¶ˆæ¯ï¼ˆå·²åå½’ä¸€åŒ–ï¼‰"""
            if action is None:
                return
            
            # å…ˆè¿›è¡Œåå½’ä¸€åŒ–
            action = unnormalize_action(action)
            
            # ç¡®ä¿æ˜¯ 1D æ•°ç»„ï¼ˆå¦‚æœæ˜¯ action chunkï¼Œå–ç¬¬ä¸€ä¸ªåŠ¨ä½œï¼‰
            if action.ndim > 1:
                action = action[0]  # å–ç¬¬ä¸€ä¸ªæ—¶é—´æ­¥çš„åŠ¨ä½œ
            
            # å¤„ç†gripperå€¼ï¼šå¦‚æœæœ€åä¸€ç»´å¤§äº0.02ï¼Œè‡ªåŠ¨å˜ä¸º1ï¼ˆè®©æœºæ¢°è‡‚é—­åˆï¼‰
            action_processed = action.copy()
            if len(action_processed) >= 8:
                # æœ€åä¸€ç»´æ˜¯gripperå€¼ï¼ˆç´¢å¼•7ï¼‰
                original_gripper = action_processed[7]
                self.get_logger().info(f'ğŸ” Raw gripper value (before processing): {original_gripper:.6f}')
                
                # å¦‚æœgripperå€¼å¤§äº0.02ï¼Œè®¾ç½®ä¸º1.0ï¼ˆé—­åˆï¼‰
                # æ³¨æ„ï¼šå¦‚æœgripperå€¼æ˜¯è´Ÿæ•°ï¼Œå¯èƒ½æ˜¯å½’ä¸€åŒ–åçš„å€¼ï¼Œéœ€è¦æ£€æŸ¥æ˜¯å¦éœ€è¦å–ç»å¯¹å€¼
                if original_gripper > 0.02:
                    action_processed[7] = 1.0
                    self.get_logger().info(f'âœ… Gripper value {original_gripper:.4f} > 0.02, set to 1.0 (close)')
                elif original_gripper < -0.02:
                    # å¦‚æœgripperå€¼æ˜¯è´Ÿæ•°ä¸”ç»å¯¹å€¼å¤§äº0.02ï¼Œå¯èƒ½æ˜¯å½’ä¸€åŒ–åçš„"é—­åˆ"ä¿¡å·
                    # è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥è®¾ç½®ä¸º1.0
                    action_processed[7] = 1.0
                    self.get_logger().info(f'âœ… Gripper value {original_gripper:.4f} < -0.02 (negative close signal), set to 1.0 (close)')
                else:
                    # ä¿æŒåŸå€¼ï¼ˆé€šå¸¸æ˜¯0æˆ–æ¥è¿‘0ï¼Œè¡¨ç¤ºæ‰“å¼€ï¼‰
                    action_processed[7] = 0.0  # ç¡®ä¿æ‰“å¼€çŠ¶æ€ä¸º0
                    self.get_logger().info(f'ğŸ“Œ Gripper value {original_gripper:.4f} in [-0.02, 0.02], set to 0.0 (open)')
            
            # è½¬æ¢ä¸º float64 åˆ—è¡¨
            action_list = action_processed.astype(np.float64).tolist()
            
            # åˆ›å»º Float64MultiArray æ¶ˆæ¯
            msg = Float64MultiArray()
            msg.data = action_list
            
            # å‘å¸ƒæ¶ˆæ¯
            self.action_publisher.publish(msg)
            self.latest_action = action_processed
            self.get_logger().debug(f'Published action: {action_list}')
else:
    # å ä½ç¬¦ç±»ï¼ˆå½“ ROS2 ä¸å¯ç”¨æ—¶ï¼‰
    class PoseSubscriber:
        def __init__(self, pose_topic: str, action_topic: str):
            pass
        
        def publish_action(self, action: np.ndarray):
            """å ä½ç¬¦æ–¹æ³•"""
            pass

def warmup_inference(client: websocket_client_policy.WebsocketClientPolicy):
    """
    é¢„ç¼–è¯‘ï¼ˆé¢„çƒ­ï¼‰æ¨ç†ï¼Œé¿å…ç¬¬ä¸€æ¬¡çœŸå®æ¨ç†æ—¶çš„å»¶è¿Ÿå¯¼è‡´çš„è¶…æ—¶
    
    Args:
        client: WebSocket å®¢æˆ·ç«¯
    """
    print("ğŸ”¥ Warming up inference server (pre-compiling)...")
    try:
        # åˆ›å»º dummy observationï¼ˆä¸çœŸå® observation æ ¼å¼ç›¸åŒï¼‰
        dummy_state = np.array(state, dtype=np.float32)  # 8 ç»´
        dummy_image = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)
        dummy_wrist_image = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)
        
        dummy_observation = {
            "observation/state": dummy_state,
            "observation/image": dummy_image,
            "observation/wrist_image": dummy_wrist_image,
            "prompt": task_instruction,
        }
        
        # æ‰§è¡Œä¸€æ¬¡æ¨ç†ï¼ˆé¢„ç¼–è¯‘ï¼‰
        result = client.infer(dummy_observation)
        print("âœ… Warmup inference completed successfully")
        if result.get("actions") is not None:
            print(f"   Warmup action shape: {result['actions'].shape}")
        return True
    except Exception as e:
        print(f"âš ï¸  Warmup inference failed: {e}")
        print("   Continuing anyway, but first real inference may be slow...")
        return False


def ensure_hwc_uint8(img: np.ndarray) -> np.ndarray:
    """
    Ensure image is (H, W, 3) uint8 for LIBERO policy.
    LIBERO expects images in HWC format: (224, 224, 3)
    """
    img = np.asarray(img)

    # å»æ‰ batch ç»´
    if img.ndim == 4 and img.shape[0] == 1:
        img = img[0]

    # CHW -> HWC (å¦‚æœå½“å‰æ˜¯ CHW æ ¼å¼)
    if img.ndim == 3 and img.shape[0] == 3:
        img = np.transpose(img, (1, 2, 0))

    # ç°åº¦ -> RGB
    if img.ndim == 2:
        img = np.repeat(img[:, :, None], 3, axis=2)

    # å•é€šé“ -> 3 é€šé“
    if img.ndim == 3 and img.shape[2] == 1:
        img = np.repeat(img, 3, axis=2)

    # ç¡®ä¿æ˜¯ (224, 224, 3)
    if img.shape != (IMG_SIZE, IMG_SIZE, 3):
        # å¦‚æœå°ºå¯¸ä¸å¯¹ï¼Œè°ƒæ•´å¤§å°
        from PIL import Image
        img_pil = Image.fromarray(img)
        img_pil = img_pil.resize((IMG_SIZE, IMG_SIZE), Image.BILINEAR)
        img = np.array(img_pil)

    assert img.shape == (IMG_SIZE, IMG_SIZE, 3), f"Bad image shape: {img.shape}, expected ({IMG_SIZE}, {IMG_SIZE}, 3)"

    return img.astype(np.uint8)


def main(argv=None):
    parser = argparse.ArgumentParser(
        description='ROS2 PoseStamped subscriber with OpenPI LIBERO policy inference',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Test mode (no ROS2 required):
  python3 packages/pose_subscriber_libero.py --test-mode
  
  # With ROS2:
  python3 packages/pose_subscriber_libero.py --topic /pose
  
  # Custom server:
  python3 packages/pose_subscriber_libero.py --test-mode --host localhost --port 8001
        """
    )
    parser.add_argument('--topic', '-t', default='/pose', help='ROS2 topic to subscribe to (pose)')
    parser.add_argument('--action-topic', default='/libero/actions', 
                       help='ROS2 topic to publish actions (default: /libero/actions)')
    parser.add_argument('--joint-states-topic', default='/joint_states',
                       help='ROS2 topic to subscribe to for joint states (default: /joint_states)')
    parser.add_argument('--gripper-topic', default='/gripper/feedback_R',
                       help='ROS2 topic to subscribe to for right gripper value (default: /gripper/feedback_R)')

    parser.add_argument('--host', default='localhost', help='Policy server host (default: localhost)')
    parser.add_argument('--port', type=int, default=8000, help='Policy server port (default: 8000)')
    parser.add_argument('--test-mode', action='store_true', 
                       help='Run in test mode without ROS2 (for testing policy server connection)')
    parser.add_argument('--publish-actions', action='store_true', default=True,
                       help='Publish actions to ROS2 topic (default: True)')
    parser.add_argument('--use-realsense', action='store_true',
                       help='Use RealSense camera instead of fake images')
    parser.add_argument('--camera-serial', type=str, default=None,
                       help='RealSense serial number (if not specified, uses first available camera)')
    parser.add_argument('--show-camera', action='store_true',
                       help='Show RealSense camera feed in a window (requires opencv-python)')
    parser.add_argument('--record', type=str, default=None,
                       help='Record actions and images to a file (specify output directory, e.g., "data/recordings")')
    parser.add_argument('--norm-stats', type=str, default=None,
                       help='Path to norm_stats.json file for action unnormalization. Example: "assets/pi05_pick_blue_bottle_libero_downsample4x/your_hf_username/pick_blue_bottle_libero_downsample4x/norm_stats.json"')
    parser.add_argument('--auto-find-norm-stats', action='store_true',
                       help='Automatically search for norm_stats.json in common locations (assets/, checkpoints/)')
    args = parser.parse_args(argv)
    
    # åŠ è½½å½’ä¸€åŒ–ç»Ÿè®¡ä¿¡æ¯
    norm_stats_loaded = False
    if args.norm_stats:
        norm_stats_loaded = load_norm_stats(args.norm_stats)
    elif args.auto_find_norm_stats:
        # è‡ªåŠ¨æŸ¥æ‰¾ norm_stats.json
        search_paths = [
            pathlib.Path("assets") / "pi05_pick_blue_bottle_libero_downsample4x" / "your_hf_username" / "pick_blue_bottle_libero_downsample4x" / "norm_stats.json",
            pathlib.Path("assets") / "pi05_libero" / "your_hf_username" / "pick_blue_bottle_libero_downsample4x" / "norm_stats.json",
            pathlib.Path("checkpoints") / "pi05_pick_blue_bottle_libero_downsample4x" / "*" / "assets" / "*" / "norm_stats.json",
        ]
        for search_path in search_paths:
            # å¤„ç†é€šé…ç¬¦
            if "*" in str(search_path):
                import glob
                matches = glob.glob(str(search_path))
                for match in matches:
                    if pathlib.Path(match).exists():
                        norm_stats_loaded = load_norm_stats(match)
                        if norm_stats_loaded:
                            break
            else:
                if search_path.exists():
                    norm_stats_loaded = load_norm_stats(search_path)
                    if norm_stats_loaded:
                        break
        if not norm_stats_loaded:
            print("âš ï¸  Could not auto-find norm_stats.json, please specify --norm-stats")
    
    if not norm_stats_loaded:
        print("â„¹ï¸  Actions will not be unnormalized (no norm stats loaded)")

    # åˆå§‹åŒ–è®°å½•åŠŸèƒ½
    global recording_enabled, recording_dir, recording_file, step_count
    if args.record:
        recording_enabled = True
        recording_dir = pathlib.Path(args.record)
        recording_dir.mkdir(parents=True, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        recording_file = recording_dir / f"actions_{timestamp}.txt"
        print(f"ğŸ“ Recording enabled: {recording_file}")
        # å†™å…¥æ–‡ä»¶å¤´
        with open(recording_file, 'w') as f:
            f.write(f"# Action and Image Recording\n")
            f.write(f"# Started at: {datetime.now().isoformat()}\n")
            f.write(f"# Format: step, action_shape, action_values, image_shape, image_mean, image_std\n")
            f.write(f"# {'='*80}\n\n")
        step_count = 0

    # åˆå§‹åŒ– RealSense ç›¸æœºï¼ˆå¦‚æœå¯ç”¨ï¼‰
    camera_manager = None
    if args.use_realsense:
        if not REALSENSE_AVAILABLE:
            print("âŒ RealSense not available. Install with: pip install pyrealsense2")
            return 1
        
        try:
            camera_manager = RealSenseCameraManager(camera_serial=args.camera_serial)
            print("âœ… RealSense camera initialized")
        except Exception as e:
            print(f"âŒ Failed to initialize RealSense camera: {e}")
            return 1
    
    if args.use_realsense and not ROS2_AVAILABLE and not args.test_mode:
        print("âš ï¸  ROS2 not available, but RealSense is enabled.")
        print("ğŸ”„ Automatically switching to test mode (no ROS2 required)")
        args.test_mode = True

    # æµ‹è¯•æ¨¡å¼ï¼šä¸éœ€è¦ ROS2
    if args.test_mode:
        print("ğŸ§ª TEST MODE: Running without ROS2 (LIBERO)")
        try:
            client = websocket_client_policy.WebsocketClientPolicy(
                host=args.host,
                port=args.port,
            )
            print("âœ… Connected to policy server")
            
            # é¢„ç¼–è¯‘ï¼ˆé¢„çƒ­ï¼‰æ¨ç†
            warmup_inference(client)
            
            while True:
                # ä» RealSense è·å–å›¾åƒæˆ–ä½¿ç”¨å‡å›¾åƒ
                if camera_manager:
                    # ä»ç›¸æœºè¯»å–å›¾åƒ
                    cam_img = camera_manager.get_image()
                    if cam_img is not None:
                        # æ˜¾ç¤ºç›¸æœºç”»é¢ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                        if args.show_camera and CV2_AVAILABLE:
                            # æ˜¾ç¤ºåŸå§‹å›¾åƒï¼ˆBGR æ ¼å¼ç”¨äº OpenCVï¼‰
                            display_img = cam_img[:, :, ::-1]  # RGB -> BGR for OpenCV
                            cv2.imshow('RealSense Camera Feed', display_img)
                            # æŒ‰ 'q' é”®é€€å‡ºï¼Œæˆ–ç­‰å¾… 1msï¼ˆéé˜»å¡ï¼‰
                            if cv2.waitKey(1) & 0xFF == ord('q'):
                                print("ğŸ›‘ Camera window closed by user")
                                break
                        
                        # è½¬æ¢ä¸º HWC æ ¼å¼å¹¶è°ƒæ•´å¤§å°
                        base_img_fixed = ensure_hwc_uint8(cam_img)
                        wrist_img_fixed = base_img_fixed  # æš‚æ—¶ä½¿ç”¨ç›¸åŒå›¾åƒ
                    else:
                        # å¦‚æœè·å–å¤±è´¥ï¼Œä½¿ç”¨é›¶å›¾åƒ
                        base_img_fixed = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)
                        wrist_img_fixed = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)
                else:
                    # ä½¿ç”¨å‡å›¾åƒ
                    base_img_fixed = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)
                    wrist_img_fixed = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)
                
                # åœ¨æµ‹è¯•æ¨¡å¼ä¸‹ä½¿ç”¨é»˜è®¤çŠ¶æ€
                current_state = np.array(state, dtype=np.float32)  # 8 ç»´
                
                # LIBERO policy expects images in HWC format with specific keys
                observation = {
                    "observation/state": current_state,  # 8 ç»´
                    "observation/image": base_img_fixed,  # HWC format (224, 224, 3)
                    "observation/wrist_image": wrist_img_fixed,  # HWC format (224, 224, 3)
                    "prompt": task_instruction,
                }
                
                try:
                    result = client.infer(observation)
                    actions = result.get("actions")
                    if actions is not None:
                        print(f"âœ… Action chunk: shape={actions.shape}")
                        # LIBERO actions are typically 7-dim, but model may return more
                        if len(actions) > 0:
                            action_first_normalized = actions[0]  # è·å–ç¬¬ä¸€ä¸ªæ—¶é—´æ­¥çš„å®Œæ•´actionï¼ˆå½’ä¸€åŒ–åï¼‰
                            print(f"   Actions (normalized, first step): {action_first_normalized}")
                            print(f"   Action dimension: {len(action_first_normalized)}")
                            
                            # åå½’ä¸€åŒ– action
                            action_first_unnormalized = unnormalize_action(action_first_normalized)
                            print(f"   Actions (unnormalized, first step): {action_first_unnormalized}")
                            if action_norm_stats is not None:
                                print(f"   ğŸ” Unnormalization applied: use_quantile={use_quantile_norm}")
                            else:
                                print(f"   âš ï¸  Unnormalization NOT applied (action_norm_stats is None)")
                            
                            # ç‰¹åˆ«æ£€æŸ¥gripperå€¼ï¼ˆå¦‚æœæœ‰ç¬¬8ç»´ï¼‰
                            if len(action_first_unnormalized) >= 8:
                                gripper_value = action_first_unnormalized[7]
                                print(f"   ğŸ” Gripper value (unnormalized, dim 7): {gripper_value:.6f}")
                                if gripper_value > 0.02:
                                    print(f"      â†’ Will be set to 1.0 (close)")
                                else:
                                    print(f"      â†’ Will remain as {gripper_value:.6f} (open or small value)")
                            elif len(action_first_unnormalized) == 7:
                                print(f"   âš ï¸  Action only has 7 dims (no gripper dimension)")
                            else:
                                print(f"   âš ï¸  Unexpected action dimension: {len(action_first_unnormalized)}")
                        
                        # è®°å½•åŠ¨ä½œå’Œå›¾ç‰‡ä¿¡æ¯ï¼ˆæµ‹è¯•æ¨¡å¼ï¼‰
                        if recording_enabled and recording_file:
                            step_count += 1
                            action_shape = actions.shape
                            action_values_normalized = action_first_normalized.tolist() if len(actions) > 0 else []
                            action_values_unnormalized = action_first_unnormalized.tolist() if len(actions) > 0 else []
                            image_shape = base_img_fixed.shape
                            image_mean = float(np.mean(base_img_fixed))
                            image_std = float(np.std(base_img_fixed))
                            
                            with open(recording_file, 'a') as f:
                                f.write(f"Step {step_count}:\n")
                                f.write(f"  Action shape: {action_shape}\n")
                                f.write(f"  Action (normalized): {action_values_normalized}\n")
                                f.write(f"  Action (unnormalized): {action_values_unnormalized}\n")
                                f.write(f"  Image shape: {image_shape}\n")
                                f.write(f"  Image mean: {image_mean:.2f}, std: {image_std:.2f}\n")
                                f.write(f"\n")
                    else:
                        print("âš ï¸  No actions in response")
                except Exception as e:
                    print(f"âŒ Inference error: {e}")
                    import traceback
                    traceback.print_exc()
                
                time.sleep(0.5)
        except KeyboardInterrupt:
            print("\nğŸ›‘ Interrupted")
        except Exception as e:
            print(f"âŒ Error: {e}")
            import traceback
            traceback.print_exc()
            return 1
        finally:
            if args.show_camera and CV2_AVAILABLE:
                cv2.destroyAllWindows()
            if camera_manager:
                camera_manager.stop()
        return 0

    # ROS2 æ¨¡å¼
    if rclpy is None:
        print("âŒ rclpy not available. Run inside ROS2 environment or use --test-mode")
        sys.exit(1)

    # Connect to OpenPI inference server
    print(f"ğŸ”Œ Connecting to policy server at {args.host}:{args.port}...")
    try:
        client = websocket_client_policy.WebsocketClientPolicy(
            host=args.host,
            port=args.port,
        )
        print("âœ… Connected to policy server")
    except Exception as e:
        print(f"âŒ Failed to connect to policy server: {e}")
        print("   Make sure the policy server is running:")
        print("   uv run scripts/serve_policy.py --env LIBERO")
        return 1

    # é¢„ç¼–è¯‘ï¼ˆé¢„çƒ­ï¼‰æ¨ç†
    warmup_inference(client)

    rclpy.init()
    node = PoseSubscriber(args.topic, args.action_topic, args.joint_states_topic, args.gripper_topic)

    if args.use_realsense:
        print("ğŸ“· Using RealSense camera for images")
    else:
        print("âœ… TEST MODE: Sending fake LIBERO observation")
    if args.publish_actions:
        print(f"ğŸ“¤ Publishing actions to: {args.action_topic}")

    try:
        while True:
            # ä» RealSense è·å–å›¾åƒæˆ–ä½¿ç”¨å‡å›¾åƒ
            if camera_manager:
                # ä»ç›¸æœºè¯»å–å›¾åƒ
                cam_img = camera_manager.get_image()
                if cam_img is not None:
                    # æ˜¾ç¤ºç›¸æœºç”»é¢ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                    if args.show_camera and CV2_AVAILABLE:
                        # æ˜¾ç¤ºåŸå§‹å›¾åƒï¼ˆBGR æ ¼å¼ç”¨äº OpenCVï¼‰
                        display_img = cam_img[:, :, ::-1]  # RGB -> BGR for OpenCV
                        cv2.imshow('RealSense Camera Feed', display_img)
                        # æŒ‰ 'q' é”®é€€å‡ºï¼Œæˆ–ç­‰å¾… 1msï¼ˆéé˜»å¡ï¼‰
                        if cv2.waitKey(1) & 0xFF == ord('q'):
                            print("ğŸ›‘ Camera window closed by user")
                            break
                    
                    # è½¬æ¢ä¸º HWC æ ¼å¼å¹¶è°ƒæ•´å¤§å°
                    base_img_fixed = ensure_hwc_uint8(cam_img)
                    wrist_img_fixed = base_img_fixed  # æš‚æ—¶ä½¿ç”¨ç›¸åŒå›¾åƒ
                else:
                    # å¦‚æœè·å–å¤±è´¥ï¼Œä½¿ç”¨é›¶å›¾åƒ
                    base_img_fixed = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)
                    wrist_img_fixed = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)
            else:
                # ä½¿ç”¨å‡å›¾åƒ
                base_img_fixed = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)
                wrist_img_fixed = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)

            # è·å–æœ€æ–°çš„å…³èŠ‚çŠ¶æ€ï¼ˆå¦‚æœ ROS2 å¯ç”¨ï¼‰
            if ROS2_AVAILABLE and hasattr(node, 'latest_state'):
                current_state = node.latest_state
            else:
                # ä½¿ç”¨é»˜è®¤çŠ¶æ€
                current_state = np.array(state, dtype=np.float32)
            
            # LIBERO policy expects images in HWC format with specific keys
            observation = {
                "observation/state": current_state,  # 8 ç»´ï¼ˆä» joint_states è·å–æˆ–ä½¿ç”¨é»˜è®¤å€¼ï¼‰
                "observation/image": base_img_fixed,  # HWC format (224, 224, 3)
                "observation/wrist_image": wrist_img_fixed,  # HWC format (224, 224, 3)
                "prompt": task_instruction,
            }

            try:
                result = client.infer(observation)
                actions = result.get("actions")
                
                if actions is not None:
                    print(f"âœ… Action chunk received: shape={actions.shape}")
                    # LIBERO actions are typically 7-dim, but model may return more
                    if len(actions) > 0:
                        action_first_normalized = actions[0]  # è·å–ç¬¬ä¸€ä¸ªæ—¶é—´æ­¥çš„å®Œæ•´actionï¼ˆå½’ä¸€åŒ–åï¼‰
                        print(f"   Actions (normalized, first step): {action_first_normalized}")
                        print(f"   Action dimension: {len(action_first_normalized)}")
                        
                        # åå½’ä¸€åŒ– action
                        action_first_unnormalized = unnormalize_action(action_first_normalized)
                        print(f"   Actions (unnormalized, first step): {action_first_unnormalized}")
                        if action_norm_stats is not None:
                            print(f"   ğŸ” Unnormalization applied: use_quantile={use_quantile_norm}")
                        else:
                            print(f"   âš ï¸  Unnormalization NOT applied (action_norm_stats is None)")
                        
                        # ç‰¹åˆ«æ£€æŸ¥gripperå€¼ï¼ˆå¦‚æœæœ‰ç¬¬8ç»´ï¼‰
                        if len(action_first_unnormalized) >= 8:
                            gripper_value = action_first_unnormalized[7]
                            print(f"   ğŸ” Gripper value (unnormalized, dim 7): {gripper_value:.6f}")
                            if gripper_value > 0.02:
                                print(f"      â†’ Will be set to 1.0 (close)")
                            else:
                                print(f"      â†’ Will remain as {gripper_value:.6f} (open or small value)")
                        elif len(action_first_unnormalized) == 7:
                            print(f"   âš ï¸  Action only has 7 dims (no gripper dimension)")
                        else:
                            print(f"   âš ï¸  Unexpected action dimension: {len(action_first_unnormalized)}")
                        
                        # è®°å½•åŠ¨ä½œå’Œå›¾ç‰‡ä¿¡æ¯ï¼ˆROS2 æ¨¡å¼ï¼‰
                        if recording_enabled and recording_file:
                            step_count += 1
                            action_shape = actions.shape
                            action_values_normalized = action_first_normalized.tolist()
                            action_values_unnormalized = action_first_unnormalized.tolist()
                            image_shape = base_img_fixed.shape
                            image_mean = float(np.mean(base_img_fixed))
                            image_std = float(np.std(base_img_fixed))
                            
                            with open(recording_file, 'a') as f:
                                f.write(f"Step {step_count}:\n")
                                f.write(f"  Action shape: {action_shape}\n")
                                f.write(f"  Action (normalized): {action_values_normalized}\n")
                                f.write(f"  Action (unnormalized): {action_values_unnormalized}\n")
                                f.write(f"  Image shape: {image_shape}\n")
                                f.write(f"  Image mean: {image_mean:.2f}, std: {image_std:.2f}\n")
                                f.write(f"\n")
                        
                        # å‘å¸ƒåŠ¨ä½œåˆ° ROS2 è¯é¢˜ï¼ˆä¼šåœ¨ publish_action å†…éƒ¨è¿›è¡Œåå½’ä¸€åŒ–ï¼‰
                        if args.publish_actions:
                            node.publish_action(actions)  # ä¼ å…¥å®Œæ•´çš„ actionsï¼ˆpublish_action ä¼šå¤„ç†ï¼‰
                    else:
                        print("   Empty action chunk")
                else:
                    print("âš ï¸  No actions in response")
                    
            except Exception as e:
                print(f"âŒ Inference error: {e}")
                import traceback
                traceback.print_exc()

            rclpy.spin_once(node, timeout_sec=0.1)
            time.sleep(2)   # 2 Hz (avoid spamming server)

    except KeyboardInterrupt:
        print("\nğŸ›‘ Interrupted")

    finally:
        if args.show_camera and CV2_AVAILABLE:
            cv2.destroyAllWindows()
        if camera_manager:
            camera_manager.stop()
        # if recording_enabled and recording_file:
        #     with open(recording_file, 'a') as f:
        #         f.write(f"# {'='*80}\n")
        #         f.write(f"# Recording ended at: {datetime.now().isoformat()}\n")
        #         f.write(f"# Total steps: {step_count}\n")
        #     print(f"ğŸ“ Recording saved: {recording_file} ({step_count} steps)")
        node.destroy_node()
        rclpy.shutdown()


if __name__ == "__main__":
    main()

