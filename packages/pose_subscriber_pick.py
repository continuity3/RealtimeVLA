#!/usr/bin/env python3
"""
Minimal TEST version for OpenPI LIBERO policy.

Goal:
- Make OpenPI LIBERO policy inference RUN successfully
- No physical meaning, only pipeline verification
"""

import argparse
import pathlib
import sys
import time
import collections
import numpy as np

from openpi_client import websocket_client_policy
import numpy as np
import math

import rclpy
from rclpy.node import Node
from geometry_msgs.msg import PoseStamped
from std_msgs.msg import Float64, Float64MultiArray

# OpenCV ç”¨äºå¯è§†åŒ–
try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    print("âš ï¸  cv2 not available. Install with: pip install opencv-python")

# RealSense ç›¸æœºæ”¯æŒ
try:
    import pyrealsense2 as rs
    REALSENSE_AVAILABLE = True
except ImportError:
    REALSENSE_AVAILABLE = False
    print("âš ï¸  pyrealsense2 not available. Install with: pip install pyrealsense2")

try:
    import rclpy
    from rclpy.node import Node
    from geometry_msgs.msg import PoseStamped
    from std_msgs.msg import Float64MultiArray, Float64
    from sensor_msgs.msg import JointState
    ROS2_AVAILABLE = True
except Exception:
    rclpy = None
    Node = None
    PoseStamped = None
    Float64MultiArray = None
    Float64 = None
    JointState = None
    ROS2_AVAILABLE = False


# =========================
# Configuration
# =========================

IMG_SIZE = 224

# LIBERO expects 8-dim joint state
state = [0.0] * 8

# Default task instruction (can be overridden via --prompt argument)
task_instruction = "Pick up the blue square and move it in the  blue plate and return to the original position"


# =========================
# Quaternion to Axis-Angle Conversion
# =========================

def _quat2axisangle(quat):
    """
    Convert quaternion to axis-angle representation.
    Copied from robosuite: https://github.com/ARISE-Initiative/robosuite/blob/eafb81f54ffc104f905ee48a16bb15f059176ad3/robosuite/utils/transform_utils.py#L490C1-L512C55
    
    Args:
        quat: quaternion [x, y, z, w] or [w, x, y, z]
    
    Returns:
        axis-angle vector [x, y, z]
    """
    # Ensure quat is numpy array
    quat = np.asarray(quat)
    
    # Handle different quaternion formats: [x,y,z,w] vs [w,x,y,z]
    # Assume input is [x, y, z, w] (scipy/ROS format)
    if len(quat) == 4:
        x, y, z, w = quat[0], quat[1], quat[2], quat[3]
    else:
        raise ValueError(f"Quaternion must have 4 elements, got {len(quat)}")
    
    # Clip w component to valid range [-1, 1]
    if w > 1.0:
        w = 1.0
    elif w < -1.0:
        w = -1.0
    
    den = np.sqrt(1.0 - w * w)
    if math.isclose(den, 0.0):
        # This is (close to) a zero degree rotation, immediately return
        return np.zeros(3, dtype=np.float32)
    
    return (np.array([x, y, z]) * 2.0 * math.acos(w)) / den


# =========================
# RealSense Camera Manager
# =========================

class RealSenseCameraManager:
    """ç®¡ç† RealSense ç›¸æœºï¼ˆLIBERO ç‰ˆæœ¬ï¼‰"""
    
    def __init__(self, camera_serial=None, width=640, height=480, fps=30):
        """
        åˆå§‹åŒ– RealSense ç›¸æœºç®¡ç†å™¨
        
        Args:
            camera_serial: ç›¸æœºåºåˆ—å·ï¼Œå¦‚æœä¸º Noneï¼Œå°†è‡ªåŠ¨æ£€æµ‹ç¬¬ä¸€ä¸ªå¯ç”¨ç›¸æœº
            width: å›¾åƒå®½åº¦
            height: å›¾åƒé«˜åº¦
            fps: å¸§ç‡
        """
        if not REALSENSE_AVAILABLE:
            raise RuntimeError("pyrealsense2 is not available. Please install it.")
        
        self.width = width
        self.height = height
        self.fps = fps
        self.pipeline = None
        
        # æ£€æµ‹å¯ç”¨ç›¸æœº
        ctx = rs.context()
        devices = ctx.query_devices()
        
        print(f"Found {len(devices)} RealSense device(s):")
        available_serials = []
        for dev in devices:
            serial = dev.get_info(rs.camera_info.serial_number)
            name = dev.get_info(rs.camera_info.name)
            print(f"  - {name} (Serial: {serial})")
            available_serials.append(serial)
        
        if len(devices) == 0:
            raise RuntimeError("No RealSense cameras found!")
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šåºåˆ—å·ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨ç›¸æœº
        if camera_serial is None:
            camera_serial = available_serials[0]
        
        # åˆå§‹åŒ–ç›¸æœº
        try:
            pipeline = rs.pipeline()
            config = rs.config()
            config.enable_device(camera_serial)
            config.enable_stream(rs.stream.color, width, height, rs.format.bgr8, fps)
            
            pipeline.start(config)
            self.pipeline = pipeline
            print(f"âœ… Started camera (Serial: {camera_serial})")
        except Exception as e:
            print(f"âš ï¸  Failed to start camera (Serial: {camera_serial}): {e}")
            raise
    
    def get_image(self):
        """
        è·å–å›¾åƒ
        
        Returns:
            numpy array in RGB format (H, W, 3), uint8, æˆ– None å¦‚æœç›¸æœºä¸å¯ç”¨
        """
        if self.pipeline is None:
            return None
        
        try:
            frames = self.pipeline.wait_for_frames(timeout_ms=1000)
            color_frame = frames.get_color_frame()
            
            if color_frame:
                # è½¬æ¢ä¸º numpy æ•°ç»„ (BGR format)
                img = np.asanyarray(color_frame.get_data())
                # BGR -> RGB
                img = img[:, :, ::-1]
                return img
        except Exception as e:
            print(f"âš ï¸  Error reading from camera: {e}")
        
        return None
    
    def stop(self):
        """åœæ­¢ç›¸æœº"""
        if self.pipeline is not None:
            try:
                self.pipeline.stop()
                print("âœ… Stopped camera")
            except Exception as e:
                print(f"âš ï¸  Error stopping camera: {e}")


# =========================
# USB Camera Manager
# =========================

class USBCameraManager:
    """ç®¡ç† USB æ‘„åƒå¤´ï¼ˆç”¨äºæ‰‹è…•ç›¸æœºï¼‰"""
    
    def __init__(self, device_index=0, width=640, height=480):
        """
        åˆå§‹åŒ– USB æ‘„åƒå¤´ç®¡ç†å™¨
        
        Args:
            device_index: æ‘„åƒå¤´è®¾å¤‡ç´¢å¼•ï¼ˆé»˜è®¤ 0ï¼Œå¯¹åº” /dev/video0ï¼‰
            width: å›¾åƒå®½åº¦
            height: å›¾åƒé«˜åº¦
        """
        if not CV2_AVAILABLE:
            raise RuntimeError("cv2 is not available. Please install opencv-python.")
        
        self.cap = cv2.VideoCapture(device_index)
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)
        
        if not self.cap.isOpened():
            raise RuntimeError(f"Failed to open USB camera /dev/video{device_index}")
        
        print(f"âœ… USB camera opened: /dev/video{device_index} (width={width}, height={height})")
    
    def get_image(self):
        """
        è·å–å›¾åƒ
        
        Returns:
            numpy array in RGB format (H, W, 3), uint8, æˆ– None å¦‚æœç›¸æœºä¸å¯ç”¨
        """
        ret, frame = self.cap.read()
        if not ret:
            return None
        # OpenCV è¯»å‡ºæ¥æ˜¯ BGR â†’ è½¬ RGB
        return frame[:, :, ::-1]
    
    def stop(self):
        """åœæ­¢ç›¸æœº"""
        if self.cap is not None:
            self.cap.release()
            print("âœ… Stopped USB camera")


# =========================
# ROS2 Node
# =========================

if ROS2_AVAILABLE:
    class PoseSubscriber(Node):
        def __init__(self, pose_topic: str, action_topic: str,
                    gripper_topic: str = "/gripper/feedback_R"):
            super().__init__('pose_subscriber_libero')

            self.get_logger().info(f'Subscribing to eef_pose topic: {pose_topic}')
            self.get_logger().info(f'Subscribing to gripper topic: {gripper_topic}')
            self.get_logger().info(f'Publishing actions to topic: {action_topic}')

            # --- subscribers ---
            # /eef_pose topic contains 7-dim: [pos_x, pos_y, pos_z, quat_x, quat_y, quat_z, quat_w]
            self.create_subscription(
                Float64MultiArray,
                pose_topic,
                self.eef_pose_callback,
                10,
            )

            # è®¢é˜… Float64MultiArrayï¼ŒåŒ…å« 5 ç»´æ•°æ®ï¼Œå–ç¬¬ä¸€åˆ—ï¼ˆç´¢å¼•0ï¼‰ä½œä¸ºå¤¹çˆªçŠ¶æ€å€¼
            # ä¸ convert_pick_blue_bottle_hdf5_to_lerobot_downsample4x.py ä¸­çš„é€»è¾‘ä¸€è‡´
            self.create_subscription(
                Float64MultiArray,
                gripper_topic,
                self.gripper_callback,
                10,
            )

            # --- publisher ---
            self.action_publisher = self.create_publisher(
                Float64MultiArray,
                action_topic,
                10
            )

            # --- state buffers ---
            self.ee_pos = None  # 3-dim position [x, y, z]
            self.ee_rotvec = None  # 3-dim axis-angle [rx, ry, rz]
            self.latest_gripper_value = 0.0  # gripper value

            self.latest_state = np.zeros(8, dtype=np.float32)
            
            # ç»´æŠ¤ gripper çš„ç´¯ç§¯çŠ¶æ€ï¼ˆç”¨äºé˜²æ­¢é¢‘ç¹åˆ‡æ¢ï¼‰
            self.current_gripper_state = 0.0  # å½“å‰gripperçŠ¶æ€ï¼š0.0=open, 1.0=close
            self.gripper_state_change_count = 0  # çŠ¶æ€æ”¹å˜çš„è®¡æ•°

        def eef_pose_callback(self, msg: Float64MultiArray):
            """
            å¤„ç† /eef_pose topic æ¶ˆæ¯
            æ¶ˆæ¯æ ¼å¼ï¼š7ç»´ [pos_x, pos_y, pos_z, quat_x, quat_y, quat_z, quat_w]
            """
            if len(msg.data) < 7:
                self.get_logger().warn(f'/eef_pose has {len(msg.data)} elements, expected 7')
                return
            
            # æå–ä½ç½® (å‰3ç»´)
            self.ee_pos = np.array([msg.data[0], msg.data[1], msg.data[2]], dtype=np.float32)
            
            # æå–å››å…ƒæ•° (å4ç»´) [x, y, z, w]
            quat = np.array([msg.data[3], msg.data[4], msg.data[5], msg.data[6]], dtype=np.float32)
            
            # è½¬æ¢ä¸º axis-angle (æ—‹è½¬å‘é‡)
            self.ee_rotvec = _quat2axisangle(quat)
            
            self.get_logger().debug(
                f'EEF Pose: pos=({self.ee_pos[0]:.3f}, {self.ee_pos[1]:.3f}, {self.ee_pos[2]:.3f}), '
                f'rotvec=({self.ee_rotvec[0]:.3f}, {self.ee_rotvec[1]:.3f}, {self.ee_rotvec[2]:.3f})'
            )
            
            # æ›´æ–°çŠ¶æ€
            self._update_state()
        
        def gripper_callback(self, msg: Float64MultiArray):
            """
            å¤„ç†å³å¤¹çˆªå€¼æ¶ˆæ¯
            æ¶ˆæ¯æ ¼å¼ï¼šFloat64MultiArrayï¼ŒåŒ…å« 5 ç»´æ•°æ®ï¼Œå–ç¬¬ä¸€åˆ—ï¼ˆç´¢å¼•0ï¼‰ä½œä¸ºå¤¹çˆªçŠ¶æ€å€¼
            ä¸ convert_pick_blue_bottle_hdf5_to_lerobot_downsample4x.py ä¸­çš„é€»è¾‘ä¸€è‡´ï¼š
            gripper_feedback_data = gripper_feedback_data[:, 0]  # å–ç¬¬ä¸€åˆ—
            """
            if len(msg.data) < 1:
                self.get_logger().warn(f'/gripper/feedback_R has {len(msg.data)} elements, expected at least 1')
                return
            
            # å–ç¬¬ä¸€åˆ—ï¼ˆç´¢å¼•0ï¼‰ä½œä¸ºå¤¹çˆªçŠ¶æ€å€¼ï¼Œä¸è½¬æ¢è„šæœ¬ä¿æŒä¸€è‡´
            self.latest_gripper_value = float(msg.data[0])
            self.get_logger().debug(
                f'Updated gripper value (from first column): {self.latest_gripper_value} '
                f'(full data length: {len(msg.data)})'
            )
            # æ›´æ–°çŠ¶æ€
            self._update_state()
        
        def _update_state(self):
            """
            æ›´æ–°çŠ¶æ€ï¼š8ç»´
            [ee_pos(3), ee_rotvec(3), gripper_value(1), -gripper_value(1)]
            """
            # å¦‚æœä½ç½®å’Œæ—‹è½¬å‘é‡éƒ½å¯ç”¨ï¼Œåˆ™æ„å»ºå®Œæ•´çŠ¶æ€
            if self.ee_pos is not None and self.ee_rotvec is not None:
                # ç»„åˆï¼šä½ç½®(3) + æ—‹è½¬å‘é‡(3) + å¤¹çˆªå€¼(1) + å¤¹çˆªå€¼ç›¸åæ•°(1) = 8ç»´
                self.latest_state = np.concatenate([
                    self.ee_pos,                    # 3-dim: EEF position
                    self.ee_rotvec,                 # 3-dim: EEF rotation (axis-angle)
                    np.array([self.latest_gripper_value], dtype=np.float32),  # 7th dim: gripper value
                    np.array([-self.latest_gripper_value], dtype=np.float32),  # 8th dim: -gripper value
                ])
                self.get_logger().debug(f'Updated state (8-dim): {self.latest_state}')
            else:
                # å¦‚æœæ•°æ®ä¸å®Œæ•´ï¼Œä½¿ç”¨é›¶å€¼
                if self.ee_pos is None:
                    self.ee_pos = np.zeros(3, dtype=np.float32)
                if self.ee_rotvec is None:
                    self.ee_rotvec = np.zeros(3, dtype=np.float32)
                self.latest_state = np.concatenate([
                    self.ee_pos,
                    self.ee_rotvec,
                    np.array([self.latest_gripper_value], dtype=np.float32),
                    np.array([-self.latest_gripper_value], dtype=np.float32),
                ])
        
        def publish_action(self, action: np.ndarray):
            """å‘å¸ƒåŠ¨ä½œä¸º Float64MultiArray æ¶ˆæ¯"""
            if action is None:
                return
            
            # ç¡®ä¿æ˜¯ 1D æ•°ç»„ï¼ˆå¦‚æœæ˜¯ action chunkï¼Œå–ç¬¬ä¸€ä¸ªåŠ¨ä½œï¼‰
            if action.ndim > 1:
                action = action[0]  # å–ç¬¬ä¸€ä¸ªæ—¶é—´æ­¥çš„åŠ¨ä½œ
            
            action_processed = action.copy()
            
            # å¤„ç†gripperå€¼ï¼šåªçœ‹ç¬¬ 6 ç»´ï¼ˆç´¢å¼• 6ï¼‰
            # Action format: [EEF_delta_pos(3), EEF_delta_ori(3), gripper_action(1)] = 7-dim
            if len(action_processed) >= 7:
                # ç¬¬ 6 ç»´ï¼ˆç´¢å¼• 6ï¼‰æ˜¯ gripper å€¼
                original_gripper = action_processed[6]
                self.get_logger().info(f'ğŸ” Raw gripper value (dim 6, before processing): {original_gripper:.6f}')
                
                # æ”¹è¿›çš„gripperåˆ¤æ–­é€»è¾‘ï¼š
                # 1. ä½¿ç”¨ç´¯ç§¯çŠ¶æ€é˜²æ­¢é¢‘ç¹åˆ‡æ¢
                # 2. è€ƒè™‘è´Ÿå€¼æƒ…å†µï¼ˆè´Ÿå€¼å¯èƒ½è¡¨ç¤ºcloseæŒ‡ä»¤ï¼‰
                # 3. ä½¿ç”¨æ›´ä¸¥æ ¼çš„é˜ˆå€¼å’Œæ»åï¼ˆhysteresisï¼‰
                
                # åˆ¤æ–­æ¨¡å‹æƒ³è¦çš„çŠ¶æ€ï¼ˆè€ƒè™‘æ­£è´Ÿå€¼ï¼‰
                desired_state = 1.0 if (original_gripper > 0.01 or original_gripper < -0.005) else 0.0
                # å¦‚æœç»å¯¹å€¼è¾ƒå¤§ï¼ˆå¯èƒ½æ˜¯closeæŒ‡ä»¤ï¼‰ï¼Œè®¾ä¸ºclose
                if abs(original_gripper) > 0.01:
                    desired_state = 1.0 if original_gripper > -0.01 else 0.0
                
                # ä½¿ç”¨æ»åé€»è¾‘ï¼šå¦‚æœå½“å‰æ˜¯openï¼Œéœ€è¦æ›´å¼ºçš„ä¿¡å·æ‰èƒ½closeï¼›åä¹‹äº¦ç„¶
                if self.current_gripper_state < 0.5:  # å½“å‰æ˜¯open
                    # éœ€è¦æ›´å¼ºçš„ä¿¡å·æ‰èƒ½åˆ‡æ¢åˆ°close
                    if original_gripper > 0.02:  # æ˜æ˜¾çš„æ­£å€¼ï¼ˆcloseä¿¡å·ï¼‰
                        gripper_cmd = 1.0
                        self.current_gripper_state = 1.0
                        self.gripper_state_change_count += 1
                    else:
                        gripper_cmd = 0.0  # ä¿æŒopen
                else:  # å½“å‰æ˜¯close
                    # éœ€è¦æ˜æ˜¾çš„è´Ÿå€¼æˆ–å°å€¼æ‰èƒ½åˆ‡æ¢åˆ°open
                    if original_gripper < -0.01:  # æ˜æ˜¾çš„è´Ÿå€¼ï¼ˆopenä¿¡å·ï¼‰
                        gripper_cmd = 0.0
                        self.current_gripper_state = 0.0
                        self.gripper_state_change_count += 1
                    else:
                        gripper_cmd = 1.0  # ä¿æŒcloseï¼ˆé»˜è®¤ä¿æŒå…³é—­çŠ¶æ€ï¼‰
                
                action_processed[6] = gripper_cmd
                
                if gripper_cmd > 0.5:
                    self.get_logger().info(f'âœ… Gripper value {original_gripper:.4f} â†’ 1.0 (close), state changes: {self.gripper_state_change_count}')
                else:
                    self.get_logger().info(f'ğŸ“Œ Gripper value {original_gripper:.4f} â†’ 0.0 (open), state changes: {self.gripper_state_change_count}')
            
            # è½¬æ¢ä¸º float64 åˆ—è¡¨
            action_list = action_processed.astype(np.float64).tolist()
            
            # åˆ›å»º Float64MultiArray æ¶ˆæ¯
            msg = Float64MultiArray()
            msg.data = action_list
            
            # å‘å¸ƒæ¶ˆæ¯
            self.action_publisher.publish(msg)
            self.latest_action = action_processed
            self.get_logger().debug(f'Published action: {action_list}')
else:
    # å ä½ç¬¦ç±»ï¼ˆå½“ ROS2 ä¸å¯ç”¨æ—¶ï¼‰
    class PoseSubscriber:
        def __init__(self, pose_topic: str, action_topic: str):
            pass
        
        def publish_action(self, action: np.ndarray):
            """å ä½ç¬¦æ–¹æ³•"""
            pass

def ensure_hwc_uint8(img: np.ndarray) -> np.ndarray:
    """
    Ensure image is (H, W, 3) uint8 for LIBERO policy.
    LIBERO expects images in HWC format: (224, 224, 3)
    """
    img = np.asarray(img)

    # å»æ‰ batch ç»´
    if img.ndim == 4 and img.shape[0] == 1:
        img = img[0]

    # CHW -> HWC (å¦‚æœå½“å‰æ˜¯ CHW æ ¼å¼)
    if img.ndim == 3 and img.shape[0] == 3:
        img = np.transpose(img, (1, 2, 0))

    # ç°åº¦ -> RGB
    if img.ndim == 2:
        img = np.repeat(img[:, :, None], 3, axis=2)

    # å•é€šé“ -> 3 é€šé“
    if img.ndim == 3 and img.shape[2] == 1:
        img = np.repeat(img, 3, axis=2)

    # ç¡®ä¿æ˜¯ (224, 224, 3)
    if img.shape != (IMG_SIZE, IMG_SIZE, 3):
        # å¦‚æœå°ºå¯¸ä¸å¯¹ï¼Œè°ƒæ•´å¤§å°
        from PIL import Image
        img_pil = Image.fromarray(img)
        img_pil = img_pil.resize((IMG_SIZE, IMG_SIZE), Image.BILINEAR)
        img = np.array(img_pil)

    assert img.shape == (IMG_SIZE, IMG_SIZE, 3), f"Bad image shape: {img.shape}, expected ({IMG_SIZE}, {IMG_SIZE}, 3)"

    return img.astype(np.uint8)


def is_using_realsense(using_realsense: bool, camera_manager) -> bool:
    """
    ç»Ÿä¸€åˆ¤æ–­å‡½æ•°ï¼šæ£€æŸ¥æ˜¯å¦æ­£åœ¨ä½¿ç”¨ RealSense ç›¸æœºä½œä¸ºè¾“å…¥æº
    
    Args:
        using_realsense: æ˜¾å¼å¸ƒå°”çŠ¶æ€æ ‡å¿—
        camera_manager: RealSense ç›¸æœºç®¡ç†å™¨å®ä¾‹
    
    Returns:
        bool: True å¦‚æœæ­£åœ¨ä½¿ç”¨ RealSense ç›¸æœºï¼ŒFalse å¦åˆ™
    """
    return using_realsense and camera_manager is not None


def main(argv=None):
    parser = argparse.ArgumentParser(
        description='ROS2 PoseStamped subscriber with OpenPI LIBERO policy inference',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Test mode (no ROS2 required):
  python3 packages/pose_subscriber_libero.py --test-mode
  
  # With ROS2:
  python3 packages/pose_subscriber_libero.py --topic /pose
  
  # Custom server:
  python3 packages/pose_subscriber_libero.py --test-mode --host localhost --port 8001
        """
    )
    parser.add_argument('--topic', '-t', default='/info/eef_right', help='ROS2 topic to subscribe to (eef_pose, 7-dim: pos+quat)')
    parser.add_argument('--action-topic', default='/libero/actions', 
                       help='ROS2 topic to publish actions (default: /libero/actions)')
    parser.add_argument('--gripper-topic', default='/gripper/feedback_R',
                       help='ROS2 topic to subscribe to for right gripper value (default: /gripper/feedback_R)')

    parser.add_argument('--host', default='localhost', help='Policy server host (default: localhost)')
    parser.add_argument('--port', type=int, default=8000, help='Policy server port (default: 8000)')
    parser.add_argument('--test-mode', action='store_true', 
                       help='Run in test mode without ROS2 (for testing policy server connection)')
    parser.add_argument('--publish-actions', action='store_true', default=True,
                       help='Publish actions to ROS2 topic (default: True)')
    parser.add_argument('--use-realsense', action='store_true',
                       help='Use RealSense camera instead of fake images')
    parser.add_argument('--camera-serial', type=str, default=None,
                       help='RealSense serial number (if not specified, uses first available camera)')
    parser.add_argument('--show-camera', action='store_true',
                       help='Show RealSense camera feed in a window (requires opencv-python)')
    parser.add_argument('--use-usb-wrist', action='store_true',
                       help='Use USB camera as wrist camera')
    parser.add_argument('--usb-index', type=int, default=0,
                       help='USB camera index (default: /dev/video0)')
    args = parser.parse_args(argv)

    # åˆå§‹åŒ– RealSense ç›¸æœºï¼ˆå¦‚æœå¯ç”¨ï¼‰
    camera_manager = None
    using_realsense = False
    
    if args.use_realsense:
        if not REALSENSE_AVAILABLE:
            print("âŒ RealSense not available. Install with: pip install pyrealsense2")
            return 1
        
        try:
            camera_manager = RealSenseCameraManager(camera_serial=args.camera_serial)
            using_realsense = True
            print("âœ… RealSense camera initialized and will be used as input")
        except Exception as e:
            print(f"âŒ Failed to initialize RealSense camera: {e}")
            using_realsense = False
            return 1
    
    if args.use_realsense and not ROS2_AVAILABLE and not args.test_mode:
        print("âš ï¸  ROS2 not available, but RealSense is enabled.")
        print("ğŸ”„ Automatically switching to test mode (no ROS2 required)")
        args.test_mode = True

    # åˆå§‹åŒ– USB æ‘„åƒå¤´ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    usb_camera = None
    if args.use_usb_wrist:
        if not CV2_AVAILABLE:
            print("âŒ cv2 not available, cannot use USB camera")
            return 1
        try:
            usb_camera = USBCameraManager(device_index=args.usb_index)
            print("âœ… USB camera initialized and will be used as wrist camera")
        except Exception as e:
            print(f"âŒ Failed to initialize USB camera: {e}")
            return 1

    # æµ‹è¯•æ¨¡å¼ï¼šä¸éœ€è¦ ROS2
    if args.test_mode:
        print("ğŸ§ª TEST MODE: Running without ROS2 (LIBERO)")
        try:
            client = websocket_client_policy.WebsocketClientPolicy(
                host=args.host,
                port=args.port,
            )
            print("âœ… Connected to policy server")
            
            # ç»´æŠ¤ action chunk é˜Ÿåˆ—
            action_plan = collections.deque()
            replan_steps = 5  # æ¯æ‰§è¡Œ 5 ä¸ªåŠ¨ä½œåé‡æ–°è§„åˆ’ï¼ˆä½¿ç”¨æ–°çš„ chunkï¼‰
            
            while True:
                # ä» RealSense è·å–å›¾åƒæˆ–ä½¿ç”¨å‡å›¾åƒ
                if camera_manager:
                    # ä»ç›¸æœºè¯»å–å›¾åƒ
                    cam_img = camera_manager.get_image()
                    if cam_img is not None:
                        # æ˜¾ç¤ºç›¸æœºç”»é¢ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                        if args.show_camera and CV2_AVAILABLE:
                            # æ˜¾ç¤ºåŸå§‹å›¾åƒï¼ˆBGR æ ¼å¼ç”¨äº OpenCVï¼‰
                            display_img = cam_img[:, :, ::-1]  # RGB -> BGR for OpenCV
                            cv2.imshow('RealSense Camera Feed', display_img)
                            # æŒ‰ 'q' é”®é€€å‡ºï¼Œæˆ–ç­‰å¾… 1msï¼ˆéé˜»å¡ï¼‰
                            if cv2.waitKey(1) & 0xFF == ord('q'):
                                print("ğŸ›‘ Camera window closed by user")
                                break
                        
                        # base image: RealSense
                        base_img_fixed = ensure_hwc_uint8(cam_img)
                        
                        # wrist image: USB camera
                        if usb_camera:
                            wrist_img = usb_camera.get_image()
                            if wrist_img is not None:
                                wrist_img_fixed = ensure_hwc_uint8(wrist_img)
                            else:
                                wrist_img_fixed = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)
                        else:
                            wrist_img_fixed = base_img_fixed  # fallbackï¼ˆä¸æ¨èï¼‰
                    else:
                        # å¦‚æœè·å–å¤±è´¥ï¼Œä½¿ç”¨é›¶å›¾åƒ
                        base_img_fixed = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)
                        wrist_img_fixed = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)
                else:
                    # ä½¿ç”¨å‡å›¾åƒ
                    base_img_fixed = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)
                    # wrist image: USB cameraï¼ˆå³ä½¿æ²¡æœ‰ RealSenseï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨ USB ä½œä¸º wristï¼‰
                    if usb_camera:
                        wrist_img = usb_camera.get_image()
                        if wrist_img is not None:
                            wrist_img_fixed = ensure_hwc_uint8(wrist_img)
                        else:
                            wrist_img_fixed = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)
                    else:
                        wrist_img_fixed = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)
                
                # åœ¨æµ‹è¯•æ¨¡å¼ä¸‹ä½¿ç”¨é»˜è®¤çŠ¶æ€
                current_state = np.array(state, dtype=np.float32)  # 8 ç»´
                
                # åˆ¤æ–­è¾“å…¥æºå¹¶æ‰“å°
                if is_using_realsense(using_realsense, camera_manager):
                    print("ğŸ“· INPUT SOURCE: RealSense image")
                else:
                    print("ğŸ§ª INPUT SOURCE: Fake / zero image")
                    if not using_realsense:
                        print("   â„¹ï¸  Reason: --use-realsense flag not set or initialization failed")
                    elif camera_manager is None:
                        print("   â„¹ï¸  Reason: camera_manager is None")
                
                # éªŒè¯åŒæ‘„åƒå¤´è¾“å…¥ï¼ˆè°ƒè¯•è¾“å‡ºï¼‰
                print(f"ğŸ” base mean: {base_img_fixed.mean():.2f}, wrist mean: {wrist_img_fixed.mean():.2f}")
                
                # å¦‚æœ action é˜Ÿåˆ—ä¸ºç©ºï¼Œè°ƒç”¨æ¨ç†è·å–æ–°çš„ chunk
                if not action_plan:
                    # LIBERO policy expects images in HWC format with specific keys
                    observation = {
                        "observation/state": current_state,  # 8 ç»´
                        "observation/image": base_img_fixed,  # HWC format (224, 224, 3)
                        "observation/wrist_image": wrist_img_fixed,  # HWC format (224, 224, 3)
                        "prompt": task_instruction,
                    }
                    
                    try:
                        print("ğŸ”„ Action queue empty, requesting new action chunk...")
                        result = client.infer(observation)
                        action_chunk = result.get("actions")
                        if action_chunk is not None:
                            print(f"âœ… Action chunk received: shape={action_chunk.shape}")
                            # å°† chunk çš„å‰ replan_steps ä¸ªåŠ¨ä½œåŠ å…¥é˜Ÿåˆ—
                            action_plan.extend(action_chunk[:replan_steps])
                            print(f"   Added {len(action_plan)} actions to queue")
                        else:
                            print("âš ï¸  No actions in response")
                            continue
                    except Exception as e:
                        print(f"âŒ Inference error: {e}")
                        import traceback
                        traceback.print_exc()
                        continue
                
                # ä»é˜Ÿåˆ—ä¸­å–å‡ºä¸€ä¸ªåŠ¨ä½œ
                action = action_plan.popleft()
                print(f"ğŸ“¤ Executing action from queue ({len(action_plan)} remaining)")
                print(f"   Action: {action}")
                
                # æ£€æŸ¥gripperå€¼ï¼ˆç¬¬ 6 ç»´ï¼Œç´¢å¼• 6ï¼‰
                if len(action) >= 7:
                    gripper_value = action[6]
                    gripper_cmd = 1.0 if gripper_value > 0.02 else 0.0
                    print(f"   ğŸ” Gripper value (dim 6): {gripper_value:.6f}")
                    print(f"      â†’ Will be set to {gripper_cmd:.1f} ({'close' if gripper_cmd > 0.5 else 'open'})")
                else:
                    print(f"   âš ï¸  Action has {len(action)} dims, expected at least 7")
                
                time.sleep(0.5)
        except KeyboardInterrupt:
            print("\nğŸ›‘ Interrupted")
        except Exception as e:
            print(f"âŒ Error: {e}")
            import traceback
            traceback.print_exc()
            return 1
        finally:
            if args.show_camera and CV2_AVAILABLE:
                cv2.destroyAllWindows()
            if camera_manager:
                camera_manager.stop()
            if usb_camera:
                usb_camera.stop()
        return 0

    # ROS2 æ¨¡å¼
    if rclpy is None:
        print("âŒ rclpy not available. Run inside ROS2 environment or use --test-mode")
        sys.exit(1)

    # Connect to OpenPI inference server
    print(f"ğŸ”Œ Connecting to policy server at {args.host}:{args.port}...")
    try:
        client = websocket_client_policy.WebsocketClientPolicy(
            host=args.host,
            port=args.port,
        )
        print("âœ… Connected to policy server")
    except Exception as e:
        print(f"âŒ Failed to connect to policy server: {e}")
        print("   Make sure the policy server is running:")
        print("   uv run scripts/serve_policy.py --env LIBERO")
        return 1

    rclpy.init()
    node = PoseSubscriber(args.topic, args.action_topic, args.gripper_topic)

    if args.publish_actions:
        print(f"ğŸ“¤ Publishing actions to: {args.action_topic}")

    # ç»´æŠ¤ action chunk é˜Ÿåˆ—
    action_plan = collections.deque()
    replan_steps = 5  # æ¯æ‰§è¡Œ 5 ä¸ªåŠ¨ä½œåé‡æ–°è§„åˆ’ï¼ˆä½¿ç”¨æ–°çš„ chunkï¼‰

    try:
        while True:
            # ä» RealSense è·å–å›¾åƒæˆ–ä½¿ç”¨å‡å›¾åƒ
            if camera_manager:
                # ä»ç›¸æœºè¯»å–å›¾åƒ
                cam_img = camera_manager.get_image()
                if cam_img is not None:
                    # æ˜¾ç¤ºç›¸æœºç”»é¢ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                    if args.show_camera and CV2_AVAILABLE:
                        # æ˜¾ç¤ºåŸå§‹å›¾åƒï¼ˆBGR æ ¼å¼ç”¨äº OpenCVï¼‰
                        display_img = cam_img[:, :, ::-1]  # RGB -> BGR for OpenCV
                        cv2.imshow('RealSense Camera Feed', display_img)
                        # æŒ‰ 'q' é”®é€€å‡ºï¼Œæˆ–ç­‰å¾… 1msï¼ˆéé˜»å¡ï¼‰
                        if cv2.waitKey(1) & 0xFF == ord('q'):
                            print("ğŸ›‘ Camera window closed by user")
                            break
                    
                    # è½¬æ¢ä¸º HWC æ ¼å¼å¹¶è°ƒæ•´å¤§å°
                    base_img_fixed = ensure_hwc_uint8(cam_img)
                    
                    # wrist image: USB camera
                    if usb_camera:
                        wrist_img = usb_camera.get_image()
                        if wrist_img is not None:
                            wrist_img_fixed = ensure_hwc_uint8(wrist_img)
                        else:
                            wrist_img_fixed = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)
                    else:
                        wrist_img_fixed = base_img_fixed  # fallbackï¼ˆä¸æ¨èï¼‰
                else:
                    # å¦‚æœè·å–å¤±è´¥ï¼Œä½¿ç”¨é›¶å›¾åƒ
                    base_img_fixed = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)
                    wrist_img_fixed = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)
            else:
                # ä½¿ç”¨å‡å›¾åƒ
                base_img_fixed = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)
                # wrist image: USB cameraï¼ˆå³ä½¿æ²¡æœ‰ RealSenseï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨ USB ä½œä¸º wristï¼‰
                if usb_camera:
                    wrist_img = usb_camera.get_image()
                    if wrist_img is not None:
                        wrist_img_fixed = ensure_hwc_uint8(wrist_img)
                    else:
                        wrist_img_fixed = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)
                else:
                    wrist_img_fixed = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)

            # è·å–æœ€æ–°çš„å…³èŠ‚çŠ¶æ€ï¼ˆå¦‚æœ ROS2 å¯ç”¨ï¼‰
            if ROS2_AVAILABLE and hasattr(node, 'latest_state'):
                current_state = node.latest_state
            else:
                # ä½¿ç”¨é»˜è®¤çŠ¶æ€
                current_state = np.array(state, dtype=np.float32)
            
            # åˆ¤æ–­è¾“å…¥æºå¹¶æ‰“å°
            if is_using_realsense(using_realsense, camera_manager):
                print("ğŸ“· INPUT SOURCE: RealSense image")
            else:
                print("ğŸ§ª INPUT SOURCE: Fake / zero image")
                if not using_realsense:
                    print("   â„¹ï¸  Reason: --use-realsense flag not set or initialization failed")
                elif camera_manager is None:
                    print("   â„¹ï¸  Reason: camera_manager is None")
            
            # éªŒè¯åŒæ‘„åƒå¤´è¾“å…¥ï¼ˆè°ƒè¯•è¾“å‡ºï¼‰
            print(f"ğŸ” base mean: {base_img_fixed.mean():.2f}, wrist mean: {wrist_img_fixed.mean():.2f}")
            
            # å¦‚æœ action é˜Ÿåˆ—ä¸ºç©ºï¼Œè°ƒç”¨æ¨ç†è·å–æ–°çš„ chunk
            if not action_plan:
                # LIBERO policy expects images in HWC format with specific keys
                observation = {
                    "observation/state": current_state,  # 8 ç»´ï¼ˆä» joint_states è·å–æˆ–ä½¿ç”¨é»˜è®¤å€¼ï¼‰
                    "observation/image": base_img_fixed,  # HWC format (224, 224, 3)
                    "observation/wrist_image": wrist_img_fixed,  # HWC format (224, 224, 3)
                    "prompt": task_instruction,
                }

                try:
                    print("ğŸ”„ Action queue empty, requesting new action chunk...")
                    result = client.infer(observation)
                    action_chunk = result.get("actions")
                    
                    if action_chunk is not None:
                        print(f"âœ… Action chunk received: shape={action_chunk.shape}")
                        # å°† chunk çš„å‰ replan_steps ä¸ªåŠ¨ä½œåŠ å…¥é˜Ÿåˆ—
                        action_plan.extend(action_chunk[:replan_steps])
                        print(f"   Added {len(action_plan)} actions to queue")
                    else:
                        print("âš ï¸  No actions in response")
                        rclpy.spin_once(node, timeout_sec=0.1)
                        continue
                        
                except Exception as e:
                    print(f"âŒ Inference error: {e}")
                    import traceback
                    traceback.print_exc()
                    rclpy.spin_once(node, timeout_sec=0.1)
                    continue
            
            # ä»é˜Ÿåˆ—ä¸­å–å‡ºä¸€ä¸ªåŠ¨ä½œ
            action = action_plan.popleft()
            print(f"ğŸ“¤ Executing action from queue ({len(action_plan)} remaining)")
            print(f"   Action: {action}")
            
            # æ£€æŸ¥gripperå€¼ï¼ˆç¬¬ 6 ç»´ï¼Œç´¢å¼• 6ï¼‰
            if len(action) >= 7:
                gripper_value = action[6]
                # ä½¿ç”¨ä¸ publish_action ç›¸åŒçš„é€»è¾‘
                if node.current_gripper_state < 0.5:  # å½“å‰æ˜¯open
                    gripper_cmd = 1.0 if gripper_value > 0.02 else 0.0
                    if gripper_cmd > 0.5:
                        node.current_gripper_state = 1.0
                        node.gripper_state_change_count += 1
                else:  # å½“å‰æ˜¯close
                    gripper_cmd = 0.0 if gripper_value < -0.01 else 1.0
                    if gripper_cmd < 0.5:
                        node.current_gripper_state = 0.0
                        node.gripper_state_change_count += 1
                print(f"   ğŸ” Gripper value (dim 6): {gripper_value:.6f}")
                print(f"      â†’ Will be set to {gripper_cmd:.1f} ({'close' if gripper_cmd > 0.5 else 'open'}), state changes: {node.gripper_state_change_count}")
            else:
                print(f"   âš ï¸  Action has {len(action)} dims, expected at least 7")
            
            # å‘å¸ƒåŠ¨ä½œåˆ° ROS2 è¯é¢˜
            if args.publish_actions:
                node.publish_action(action)

            rclpy.spin_once(node, timeout_sec=0.1)
            time.sleep(0.2)   # 5 Hz (æ¯ 0.2 ç§’æ‰§è¡Œä¸€ä¸ªåŠ¨ä½œ)

    except KeyboardInterrupt:
        print("\nğŸ›‘ Interrupted")

    finally:
        if args.show_camera and CV2_AVAILABLE:
            cv2.destroyAllWindows()
        if camera_manager:
            camera_manager.stop()
        if usb_camera:
            usb_camera.stop()
        node.destroy_node()
        rclpy.shutdown()


if __name__ == "__main__":
    main()

